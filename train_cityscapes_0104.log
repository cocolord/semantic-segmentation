None
Global Rank: 3 Local Rank: 3
None
Global Rank: 0 Local Rank: 0
None
Global Rank: 1 Local Rank: 1
None
Global Rank: 2 Local Rank: 2
Torch version: 1.6, 1.6.0
n scales [0.5, 1.0, 2.0]
dataset = cityscapes
ignore_label = 255
num_classes = 19
cv split val 0 ['val/munster', 'val/frankfurt', 'val/lindau']
mode val found 500 images
cn num_classes 19
cv split train 0 ['train/aachen', 'train/bochum', 'train/bremen', 'train/cologne', 'train/darmstadt', 'train/dusseldorf', 'train/erfurt', 'train/hamburg', 'train/hanover', 'train/jena', 'train/krefeld', 'train/monchengladbach', 'train/strasbourg', 'train/stuttgart', 'train/tubingen', 'train/ulm', 'train/weimar', 'train/zurich']
mode train found 2975 images
cn num_classes 19
Loading centroid file /home/gandi/Donglusen/workspace/semantic-segmentation/assets/uniform_centroids/cityscapes_cv0_tile1024.json
Found 19 centroids
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
Using Cross Entropy Loss
Loading weights from: checkpoint=/home/gandi/Donglusen/workspace/semantic-segmentation/assets/seg_weights/ocrnet.HRNet_industrious-chicken.pth
=> init weights from normal distribution
=> loading pretrained model /home/gandi/Donglusen/workspace/semantic-segmentation/assets/seg_weights/hrnetv2_w48_imagenet_pretrained.pth
Trunk: hrnetv2
Model params = 72.1M
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Skipped loading parameter module.ocr.cls_head.weight
Skipped loading parameter module.ocr.cls_head.bias
Skipped loading parameter module.ocr.aux_head.2.weight
Skipped loading parameter module.ocr.aux_head.2.bias
Skipped loading parameter module.scale_attn.conv0.weight
Skipped loading parameter module.scale_attn.bn0.weight
Skipped loading parameter module.scale_attn.bn0.bias
Skipped loading parameter module.scale_attn.bn0.running_mean
Skipped loading parameter module.scale_attn.bn0.running_var
Skipped loading parameter module.scale_attn.bn0.num_batches_tracked
Skipped loading parameter module.scale_attn.conv1.weight
Skipped loading parameter module.scale_attn.bn1.weight
Skipped loading parameter module.scale_attn.bn1.bias
Skipped loading parameter module.scale_attn.bn1.running_mean
Skipped loading parameter module.scale_attn.bn1.running_var
Skipped loading parameter module.scale_attn.bn1.num_batches_tracked
Skipped loading parameter module.scale_attn.conv2.weight
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0

Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0

[epoch 0], [iter 1 / 744], [train main loss -0.699507], [lr 0.005000] [batchtime 0]
[epoch 0], [iter 2 / 744], [train main loss 4.613508], [lr 0.005000] [batchtime 0]
[epoch 0], [iter 3 / 744], [train main loss 5.689225], [lr 0.005000] [batchtime 0]
[epoch 0], [iter 4 / 744], [train main loss 6.711514], [lr 0.005000] [batchtime 0]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
[epoch 0], [iter 5 / 744], [train main loss 5.195543], [lr 0.005000] [batchtime 0]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
[epoch 0], [iter 6 / 744], [train main loss 4.135168], [lr 0.005000] [batchtime 0]
[epoch 0], [iter 7 / 744], [train main loss 4.655948], [lr 0.005000] [batchtime 0]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0



[epoch 0], [iter 8 / 744], [train main loss 4.193871], [lr 0.005000] [batchtime 0]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0


[epoch 0], [iter 9 / 744], [train main loss 2.555196], [lr 0.005000] [batchtime 0]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
[epoch 0], [iter 10 / 744], [train main loss 1.696174], [lr 0.005000] [batchtime 0]
[epoch 0], [iter 11 / 744], [train main loss 1.669421], [lr 0.005000] [batchtime 1.12]
[epoch 0], [iter 12 / 744], [train main loss 1.522224], [lr 0.005000] [batchtime 1.12]
[epoch 0], [iter 13 / 744], [train main loss 1.137958], [lr 0.005000] [batchtime 1.12]
[epoch 0], [iter 14 / 744], [train main loss 0.886346], [lr 0.005000] [batchtime 1.12]
[epoch 0], [iter 15 / 744], [train main loss 0.825522], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 16 / 744], [train main loss 0.507314], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 17 / 744], [train main loss 0.393363], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 18 / 744], [train main loss -0.011102], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 19 / 744], [train main loss -0.520919], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 20 / 744], [train main loss -0.653416], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 21 / 744], [train main loss -0.802839], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 22 / 744], [train main loss -1.060418], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 23 / 744], [train main loss -1.354372], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 24 / 744], [train main loss -1.777316], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 25 / 744], [train main loss -1.946318], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 26 / 744], [train main loss -1.843279], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 27 / 744], [train main loss -2.384721], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 28 / 744], [train main loss -2.604288], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 29 / 744], [train main loss -2.977418], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 30 / 744], [train main loss -3.253728], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 31 / 744], [train main loss -3.343006], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 32 / 744], [train main loss -3.419271], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 33 / 744], [train main loss -3.671551], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 34 / 744], [train main loss -3.894133], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 35 / 744], [train main loss -3.915936], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 36 / 744], [train main loss -3.976864], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 37 / 744], [train main loss -4.104237], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 38 / 744], [train main loss -4.190474], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 39 / 744], [train main loss -4.204251], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 40 / 744], [train main loss -4.236112], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 41 / 744], [train main loss -4.305362], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 42 / 744], [train main loss -4.415414], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 43 / 744], [train main loss -4.414862], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 44 / 744], [train main loss -4.578368], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 45 / 744], [train main loss -4.683126], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 46 / 744], [train main loss -4.721082], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 47 / 744], [train main loss -4.749209], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 48 / 744], [train main loss -4.936052], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 49 / 744], [train main loss -5.107200], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 50 / 744], [train main loss -5.236364], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 51 / 744], [train main loss -5.279151], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 52 / 744], [train main loss -5.382968], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 53 / 744], [train main loss -5.529680], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 54 / 744], [train main loss -5.674553], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 55 / 744], [train main loss -5.763981], [lr 0.005000] [batchtime 1.13]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0

Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0[epoch 0], [iter 56 / 744], [train main loss -5.789592], [lr 0.005000] [batchtime 1.13]

Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0
[epoch 0], [iter 57 / 744], [train main loss -5.782153], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 58 / 744], [train main loss -5.804476], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 59 / 744], [train main loss -5.799185], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 60 / 744], [train main loss -5.847747], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 61 / 744], [train main loss -5.915163], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 62 / 744], [train main loss -5.865306], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 63 / 744], [train main loss -5.850460], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 64 / 744], [train main loss -5.874552], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 65 / 744], [train main loss -5.880789], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 66 / 744], [train main loss -5.832515], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 67 / 744], [train main loss -5.848516], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 68 / 744], [train main loss -5.851528], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 69 / 744], [train main loss -5.929916], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 70 / 744], [train main loss -5.947170], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 71 / 744], [train main loss -6.008299], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 72 / 744], [train main loss -5.978098], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 73 / 744], [train main loss -6.010966], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 74 / 744], [train main loss -6.040126], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 75 / 744], [train main loss -6.138464], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 76 / 744], [train main loss -6.165876], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 77 / 744], [train main loss -6.112259], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 78 / 744], [train main loss -6.246157], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 79 / 744], [train main loss -6.217512], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 80 / 744], [train main loss -6.293740], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 81 / 744], [train main loss -6.315813], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 82 / 744], [train main loss -6.406532], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 83 / 744], [train main loss -6.481228], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 84 / 744], [train main loss -6.501983], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 85 / 744], [train main loss -6.479106], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 86 / 744], [train main loss -6.486115], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 87 / 744], [train main loss -6.529532], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 88 / 744], [train main loss -6.579721], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 89 / 744], [train main loss -6.632875], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 90 / 744], [train main loss -6.678919], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 91 / 744], [train main loss -6.563315], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 92 / 744], [train main loss -6.562075], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 93 / 744], [train main loss -6.584380], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 94 / 744], [train main loss -6.607395], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 95 / 744], [train main loss -6.646596], [lr 0.005000] [batchtime 1.13]
[epoch 0], [iter 96 / 744], [train main loss -6.707632], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 97 / 744], [train main loss -6.694682], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 98 / 744], [train main loss -6.666947], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 99 / 744], [train main loss -6.614296], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 100 / 744], [train main loss -6.640263], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 101 / 744], [train main loss -6.643342], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 102 / 744], [train main loss -6.647604], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 103 / 744], [train main loss -6.630574], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 104 / 744], [train main loss -6.629654], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 105 / 744], [train main loss -6.588062], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 106 / 744], [train main loss -6.630402], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 107 / 744], [train main loss -6.646655], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 108 / 744], [train main loss -6.664715], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 109 / 744], [train main loss -6.665702], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 110 / 744], [train main loss -6.653124], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 111 / 744], [train main loss -6.616892], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 112 / 744], [train main loss -6.624287], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 113 / 744], [train main loss -6.654572], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 114 / 744], [train main loss -6.658421], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 115 / 744], [train main loss -6.670886], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 116 / 744], [train main loss -6.681060], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 117 / 744], [train main loss -6.694766], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 118 / 744], [train main loss -6.714351], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 119 / 744], [train main loss -6.768991], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 120 / 744], [train main loss -6.755674], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 121 / 744], [train main loss -6.755665], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 122 / 744], [train main loss -6.746688], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 123 / 744], [train main loss -6.797618], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 124 / 744], [train main loss -6.771493], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 125 / 744], [train main loss -6.779455], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 126 / 744], [train main loss -6.780639], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 127 / 744], [train main loss -6.784911], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 128 / 744], [train main loss -6.773858], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 129 / 744], [train main loss -6.805054], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 130 / 744], [train main loss -6.794364], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 131 / 744], [train main loss -6.807905], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 132 / 744], [train main loss -6.846376], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 133 / 744], [train main loss -6.907498], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 134 / 744], [train main loss -6.880628], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 135 / 744], [train main loss -6.869070], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 136 / 744], [train main loss -6.902929], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 137 / 744], [train main loss -6.916294], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 138 / 744], [train main loss -6.881042], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 139 / 744], [train main loss -6.898732], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 140 / 744], [train main loss -6.914895], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 141 / 744], [train main loss -6.933414], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 142 / 744], [train main loss -6.986362], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 143 / 744], [train main loss -6.991324], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 144 / 744], [train main loss -6.981033], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 145 / 744], [train main loss -7.006547], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 146 / 744], [train main loss -7.020582], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 147 / 744], [train main loss -7.050994], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 148 / 744], [train main loss -7.058997], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 149 / 744], [train main loss -7.036370], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 150 / 744], [train main loss -7.033402], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 151 / 744], [train main loss -7.022786], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 152 / 744], [train main loss -6.998121], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 153 / 744], [train main loss -7.006508], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 154 / 744], [train main loss -7.032806], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 155 / 744], [train main loss -7.028879], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 156 / 744], [train main loss -7.095301], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 157 / 744], [train main loss -7.083002], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 158 / 744], [train main loss -7.102612], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 159 / 744], [train main loss -7.105386], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 160 / 744], [train main loss -7.131437], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 161 / 744], [train main loss -7.162349], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 162 / 744], [train main loss -7.135895], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 163 / 744], [train main loss -7.120726], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 164 / 744], [train main loss -7.107450], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 165 / 744], [train main loss -7.159953], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 166 / 744], [train main loss -7.159213], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 167 / 744], [train main loss -7.168372], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 168 / 744], [train main loss -7.155836], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 169 / 744], [train main loss -7.146359], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 170 / 744], [train main loss -7.133953], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 171 / 744], [train main loss -7.136045], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 172 / 744], [train main loss -7.178346], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 173 / 744], [train main loss -7.183319], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 174 / 744], [train main loss -7.184194], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 175 / 744], [train main loss -7.204601], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 176 / 744], [train main loss -7.199697], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 177 / 744], [train main loss -7.191624], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 178 / 744], [train main loss -7.201492], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 179 / 744], [train main loss -7.177874], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 180 / 744], [train main loss -7.198654], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 181 / 744], [train main loss -7.169688], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 182 / 744], [train main loss -7.173967], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 183 / 744], [train main loss -7.155149], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 184 / 744], [train main loss -7.133708], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 185 / 744], [train main loss -7.177969], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 186 / 744], [train main loss -7.205628], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 187 / 744], [train main loss -7.201740], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 188 / 744], [train main loss -7.198256], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 189 / 744], [train main loss -7.207922], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 190 / 744], [train main loss -7.221692], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 191 / 744], [train main loss -7.221591], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 192 / 744], [train main loss -7.203180], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 193 / 744], [train main loss -7.194241], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 194 / 744], [train main loss -7.206522], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 195 / 744], [train main loss -7.205594], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 196 / 744], [train main loss -7.189736], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 197 / 744], [train main loss -7.203941], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 198 / 744], [train main loss -7.198128], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 199 / 744], [train main loss -7.234802], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 200 / 744], [train main loss -7.211924], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 201 / 744], [train main loss -7.262229], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 202 / 744], [train main loss -7.266829], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 203 / 744], [train main loss -7.246518], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 204 / 744], [train main loss -7.246119], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 205 / 744], [train main loss -7.237292], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 206 / 744], [train main loss -7.232228], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 207 / 744], [train main loss -7.233097], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 208 / 744], [train main loss -7.220199], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 209 / 744], [train main loss -7.216711], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 210 / 744], [train main loss -7.210739], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 211 / 744], [train main loss -7.211962], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 212 / 744], [train main loss -7.231452], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 213 / 744], [train main loss -7.251749], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 214 / 744], [train main loss -7.255939], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 215 / 744], [train main loss -7.294897], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 216 / 744], [train main loss -7.286920], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 217 / 744], [train main loss -7.312850], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 218 / 744], [train main loss -7.320927], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 219 / 744], [train main loss -7.315888], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 220 / 744], [train main loss -7.311549], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 221 / 744], [train main loss -7.301798], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 222 / 744], [train main loss -7.303932], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 223 / 744], [train main loss -7.314445], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 224 / 744], [train main loss -7.313900], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 225 / 744], [train main loss -7.298321], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 226 / 744], [train main loss -7.323831], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 227 / 744], [train main loss -7.322986], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 228 / 744], [train main loss -7.326057], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 229 / 744], [train main loss -7.325715], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 230 / 744], [train main loss -7.354379], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 231 / 744], [train main loss -7.345007], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 232 / 744], [train main loss -7.346254], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 233 / 744], [train main loss -7.355493], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 234 / 744], [train main loss -7.379266], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 235 / 744], [train main loss -7.369264], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 236 / 744], [train main loss -7.385601], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 237 / 744], [train main loss -7.371547], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 238 / 744], [train main loss -7.386686], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 239 / 744], [train main loss -7.404981], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 240 / 744], [train main loss -7.415210], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 241 / 744], [train main loss -7.429799], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 242 / 744], [train main loss -7.421005], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 243 / 744], [train main loss -7.412961], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 244 / 744], [train main loss -7.455995], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 245 / 744], [train main loss -7.438242], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 246 / 744], [train main loss -7.446069], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 247 / 744], [train main loss -7.459588], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 248 / 744], [train main loss -7.464689], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 249 / 744], [train main loss -7.459719], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 250 / 744], [train main loss -7.491455], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 251 / 744], [train main loss -7.492370], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 252 / 744], [train main loss -7.510012], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 253 / 744], [train main loss -7.508699], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 254 / 744], [train main loss -7.520150], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 255 / 744], [train main loss -7.538722], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 256 / 744], [train main loss -7.542727], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 257 / 744], [train main loss -7.532149], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 258 / 744], [train main loss -7.514724], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 259 / 744], [train main loss -7.544107], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 260 / 744], [train main loss -7.556449], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 261 / 744], [train main loss -7.568551], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 262 / 744], [train main loss -7.587360], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 263 / 744], [train main loss -7.574823], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 264 / 744], [train main loss -7.588257], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 265 / 744], [train main loss -7.586915], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 266 / 744], [train main loss -7.599407], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 267 / 744], [train main loss -7.593770], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 268 / 744], [train main loss -7.599875], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 269 / 744], [train main loss -7.600293], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 270 / 744], [train main loss -7.610860], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 271 / 744], [train main loss -7.594437], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 272 / 744], [train main loss -7.593225], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 273 / 744], [train main loss -7.581288], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 274 / 744], [train main loss -7.586869], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 275 / 744], [train main loss -7.586004], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 276 / 744], [train main loss -7.583994], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 277 / 744], [train main loss -7.580457], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 278 / 744], [train main loss -7.593409], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 279 / 744], [train main loss -7.592197], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 280 / 744], [train main loss -7.595099], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 281 / 744], [train main loss -7.590724], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 282 / 744], [train main loss -7.590052], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 283 / 744], [train main loss -7.592137], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 284 / 744], [train main loss -7.571525], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 285 / 744], [train main loss -7.568037], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 286 / 744], [train main loss -7.569259], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 287 / 744], [train main loss -7.560587], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 288 / 744], [train main loss -7.551405], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 289 / 744], [train main loss -7.555743], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 290 / 744], [train main loss -7.555294], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 291 / 744], [train main loss -7.559065], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 292 / 744], [train main loss -7.568808], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 293 / 744], [train main loss -7.581601], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 294 / 744], [train main loss -7.587687], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 295 / 744], [train main loss -7.589652], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 296 / 744], [train main loss -7.599086], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 297 / 744], [train main loss -7.603457], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 298 / 744], [train main loss -7.582114], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 299 / 744], [train main loss -7.592612], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 300 / 744], [train main loss -7.578469], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 301 / 744], [train main loss -7.625292], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 302 / 744], [train main loss -7.616803], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 303 / 744], [train main loss -7.630092], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 304 / 744], [train main loss -7.625550], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 305 / 744], [train main loss -7.634829], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 306 / 744], [train main loss -7.641621], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 307 / 744], [train main loss -7.646037], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 308 / 744], [train main loss -7.647191], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 309 / 744], [train main loss -7.658968], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 310 / 744], [train main loss -7.655606], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 311 / 744], [train main loss -7.653638], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 312 / 744], [train main loss -7.634277], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 313 / 744], [train main loss -7.636683], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 314 / 744], [train main loss -7.622206], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 315 / 744], [train main loss -7.617587], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 316 / 744], [train main loss -7.607406], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 317 / 744], [train main loss -7.639567], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 318 / 744], [train main loss -7.645465], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 319 / 744], [train main loss -7.636573], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 320 / 744], [train main loss -7.639990], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 321 / 744], [train main loss -7.647581], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 322 / 744], [train main loss -7.645447], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 323 / 744], [train main loss -7.628921], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 324 / 744], [train main loss -7.629294], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 325 / 744], [train main loss -7.640477], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 326 / 744], [train main loss -7.648672], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 327 / 744], [train main loss -7.667582], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 328 / 744], [train main loss -7.673005], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 329 / 744], [train main loss -7.664369], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 330 / 744], [train main loss -7.675877], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 331 / 744], [train main loss -7.669549], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 332 / 744], [train main loss -7.672622], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 333 / 744], [train main loss -7.663839], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 334 / 744], [train main loss -7.669928], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 335 / 744], [train main loss -7.682033], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 336 / 744], [train main loss -7.694505], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 337 / 744], [train main loss -7.696888], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 338 / 744], [train main loss -7.695361], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 339 / 744], [train main loss -7.685090], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 340 / 744], [train main loss -7.679274], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 341 / 744], [train main loss -7.689870], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 342 / 744], [train main loss -7.685480], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 343 / 744], [train main loss -7.690817], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 344 / 744], [train main loss -7.686245], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 345 / 744], [train main loss -7.679479], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 346 / 744], [train main loss -7.688678], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 347 / 744], [train main loss -7.687144], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 348 / 744], [train main loss -7.671363], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 349 / 744], [train main loss -7.669323], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 350 / 744], [train main loss -7.666830], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 351 / 744], [train main loss -7.676998], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 352 / 744], [train main loss -7.673156], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 353 / 744], [train main loss -7.678497], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 354 / 744], [train main loss -7.683424], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 355 / 744], [train main loss -7.672894], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 356 / 744], [train main loss -7.668971], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 357 / 744], [train main loss -7.668374], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 358 / 744], [train main loss -7.662704], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 359 / 744], [train main loss -7.665685], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 360 / 744], [train main loss -7.670804], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 361 / 744], [train main loss -7.670357], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 362 / 744], [train main loss -7.663241], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 363 / 744], [train main loss -7.666686], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 364 / 744], [train main loss -7.669113], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 365 / 744], [train main loss -7.663691], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 366 / 744], [train main loss -7.663934], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 367 / 744], [train main loss -7.657813], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 368 / 744], [train main loss -7.662471], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 369 / 744], [train main loss -7.659797], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 370 / 744], [train main loss -7.660786], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 371 / 744], [train main loss -7.660401], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 372 / 744], [train main loss -7.657044], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 373 / 744], [train main loss -7.666956], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 374 / 744], [train main loss -7.672705], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 375 / 744], [train main loss -7.685687], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 376 / 744], [train main loss -7.687057], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 377 / 744], [train main loss -7.687777], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 378 / 744], [train main loss -7.697758], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 379 / 744], [train main loss -7.707898], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 380 / 744], [train main loss -7.713498], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 381 / 744], [train main loss -7.727084], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 382 / 744], [train main loss -7.744222], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 383 / 744], [train main loss -7.736832], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 384 / 744], [train main loss -7.721657], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 385 / 744], [train main loss -7.708638], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 386 / 744], [train main loss -7.705960], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 387 / 744], [train main loss -7.697256], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 388 / 744], [train main loss -7.690193], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 389 / 744], [train main loss -7.685136], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 390 / 744], [train main loss -7.681858], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 391 / 744], [train main loss -7.684651], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 392 / 744], [train main loss -7.682047], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 393 / 744], [train main loss -7.686627], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 394 / 744], [train main loss -7.703732], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 395 / 744], [train main loss -7.693950], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 396 / 744], [train main loss -7.691647], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 397 / 744], [train main loss -7.686525], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 398 / 744], [train main loss -7.683222], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 399 / 744], [train main loss -7.689735], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 400 / 744], [train main loss -7.672002], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 401 / 744], [train main loss -7.678909], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 402 / 744], [train main loss -7.672881], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 403 / 744], [train main loss -7.669642], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 404 / 744], [train main loss -7.681788], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 405 / 744], [train main loss -7.669948], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 406 / 744], [train main loss -7.653193], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 407 / 744], [train main loss -7.653705], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 408 / 744], [train main loss -7.656131], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 409 / 744], [train main loss -7.657739], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 410 / 744], [train main loss -7.662704], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 411 / 744], [train main loss -7.663333], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 412 / 744], [train main loss -7.659722], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 413 / 744], [train main loss -7.659102], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 414 / 744], [train main loss -7.666776], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 415 / 744], [train main loss -7.665999], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 416 / 744], [train main loss -7.664542], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 417 / 744], [train main loss -7.674552], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 418 / 744], [train main loss -7.680519], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 419 / 744], [train main loss -7.672761], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 420 / 744], [train main loss -7.673363], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 421 / 744], [train main loss -7.667418], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 422 / 744], [train main loss -7.667685], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 423 / 744], [train main loss -7.661157], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 424 / 744], [train main loss -7.655187], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 425 / 744], [train main loss -7.643047], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 426 / 744], [train main loss -7.651253], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 427 / 744], [train main loss -7.660642], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 428 / 744], [train main loss -7.663742], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 429 / 744], [train main loss -7.662759], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 430 / 744], [train main loss -7.660522], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 431 / 744], [train main loss -7.662083], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 432 / 744], [train main loss -7.660757], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 433 / 744], [train main loss -7.657294], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 434 / 744], [train main loss -7.656703], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 435 / 744], [train main loss -7.658977], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 436 / 744], [train main loss -7.657769], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 437 / 744], [train main loss -7.653503], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 438 / 744], [train main loss -7.667875], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 439 / 744], [train main loss -7.665454], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 440 / 744], [train main loss -7.652386], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 441 / 744], [train main loss -7.642404], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 442 / 744], [train main loss -7.641819], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 443 / 744], [train main loss -7.652103], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 444 / 744], [train main loss -7.647405], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 445 / 744], [train main loss -7.642008], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 446 / 744], [train main loss -7.639853], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 447 / 744], [train main loss -7.645091], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 448 / 744], [train main loss -7.658765], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 449 / 744], [train main loss -7.651370], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 450 / 744], [train main loss -7.649292], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 451 / 744], [train main loss -7.650856], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 452 / 744], [train main loss -7.649451], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 453 / 744], [train main loss -7.651734], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 454 / 744], [train main loss -7.646748], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 455 / 744], [train main loss -7.644016], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 456 / 744], [train main loss -7.632527], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 457 / 744], [train main loss -7.625211], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 458 / 744], [train main loss -7.624831], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 459 / 744], [train main loss -7.624605], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 460 / 744], [train main loss -7.634701], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 461 / 744], [train main loss -7.637705], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 462 / 744], [train main loss -7.638384], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 463 / 744], [train main loss -7.649481], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 464 / 744], [train main loss -7.647727], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 465 / 744], [train main loss -7.630634], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 466 / 744], [train main loss -7.629134], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 467 / 744], [train main loss -7.638275], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 468 / 744], [train main loss -7.637163], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 469 / 744], [train main loss -7.659454], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 470 / 744], [train main loss -7.663850], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 471 / 744], [train main loss -7.661529], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 472 / 744], [train main loss -7.659630], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 473 / 744], [train main loss -7.658174], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 474 / 744], [train main loss -7.667663], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 475 / 744], [train main loss -7.675489], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 476 / 744], [train main loss -7.681386], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 477 / 744], [train main loss -7.682671], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 478 / 744], [train main loss -7.691348], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 479 / 744], [train main loss -7.694526], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 480 / 744], [train main loss -7.703373], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 481 / 744], [train main loss -7.700435], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 482 / 744], [train main loss -7.701531], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 483 / 744], [train main loss -7.697892], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 484 / 744], [train main loss -7.701365], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 485 / 744], [train main loss -7.710062], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 486 / 744], [train main loss -7.704374], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 487 / 744], [train main loss -7.700557], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 488 / 744], [train main loss -7.704375], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 489 / 744], [train main loss -7.708298], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 490 / 744], [train main loss -7.702145], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 491 / 744], [train main loss -7.697675], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 492 / 744], [train main loss -7.689968], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 493 / 744], [train main loss -7.678193], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 494 / 744], [train main loss -7.678634], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 495 / 744], [train main loss -7.681479], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 496 / 744], [train main loss -7.679643], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 497 / 744], [train main loss -7.682887], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 498 / 744], [train main loss -7.681871], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 499 / 744], [train main loss -7.682715], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 500 / 744], [train main loss -7.693092], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 501 / 744], [train main loss -7.698420], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 502 / 744], [train main loss -7.703216], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 503 / 744], [train main loss -7.693913], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 504 / 744], [train main loss -7.695509], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 505 / 744], [train main loss -7.685774], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 506 / 744], [train main loss -7.698589], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 507 / 744], [train main loss -7.693841], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 508 / 744], [train main loss -7.693270], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 509 / 744], [train main loss -7.700218], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 510 / 744], [train main loss -7.703217], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 511 / 744], [train main loss -7.702316], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 512 / 744], [train main loss -7.699347], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 513 / 744], [train main loss -7.686779], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 514 / 744], [train main loss -7.681309], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 515 / 744], [train main loss -7.676621], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 516 / 744], [train main loss -7.683818], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 517 / 744], [train main loss -7.693305], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 518 / 744], [train main loss -7.687617], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 519 / 744], [train main loss -7.687491], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 520 / 744], [train main loss -7.691571], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 521 / 744], [train main loss -7.689499], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 522 / 744], [train main loss -7.701045], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 523 / 744], [train main loss -7.702783], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 524 / 744], [train main loss -7.703125], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 525 / 744], [train main loss -7.690526], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 526 / 744], [train main loss -7.687430], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 527 / 744], [train main loss -7.686173], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 528 / 744], [train main loss -7.687739], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 529 / 744], [train main loss -7.692076], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 530 / 744], [train main loss -7.694986], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 531 / 744], [train main loss -7.693290], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 532 / 744], [train main loss -7.693423], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 533 / 744], [train main loss -7.694046], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 534 / 744], [train main loss -7.685766], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 535 / 744], [train main loss -7.684724], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 536 / 744], [train main loss -7.674715], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 537 / 744], [train main loss -7.684632], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 538 / 744], [train main loss -7.692162], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 539 / 744], [train main loss -7.691817], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 540 / 744], [train main loss -7.694410], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 541 / 744], [train main loss -7.703513], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 542 / 744], [train main loss -7.696080], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 543 / 744], [train main loss -7.694420], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 544 / 744], [train main loss -7.682365], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 545 / 744], [train main loss -7.684637], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 546 / 744], [train main loss -7.686669], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 547 / 744], [train main loss -7.683748], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 548 / 744], [train main loss -7.691064], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 549 / 744], [train main loss -7.707519], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 550 / 744], [train main loss -7.716390], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 551 / 744], [train main loss -7.711500], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 552 / 744], [train main loss -7.718178], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 553 / 744], [train main loss -7.718551], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 554 / 744], [train main loss -7.722398], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 555 / 744], [train main loss -7.717867], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 556 / 744], [train main loss -7.721784], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 557 / 744], [train main loss -7.724391], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 558 / 744], [train main loss -7.717540], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 559 / 744], [train main loss -7.719974], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 560 / 744], [train main loss -7.719486], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 561 / 744], [train main loss -7.726463], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 562 / 744], [train main loss -7.729525], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 563 / 744], [train main loss -7.724333], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 564 / 744], [train main loss -7.740226], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 565 / 744], [train main loss -7.746760], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 566 / 744], [train main loss -7.753056], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 567 / 744], [train main loss -7.748097], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 568 / 744], [train main loss -7.746369], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 569 / 744], [train main loss -7.750845], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 570 / 744], [train main loss -7.762925], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 571 / 744], [train main loss -7.763477], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 572 / 744], [train main loss -7.768493], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 573 / 744], [train main loss -7.772883], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 574 / 744], [train main loss -7.766137], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 575 / 744], [train main loss -7.765024], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 576 / 744], [train main loss -7.761944], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 577 / 744], [train main loss -7.752942], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 578 / 744], [train main loss -7.770324], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 579 / 744], [train main loss -7.776548], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 580 / 744], [train main loss -7.764810], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 581 / 744], [train main loss -7.759123], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 582 / 744], [train main loss -7.771172], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 583 / 744], [train main loss -7.774610], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 584 / 744], [train main loss -7.772284], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 585 / 744], [train main loss -7.782909], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 586 / 744], [train main loss -7.776300], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 587 / 744], [train main loss -7.781422], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 588 / 744], [train main loss -7.779928], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 589 / 744], [train main loss -7.775950], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 590 / 744], [train main loss -7.774342], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 591 / 744], [train main loss -7.779163], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 592 / 744], [train main loss -7.782828], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 593 / 744], [train main loss -7.791767], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 594 / 744], [train main loss -7.792957], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 595 / 744], [train main loss -7.786910], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 596 / 744], [train main loss -7.790060], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 597 / 744], [train main loss -7.790865], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 598 / 744], [train main loss -7.788768], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 599 / 744], [train main loss -7.783144], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 600 / 744], [train main loss -7.778049], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 601 / 744], [train main loss -7.780497], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 602 / 744], [train main loss -7.790128], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 603 / 744], [train main loss -7.791776], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 604 / 744], [train main loss -7.788165], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 605 / 744], [train main loss -7.783088], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 606 / 744], [train main loss -7.780908], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 607 / 744], [train main loss -7.787779], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 608 / 744], [train main loss -7.793254], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 609 / 744], [train main loss -7.791746], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 610 / 744], [train main loss -7.793200], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 611 / 744], [train main loss -7.791003], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 612 / 744], [train main loss -7.798929], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 613 / 744], [train main loss -7.796551], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 614 / 744], [train main loss -7.807714], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 615 / 744], [train main loss -7.801849], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 616 / 744], [train main loss -7.805154], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 617 / 744], [train main loss -7.799878], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 618 / 744], [train main loss -7.802065], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 619 / 744], [train main loss -7.808776], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 620 / 744], [train main loss -7.811929], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 621 / 744], [train main loss -7.811756], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 622 / 744], [train main loss -7.816178], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 623 / 744], [train main loss -7.811781], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 624 / 744], [train main loss -7.814485], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 625 / 744], [train main loss -7.814026], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 626 / 744], [train main loss -7.815725], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 627 / 744], [train main loss -7.804592], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 628 / 744], [train main loss -7.808491], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 629 / 744], [train main loss -7.806540], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 630 / 744], [train main loss -7.803612], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 631 / 744], [train main loss -7.816502], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 632 / 744], [train main loss -7.822643], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 633 / 744], [train main loss -7.823973], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 634 / 744], [train main loss -7.815085], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 635 / 744], [train main loss -7.807862], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 636 / 744], [train main loss -7.802512], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 637 / 744], [train main loss -7.801154], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 638 / 744], [train main loss -7.800918], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 639 / 744], [train main loss -7.802348], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 640 / 744], [train main loss -7.802645], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 641 / 744], [train main loss -7.807944], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 642 / 744], [train main loss -7.812265], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 643 / 744], [train main loss -7.813090], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 644 / 744], [train main loss -7.811938], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 645 / 744], [train main loss -7.806878], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 646 / 744], [train main loss -7.814470], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 647 / 744], [train main loss -7.818072], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 648 / 744], [train main loss -7.819813], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 649 / 744], [train main loss -7.822896], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 650 / 744], [train main loss -7.823309], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 651 / 744], [train main loss -7.825866], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 652 / 744], [train main loss -7.822999], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 653 / 744], [train main loss -7.829428], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 654 / 744], [train main loss -7.833229], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 655 / 744], [train main loss -7.836093], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 656 / 744], [train main loss -7.835513], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 657 / 744], [train main loss -7.838579], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 658 / 744], [train main loss -7.835822], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 659 / 744], [train main loss -7.839279], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 660 / 744], [train main loss -7.829966], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 661 / 744], [train main loss -7.830280], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 662 / 744], [train main loss -7.844899], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 663 / 744], [train main loss -7.845694], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 664 / 744], [train main loss -7.844416], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 665 / 744], [train main loss -7.845955], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 666 / 744], [train main loss -7.852531], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 667 / 744], [train main loss -7.843899], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 668 / 744], [train main loss -7.844909], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 669 / 744], [train main loss -7.843210], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 670 / 744], [train main loss -7.842072], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 671 / 744], [train main loss -7.845540], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 672 / 744], [train main loss -7.848880], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 673 / 744], [train main loss -7.848851], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 674 / 744], [train main loss -7.862449], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 675 / 744], [train main loss -7.869757], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 676 / 744], [train main loss -7.865177], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 677 / 744], [train main loss -7.862893], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 678 / 744], [train main loss -7.855988], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 679 / 744], [train main loss -7.855849], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 680 / 744], [train main loss -7.851478], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 681 / 744], [train main loss -7.852515], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 682 / 744], [train main loss -7.854851], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 683 / 744], [train main loss -7.851700], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 684 / 744], [train main loss -7.843168], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 685 / 744], [train main loss -7.856862], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 686 / 744], [train main loss -7.864114], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 687 / 744], [train main loss -7.870947], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 688 / 744], [train main loss -7.864201], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 689 / 744], [train main loss -7.863299], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 690 / 744], [train main loss -7.855769], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 691 / 744], [train main loss -7.851283], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 692 / 744], [train main loss -7.854383], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 693 / 744], [train main loss -7.846311], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 694 / 744], [train main loss -7.853499], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 695 / 744], [train main loss -7.844668], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 696 / 744], [train main loss -7.846866], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 697 / 744], [train main loss -7.854581], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 698 / 744], [train main loss -7.853710], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 699 / 744], [train main loss -7.856006], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 700 / 744], [train main loss -7.854896], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 701 / 744], [train main loss -7.847515], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 702 / 744], [train main loss -7.844771], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 703 / 744], [train main loss -7.842515], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 704 / 744], [train main loss -7.844593], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 705 / 744], [train main loss -7.846230], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 706 / 744], [train main loss -7.845197], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 707 / 744], [train main loss -7.848874], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 708 / 744], [train main loss -7.854127], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 709 / 744], [train main loss -7.858373], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 710 / 744], [train main loss -7.862057], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 711 / 744], [train main loss -7.870172], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 712 / 744], [train main loss -7.877511], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 713 / 744], [train main loss -7.879793], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 714 / 744], [train main loss -7.873379], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 715 / 744], [train main loss -7.866809], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 716 / 744], [train main loss -7.866512], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 717 / 744], [train main loss -7.866992], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 718 / 744], [train main loss -7.861340], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 719 / 744], [train main loss -7.868812], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 720 / 744], [train main loss -7.871772], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 721 / 744], [train main loss -7.870057], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 722 / 744], [train main loss -7.866182], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 723 / 744], [train main loss -7.868402], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 724 / 744], [train main loss -7.871092], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 725 / 744], [train main loss -7.867791], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 726 / 744], [train main loss -7.862979], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 727 / 744], [train main loss -7.870657], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 728 / 744], [train main loss -7.870573], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 729 / 744], [train main loss -7.877010], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 730 / 744], [train main loss -7.870536], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 731 / 744], [train main loss -7.870789], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 732 / 744], [train main loss -7.880984], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 733 / 744], [train main loss -7.877638], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 734 / 744], [train main loss -7.878371], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 735 / 744], [train main loss -7.885638], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 736 / 744], [train main loss -7.887065], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 737 / 744], [train main loss -7.887293], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 738 / 744], [train main loss -7.886398], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 739 / 744], [train main loss -7.885767], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 740 / 744], [train main loss -7.882809], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 741 / 744], [train main loss -7.886122], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 742 / 744], [train main loss -7.878006], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 743 / 744], [train main loss -7.876274], [lr 0.005000] [batchtime 1.14]
[epoch 0], [iter 744 / 744], [train main loss -7.878403], [lr 0.005000] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP     FN    Precision    Recall
----  -------------  --------  -----  ----  -----  -----------  --------
   0  road              97.89  37.19  0.01   0.01         0.99      0.99
   1  sidewalk          82.41   4.82  0.12   0.09         0.89      0.92
   2  building          90.80  20.49  0.07   0.03         0.93      0.97
   3  wall              50.25   0.42  0.73   0.26         0.58      0.79
   4  fence             57.95   0.57  0.45   0.28         0.69      0.78
   5  pole              69.11   1.18  0.25   0.19         0.80      0.84
   6  traffic light     72.30   0.17  0.19   0.19         0.84      0.84
   7  traffic sign      76.02   0.53  0.26   0.05         0.79      0.95
   8  vegetation        89.87  16.78  0.03   0.08         0.97      0.93
   9  terrain           50.61   0.69  0.20   0.77         0.83      0.56
  10  sky               92.42   3.28  0.02   0.06         0.98      0.94
  11  person            82.22   1.17  0.11   0.11         0.90      0.90
  12  rider             65.07   0.17  0.30   0.23         0.77      0.81
  13  car               93.66   6.29  0.04   0.03         0.97      0.97
  14  truck             66.95   0.24  0.25   0.25         0.80      0.80
  15  bus               70.04   0.35  0.11   0.32         0.90      0.76
  16  train              3.68   0.01  7.42  18.72         0.12      0.05
  17  motorcycle        53.48   0.06  0.37   0.50         0.73      0.67
  18  bicycle           76.47   0.62  0.14   0.16         0.87      0.86
Mean: 70.59
-----------------------------------------------------------------------------------------------------------
this : [epoch 0], [val loss 0.19903], [acc 0.95022], [acc_cls 0.80791], [mean_iu 0.70590], [fwavacc 0.91191]
best : [epoch 0], [val loss 0.19903], [acc 0.95022], [acc_cls 0.80791], [mean_iu 0.70590], [fwavacc 0.91191]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 1], [iter 1 / 744], [train main loss -11.995914], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 2 / 744], [train main loss -7.484611], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 3 / 744], [train main loss -8.543458], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 4 / 744], [train main loss -8.768178], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 5 / 744], [train main loss -9.761562], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 6 / 744], [train main loss -9.562714], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 7 / 744], [train main loss -9.473032], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 8 / 744], [train main loss -10.503649], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 9 / 744], [train main loss -11.015139], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 10 / 744], [train main loss -10.577456], [lr 0.004943] [batchtime 0]
[epoch 1], [iter 11 / 744], [train main loss -10.136081], [lr 0.004943] [batchtime 1.22]
[epoch 1], [iter 12 / 744], [train main loss -9.522404], [lr 0.004943] [batchtime 1.18]
[epoch 1], [iter 13 / 744], [train main loss -9.325791], [lr 0.004943] [batchtime 1.16]
[epoch 1], [iter 14 / 744], [train main loss -9.228586], [lr 0.004943] [batchtime 1.16]
[epoch 1], [iter 15 / 744], [train main loss -9.095461], [lr 0.004943] [batchtime 1.15]
[epoch 1], [iter 16 / 744], [train main loss -9.243839], [lr 0.004943] [batchtime 1.15]
[epoch 1], [iter 17 / 744], [train main loss -9.020466], [lr 0.004943] [batchtime 1.15]
[epoch 1], [iter 18 / 744], [train main loss -9.133278], [lr 0.004943] [batchtime 1.15]
[epoch 1], [iter 19 / 744], [train main loss -9.140656], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 20 / 744], [train main loss -9.161608], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 21 / 744], [train main loss -9.192367], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 22 / 744], [train main loss -9.217033], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 23 / 744], [train main loss -9.334526], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 24 / 744], [train main loss -9.492816], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 25 / 744], [train main loss -9.437492], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 26 / 744], [train main loss -9.560363], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 27 / 744], [train main loss -9.611140], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 28 / 744], [train main loss -9.469775], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 29 / 744], [train main loss -9.342813], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 30 / 744], [train main loss -9.196965], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 31 / 744], [train main loss -9.125880], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 32 / 744], [train main loss -9.258755], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 33 / 744], [train main loss -9.320488], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 34 / 744], [train main loss -9.279749], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 35 / 744], [train main loss -9.377626], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 36 / 744], [train main loss -9.061578], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 37 / 744], [train main loss -8.970132], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 38 / 744], [train main loss -9.026762], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 39 / 744], [train main loss -8.917293], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 40 / 744], [train main loss -8.874597], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 41 / 744], [train main loss -8.897249], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 42 / 744], [train main loss -8.939617], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 43 / 744], [train main loss -8.937240], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 44 / 744], [train main loss -8.883819], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 45 / 744], [train main loss -8.816090], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 46 / 744], [train main loss -8.714303], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 47 / 744], [train main loss -8.689979], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 48 / 744], [train main loss -8.670516], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 49 / 744], [train main loss -8.699267], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 50 / 744], [train main loss -8.610112], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 51 / 744], [train main loss -8.570091], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 52 / 744], [train main loss -8.484051], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 53 / 744], [train main loss -8.412528], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 54 / 744], [train main loss -8.378811], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 55 / 744], [train main loss -8.350868], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 56 / 744], [train main loss -8.283641], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 57 / 744], [train main loss -8.193727], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 58 / 744], [train main loss -8.176980], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 59 / 744], [train main loss -8.143237], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 60 / 744], [train main loss -8.096673], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 61 / 744], [train main loss -8.070541], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 62 / 744], [train main loss -8.037455], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 63 / 744], [train main loss -7.998456], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 64 / 744], [train main loss -7.953471], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 65 / 744], [train main loss -7.956039], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 66 / 744], [train main loss -8.002666], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 67 / 744], [train main loss -8.025505], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 68 / 744], [train main loss -7.987616], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 69 / 744], [train main loss -7.978938], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 70 / 744], [train main loss -8.017056], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 71 / 744], [train main loss -8.079182], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 72 / 744], [train main loss -8.115797], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 73 / 744], [train main loss -8.156550], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 74 / 744], [train main loss -8.112022], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 75 / 744], [train main loss -8.056210], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 76 / 744], [train main loss -8.127377], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 77 / 744], [train main loss -8.100586], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 78 / 744], [train main loss -8.038609], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 79 / 744], [train main loss -8.076975], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 80 / 744], [train main loss -8.088752], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 81 / 744], [train main loss -8.102616], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 82 / 744], [train main loss -8.156747], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 83 / 744], [train main loss -8.128118], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 84 / 744], [train main loss -8.152200], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 85 / 744], [train main loss -8.157645], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 86 / 744], [train main loss -8.147235], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 87 / 744], [train main loss -8.167669], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 88 / 744], [train main loss -8.131310], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 89 / 744], [train main loss -8.106093], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 90 / 744], [train main loss -8.130492], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 91 / 744], [train main loss -8.140787], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 92 / 744], [train main loss -8.213041], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 93 / 744], [train main loss -8.211879], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 94 / 744], [train main loss -8.191066], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 95 / 744], [train main loss -8.246909], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 96 / 744], [train main loss -8.234322], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 97 / 744], [train main loss -8.234250], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 98 / 744], [train main loss -8.307042], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 99 / 744], [train main loss -8.345442], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 100 / 744], [train main loss -8.365761], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 101 / 744], [train main loss -8.379456], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 102 / 744], [train main loss -8.355787], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 103 / 744], [train main loss -8.376546], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 104 / 744], [train main loss -8.403822], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 105 / 744], [train main loss -8.439215], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 106 / 744], [train main loss -8.437889], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 107 / 744], [train main loss -8.434900], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 108 / 744], [train main loss -8.430093], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 109 / 744], [train main loss -8.473721], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 110 / 744], [train main loss -8.448756], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 111 / 744], [train main loss -8.494016], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 112 / 744], [train main loss -8.470713], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 113 / 744], [train main loss -8.486521], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 114 / 744], [train main loss -8.436856], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 115 / 744], [train main loss -8.462948], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 116 / 744], [train main loss -8.425901], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 117 / 744], [train main loss -8.400876], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 118 / 744], [train main loss -8.438534], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 119 / 744], [train main loss -8.401941], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 120 / 744], [train main loss -8.387835], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 121 / 744], [train main loss -8.386784], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 122 / 744], [train main loss -8.363984], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 123 / 744], [train main loss -8.367913], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 124 / 744], [train main loss -8.374666], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 125 / 744], [train main loss -8.370379], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 126 / 744], [train main loss -8.325644], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 127 / 744], [train main loss -8.323053], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 128 / 744], [train main loss -8.327883], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 129 / 744], [train main loss -8.369233], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 130 / 744], [train main loss -8.367353], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 131 / 744], [train main loss -8.396641], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 132 / 744], [train main loss -8.410121], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 133 / 744], [train main loss -8.414572], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 134 / 744], [train main loss -8.488834], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 135 / 744], [train main loss -8.506353], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 136 / 744], [train main loss -8.487244], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 137 / 744], [train main loss -8.451927], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 138 / 744], [train main loss -8.469029], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 139 / 744], [train main loss -8.436242], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 140 / 744], [train main loss -8.449507], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 141 / 744], [train main loss -8.450136], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 142 / 744], [train main loss -8.451937], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 143 / 744], [train main loss -8.434788], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 144 / 744], [train main loss -8.460043], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 145 / 744], [train main loss -8.459016], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 146 / 744], [train main loss -8.444626], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 147 / 744], [train main loss -8.455944], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 148 / 744], [train main loss -8.454769], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 149 / 744], [train main loss -8.426965], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 150 / 744], [train main loss -8.409647], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 151 / 744], [train main loss -8.385398], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 152 / 744], [train main loss -8.365996], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 153 / 744], [train main loss -8.325000], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 154 / 744], [train main loss -8.327457], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 155 / 744], [train main loss -8.336377], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 156 / 744], [train main loss -8.318320], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 157 / 744], [train main loss -8.274416], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 158 / 744], [train main loss -8.266154], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 159 / 744], [train main loss -8.235245], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 160 / 744], [train main loss -8.218735], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 161 / 744], [train main loss -8.215001], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 162 / 744], [train main loss -8.190713], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 163 / 744], [train main loss -8.200173], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 164 / 744], [train main loss -8.209739], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 165 / 744], [train main loss -8.253245], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 166 / 744], [train main loss -8.201434], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 167 / 744], [train main loss -8.198240], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 168 / 744], [train main loss -8.195005], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 169 / 744], [train main loss -8.186186], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 170 / 744], [train main loss -8.212687], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 171 / 744], [train main loss -8.199591], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 172 / 744], [train main loss -8.190965], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 173 / 744], [train main loss -8.198160], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 174 / 744], [train main loss -8.209315], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 175 / 744], [train main loss -8.232856], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 176 / 744], [train main loss -8.225424], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 177 / 744], [train main loss -8.270407], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 178 / 744], [train main loss -8.280863], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 179 / 744], [train main loss -8.314342], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 180 / 744], [train main loss -8.298439], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 181 / 744], [train main loss -8.304526], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 182 / 744], [train main loss -8.293385], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 183 / 744], [train main loss -8.280529], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 184 / 744], [train main loss -8.286190], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 185 / 744], [train main loss -8.312240], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 186 / 744], [train main loss -8.331874], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 187 / 744], [train main loss -8.317107], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 188 / 744], [train main loss -8.326038], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 189 / 744], [train main loss -8.306341], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 190 / 744], [train main loss -8.280024], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 191 / 744], [train main loss -8.275237], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 192 / 744], [train main loss -8.306535], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 193 / 744], [train main loss -8.302914], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 194 / 744], [train main loss -8.266203], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 195 / 744], [train main loss -8.288870], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 196 / 744], [train main loss -8.283124], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 197 / 744], [train main loss -8.262843], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 198 / 744], [train main loss -8.264807], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 199 / 744], [train main loss -8.260794], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 200 / 744], [train main loss -8.249651], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 201 / 744], [train main loss -8.246977], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 202 / 744], [train main loss -8.229570], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 203 / 744], [train main loss -8.242076], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 204 / 744], [train main loss -8.233233], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 205 / 744], [train main loss -8.240957], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 206 / 744], [train main loss -8.250376], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 207 / 744], [train main loss -8.249849], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 208 / 744], [train main loss -8.238649], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 209 / 744], [train main loss -8.232102], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 210 / 744], [train main loss -8.228641], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 211 / 744], [train main loss -8.242483], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 212 / 744], [train main loss -8.238625], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 213 / 744], [train main loss -8.236981], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 214 / 744], [train main loss -8.267333], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 215 / 744], [train main loss -8.270396], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 216 / 744], [train main loss -8.276222], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 217 / 744], [train main loss -8.286506], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 218 / 744], [train main loss -8.290474], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 219 / 744], [train main loss -8.307965], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 220 / 744], [train main loss -8.285058], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 221 / 744], [train main loss -8.264400], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 222 / 744], [train main loss -8.277752], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 223 / 744], [train main loss -8.287244], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 224 / 744], [train main loss -8.269709], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 225 / 744], [train main loss -8.299480], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 226 / 744], [train main loss -8.305830], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 227 / 744], [train main loss -8.306964], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 228 / 744], [train main loss -8.309588], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 229 / 744], [train main loss -8.280718], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 230 / 744], [train main loss -8.308202], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 231 / 744], [train main loss -8.293230], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 232 / 744], [train main loss -8.287923], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 233 / 744], [train main loss -8.285971], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 234 / 744], [train main loss -8.306179], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 235 / 744], [train main loss -8.306313], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 236 / 744], [train main loss -8.323552], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 237 / 744], [train main loss -8.326458], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 238 / 744], [train main loss -8.309496], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 239 / 744], [train main loss -8.300011], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 240 / 744], [train main loss -8.288512], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 241 / 744], [train main loss -8.293746], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 242 / 744], [train main loss -8.295488], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 243 / 744], [train main loss -8.294991], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 244 / 744], [train main loss -8.309005], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 245 / 744], [train main loss -8.314575], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 246 / 744], [train main loss -8.302417], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 247 / 744], [train main loss -8.297392], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 248 / 744], [train main loss -8.286392], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 249 / 744], [train main loss -8.289909], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 250 / 744], [train main loss -8.274207], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 251 / 744], [train main loss -8.280412], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 252 / 744], [train main loss -8.283996], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 253 / 744], [train main loss -8.283308], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 254 / 744], [train main loss -8.289655], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 255 / 744], [train main loss -8.296333], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 256 / 744], [train main loss -8.299590], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 257 / 744], [train main loss -8.307152], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 258 / 744], [train main loss -8.312913], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 259 / 744], [train main loss -8.328027], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 260 / 744], [train main loss -8.320327], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 261 / 744], [train main loss -8.332754], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 262 / 744], [train main loss -8.333027], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 263 / 744], [train main loss -8.321599], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 264 / 744], [train main loss -8.346170], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 265 / 744], [train main loss -8.351386], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 266 / 744], [train main loss -8.330952], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 267 / 744], [train main loss -8.315028], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 268 / 744], [train main loss -8.312075], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 269 / 744], [train main loss -8.304379], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 270 / 744], [train main loss -8.306100], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 271 / 744], [train main loss -8.308941], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 272 / 744], [train main loss -8.293145], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 273 / 744], [train main loss -8.289771], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 274 / 744], [train main loss -8.298971], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 275 / 744], [train main loss -8.288304], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 276 / 744], [train main loss -8.271021], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 277 / 744], [train main loss -8.272333], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 278 / 744], [train main loss -8.265376], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 279 / 744], [train main loss -8.264261], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 280 / 744], [train main loss -8.268391], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 281 / 744], [train main loss -8.268492], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 282 / 744], [train main loss -8.260549], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 283 / 744], [train main loss -8.257253], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 284 / 744], [train main loss -8.260294], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 285 / 744], [train main loss -8.257564], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 286 / 744], [train main loss -8.269308], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 287 / 744], [train main loss -8.285709], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 288 / 744], [train main loss -8.288656], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 289 / 744], [train main loss -8.302013], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 290 / 744], [train main loss -8.304821], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 291 / 744], [train main loss -8.319620], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 292 / 744], [train main loss -8.317789], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 293 / 744], [train main loss -8.305312], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 294 / 744], [train main loss -8.303270], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 295 / 744], [train main loss -8.296856], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 296 / 744], [train main loss -8.275912], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 297 / 744], [train main loss -8.267276], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 298 / 744], [train main loss -8.268652], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 299 / 744], [train main loss -8.266563], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 300 / 744], [train main loss -8.255065], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 301 / 744], [train main loss -8.262913], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 302 / 744], [train main loss -8.268941], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 303 / 744], [train main loss -8.267935], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 304 / 744], [train main loss -8.266306], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 305 / 744], [train main loss -8.267742], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 306 / 744], [train main loss -8.257108], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 307 / 744], [train main loss -8.261416], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 308 / 744], [train main loss -8.268534], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 309 / 744], [train main loss -8.299242], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 310 / 744], [train main loss -8.309245], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 311 / 744], [train main loss -8.287989], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 312 / 744], [train main loss -8.284559], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 313 / 744], [train main loss -8.275667], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 314 / 744], [train main loss -8.261645], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 315 / 744], [train main loss -8.241665], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 316 / 744], [train main loss -8.241204], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 317 / 744], [train main loss -8.247117], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 318 / 744], [train main loss -8.236929], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 319 / 744], [train main loss -8.226117], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 320 / 744], [train main loss -8.224055], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 321 / 744], [train main loss -8.223158], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 322 / 744], [train main loss -8.226327], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 323 / 744], [train main loss -8.227652], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 324 / 744], [train main loss -8.214332], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 325 / 744], [train main loss -8.207865], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 326 / 744], [train main loss -8.205017], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 327 / 744], [train main loss -8.176759], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 328 / 744], [train main loss -8.188529], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 329 / 744], [train main loss -8.175005], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 330 / 744], [train main loss -8.181039], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 331 / 744], [train main loss -8.177793], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 332 / 744], [train main loss -8.190664], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 333 / 744], [train main loss -8.198261], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 334 / 744], [train main loss -8.201936], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 335 / 744], [train main loss -8.190270], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 336 / 744], [train main loss -8.177949], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 337 / 744], [train main loss -8.187594], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 338 / 744], [train main loss -8.210972], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 339 / 744], [train main loss -8.217868], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 340 / 744], [train main loss -8.216082], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 341 / 744], [train main loss -8.209848], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 342 / 744], [train main loss -8.211914], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 343 / 744], [train main loss -8.219264], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 344 / 744], [train main loss -8.213616], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 345 / 744], [train main loss -8.217667], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 346 / 744], [train main loss -8.208569], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 347 / 744], [train main loss -8.207649], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 348 / 744], [train main loss -8.228640], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 349 / 744], [train main loss -8.231045], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 350 / 744], [train main loss -8.244673], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 351 / 744], [train main loss -8.235654], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 352 / 744], [train main loss -8.223653], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 353 / 744], [train main loss -8.224537], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 354 / 744], [train main loss -8.215696], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 355 / 744], [train main loss -8.231644], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 356 / 744], [train main loss -8.232478], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 357 / 744], [train main loss -8.232760], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 358 / 744], [train main loss -8.223894], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 359 / 744], [train main loss -8.215807], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 360 / 744], [train main loss -8.227428], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 361 / 744], [train main loss -8.209258], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 362 / 744], [train main loss -8.204602], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 363 / 744], [train main loss -8.202927], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 364 / 744], [train main loss -8.211925], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 365 / 744], [train main loss -8.200227], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 366 / 744], [train main loss -8.211009], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 367 / 744], [train main loss -8.198339], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 368 / 744], [train main loss -8.189744], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 369 / 744], [train main loss -8.186600], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 370 / 744], [train main loss -8.208223], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 371 / 744], [train main loss -8.196509], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 372 / 744], [train main loss -8.205713], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 373 / 744], [train main loss -8.209806], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 374 / 744], [train main loss -8.216325], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 375 / 744], [train main loss -8.219329], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 376 / 744], [train main loss -8.210354], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 377 / 744], [train main loss -8.213246], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 378 / 744], [train main loss -8.208294], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 379 / 744], [train main loss -8.211015], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 380 / 744], [train main loss -8.194181], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 381 / 744], [train main loss -8.181802], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 382 / 744], [train main loss -8.186770], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 383 / 744], [train main loss -8.187845], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 384 / 744], [train main loss -8.197555], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 385 / 744], [train main loss -8.199998], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 386 / 744], [train main loss -8.199417], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 387 / 744], [train main loss -8.199073], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 388 / 744], [train main loss -8.202814], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 389 / 744], [train main loss -8.210807], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 390 / 744], [train main loss -8.209248], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 391 / 744], [train main loss -8.221721], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 392 / 744], [train main loss -8.230520], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 393 / 744], [train main loss -8.247788], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 394 / 744], [train main loss -8.247773], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 395 / 744], [train main loss -8.242795], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 396 / 744], [train main loss -8.240409], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 397 / 744], [train main loss -8.236392], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 398 / 744], [train main loss -8.248618], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 399 / 744], [train main loss -8.253884], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 400 / 744], [train main loss -8.272846], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 401 / 744], [train main loss -8.272412], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 402 / 744], [train main loss -8.274536], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 403 / 744], [train main loss -8.273962], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 404 / 744], [train main loss -8.278267], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 405 / 744], [train main loss -8.278831], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 406 / 744], [train main loss -8.279243], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 407 / 744], [train main loss -8.304740], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 408 / 744], [train main loss -8.305907], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 409 / 744], [train main loss -8.306822], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 410 / 744], [train main loss -8.300884], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 411 / 744], [train main loss -8.316617], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 412 / 744], [train main loss -8.311756], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 413 / 744], [train main loss -8.315074], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 414 / 744], [train main loss -8.299873], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 415 / 744], [train main loss -8.311054], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 416 / 744], [train main loss -8.309669], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 417 / 744], [train main loss -8.332829], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 418 / 744], [train main loss -8.325030], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 419 / 744], [train main loss -8.319307], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 420 / 744], [train main loss -8.312569], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 421 / 744], [train main loss -8.302269], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 422 / 744], [train main loss -8.317772], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 423 / 744], [train main loss -8.312564], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 424 / 744], [train main loss -8.315077], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 425 / 744], [train main loss -8.316141], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 426 / 744], [train main loss -8.310173], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 427 / 744], [train main loss -8.307029], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 428 / 744], [train main loss -8.302387], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 429 / 744], [train main loss -8.294027], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 430 / 744], [train main loss -8.289266], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 431 / 744], [train main loss -8.301397], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 432 / 744], [train main loss -8.297654], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 433 / 744], [train main loss -8.299094], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 434 / 744], [train main loss -8.292487], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 435 / 744], [train main loss -8.315809], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 436 / 744], [train main loss -8.309037], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 437 / 744], [train main loss -8.300796], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 438 / 744], [train main loss -8.292910], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 439 / 744], [train main loss -8.306164], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 440 / 744], [train main loss -8.305152], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 441 / 744], [train main loss -8.315594], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 442 / 744], [train main loss -8.316717], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 443 / 744], [train main loss -8.321442], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 444 / 744], [train main loss -8.328298], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 445 / 744], [train main loss -8.321262], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 446 / 744], [train main loss -8.325713], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 447 / 744], [train main loss -8.327398], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 448 / 744], [train main loss -8.324944], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 449 / 744], [train main loss -8.326695], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 450 / 744], [train main loss -8.322887], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 451 / 744], [train main loss -8.338492], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 452 / 744], [train main loss -8.334189], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 453 / 744], [train main loss -8.328965], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 454 / 744], [train main loss -8.328496], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 455 / 744], [train main loss -8.331050], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 456 / 744], [train main loss -8.339828], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 457 / 744], [train main loss -8.338802], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 458 / 744], [train main loss -8.349740], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 459 / 744], [train main loss -8.347478], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 460 / 744], [train main loss -8.361728], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 461 / 744], [train main loss -8.358612], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 462 / 744], [train main loss -8.354171], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 463 / 744], [train main loss -8.343441], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 464 / 744], [train main loss -8.344018], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 465 / 744], [train main loss -8.342954], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 466 / 744], [train main loss -8.336950], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 467 / 744], [train main loss -8.328544], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 468 / 744], [train main loss -8.328990], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 469 / 744], [train main loss -8.322645], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 470 / 744], [train main loss -8.320098], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 471 / 744], [train main loss -8.317599], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 472 / 744], [train main loss -8.307292], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 473 / 744], [train main loss -8.300070], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 474 / 744], [train main loss -8.290104], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 475 / 744], [train main loss -8.281393], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 476 / 744], [train main loss -8.275502], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 477 / 744], [train main loss -8.263323], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 478 / 744], [train main loss -8.267836], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 479 / 744], [train main loss -8.279334], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 480 / 744], [train main loss -8.283582], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 481 / 744], [train main loss -8.288115], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 482 / 744], [train main loss -8.285685], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 483 / 744], [train main loss -8.272846], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 484 / 744], [train main loss -8.275843], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 485 / 744], [train main loss -8.274516], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 486 / 744], [train main loss -8.279916], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 487 / 744], [train main loss -8.273069], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 488 / 744], [train main loss -8.272314], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 489 / 744], [train main loss -8.280854], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 490 / 744], [train main loss -8.283142], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 491 / 744], [train main loss -8.285460], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 492 / 744], [train main loss -8.284647], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 493 / 744], [train main loss -8.295295], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 494 / 744], [train main loss -8.298899], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 495 / 744], [train main loss -8.308752], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 496 / 744], [train main loss -8.306999], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 497 / 744], [train main loss -8.295836], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 498 / 744], [train main loss -8.283402], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 499 / 744], [train main loss -8.281658], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 500 / 744], [train main loss -8.278609], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 501 / 744], [train main loss -8.280402], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 502 / 744], [train main loss -8.281944], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 503 / 744], [train main loss -8.283435], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 504 / 744], [train main loss -8.279363], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 505 / 744], [train main loss -8.271927], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 506 / 744], [train main loss -8.269405], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 507 / 744], [train main loss -8.262111], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 508 / 744], [train main loss -8.270744], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 509 / 744], [train main loss -8.275783], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 510 / 744], [train main loss -8.273648], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 511 / 744], [train main loss -8.269742], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 512 / 744], [train main loss -8.275397], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 513 / 744], [train main loss -8.272043], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 514 / 744], [train main loss -8.275634], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 515 / 744], [train main loss -8.276281], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 516 / 744], [train main loss -8.272137], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 517 / 744], [train main loss -8.272741], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 518 / 744], [train main loss -8.288033], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 519 / 744], [train main loss -8.299001], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 520 / 744], [train main loss -8.297409], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 521 / 744], [train main loss -8.303750], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 522 / 744], [train main loss -8.298363], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 523 / 744], [train main loss -8.296105], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 524 / 744], [train main loss -8.300661], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 525 / 744], [train main loss -8.292788], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 526 / 744], [train main loss -8.287166], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 527 / 744], [train main loss -8.278114], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 528 / 744], [train main loss -8.285614], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 529 / 744], [train main loss -8.274068], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 530 / 744], [train main loss -8.268354], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 531 / 744], [train main loss -8.267401], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 532 / 744], [train main loss -8.251536], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 533 / 744], [train main loss -8.254666], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 534 / 744], [train main loss -8.250549], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 535 / 744], [train main loss -8.245035], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 536 / 744], [train main loss -8.240219], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 537 / 744], [train main loss -8.232853], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 538 / 744], [train main loss -8.229878], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 539 / 744], [train main loss -8.230459], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 540 / 744], [train main loss -8.226397], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 541 / 744], [train main loss -8.218634], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 542 / 744], [train main loss -8.215206], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 543 / 744], [train main loss -8.223306], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 544 / 744], [train main loss -8.229130], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 545 / 744], [train main loss -8.229950], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 546 / 744], [train main loss -8.218764], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 547 / 744], [train main loss -8.210600], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 548 / 744], [train main loss -8.214280], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 549 / 744], [train main loss -8.217925], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 550 / 744], [train main loss -8.226275], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 551 / 744], [train main loss -8.218251], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 552 / 744], [train main loss -8.214139], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 553 / 744], [train main loss -8.214869], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 554 / 744], [train main loss -8.202256], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 555 / 744], [train main loss -8.198331], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 556 / 744], [train main loss -8.194920], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 557 / 744], [train main loss -8.196446], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 558 / 744], [train main loss -8.189519], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 559 / 744], [train main loss -8.206573], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 560 / 744], [train main loss -8.201434], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 561 / 744], [train main loss -8.202705], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 562 / 744], [train main loss -8.195545], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 563 / 744], [train main loss -8.199177], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 564 / 744], [train main loss -8.196253], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 565 / 744], [train main loss -8.206465], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 566 / 744], [train main loss -8.203102], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 567 / 744], [train main loss -8.196385], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 568 / 744], [train main loss -8.193808], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 569 / 744], [train main loss -8.188821], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 570 / 744], [train main loss -8.190070], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 571 / 744], [train main loss -8.179177], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 572 / 744], [train main loss -8.171758], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 573 / 744], [train main loss -8.168033], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 574 / 744], [train main loss -8.185647], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 575 / 744], [train main loss -8.188693], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 576 / 744], [train main loss -8.185716], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 577 / 744], [train main loss -8.183518], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 578 / 744], [train main loss -8.185270], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 579 / 744], [train main loss -8.190188], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 580 / 744], [train main loss -8.184787], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 581 / 744], [train main loss -8.181028], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 582 / 744], [train main loss -8.184533], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 583 / 744], [train main loss -8.191097], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 584 / 744], [train main loss -8.197366], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 585 / 744], [train main loss -8.212159], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 586 / 744], [train main loss -8.223922], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 587 / 744], [train main loss -8.220521], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 588 / 744], [train main loss -8.214952], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 589 / 744], [train main loss -8.220640], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 590 / 744], [train main loss -8.220064], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 591 / 744], [train main loss -8.229733], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 592 / 744], [train main loss -8.234040], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 593 / 744], [train main loss -8.240915], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 594 / 744], [train main loss -8.236277], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 595 / 744], [train main loss -8.242537], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 596 / 744], [train main loss -8.241356], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 597 / 744], [train main loss -8.239832], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 598 / 744], [train main loss -8.243366], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 599 / 744], [train main loss -8.248574], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 600 / 744], [train main loss -8.248534], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 601 / 744], [train main loss -8.257016], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 602 / 744], [train main loss -8.257691], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 603 / 744], [train main loss -8.260705], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 604 / 744], [train main loss -8.257252], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 605 / 744], [train main loss -8.259598], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 606 / 744], [train main loss -8.248965], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 607 / 744], [train main loss -8.245624], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 608 / 744], [train main loss -8.242347], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 609 / 744], [train main loss -8.237992], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 610 / 744], [train main loss -8.234761], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 611 / 744], [train main loss -8.237812], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 612 / 744], [train main loss -8.231182], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 613 / 744], [train main loss -8.232450], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 614 / 744], [train main loss -8.232074], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 615 / 744], [train main loss -8.231783], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 616 / 744], [train main loss -8.230977], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 617 / 744], [train main loss -8.225010], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 618 / 744], [train main loss -8.228212], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 619 / 744], [train main loss -8.224959], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 620 / 744], [train main loss -8.219007], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 621 / 744], [train main loss -8.222699], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 622 / 744], [train main loss -8.212671], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 623 / 744], [train main loss -8.205673], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 624 / 744], [train main loss -8.202683], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 625 / 744], [train main loss -8.205613], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 626 / 744], [train main loss -8.204886], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 627 / 744], [train main loss -8.208566], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 628 / 744], [train main loss -8.214256], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 629 / 744], [train main loss -8.221960], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 630 / 744], [train main loss -8.223409], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 631 / 744], [train main loss -8.226553], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 632 / 744], [train main loss -8.219586], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 633 / 744], [train main loss -8.215387], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 634 / 744], [train main loss -8.216141], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 635 / 744], [train main loss -8.215312], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 636 / 744], [train main loss -8.215472], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 637 / 744], [train main loss -8.214178], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 638 / 744], [train main loss -8.210069], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 639 / 744], [train main loss -8.206419], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 640 / 744], [train main loss -8.212740], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 641 / 744], [train main loss -8.214482], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 642 / 744], [train main loss -8.207829], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 643 / 744], [train main loss -8.214029], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 644 / 744], [train main loss -8.205509], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 645 / 744], [train main loss -8.208768], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 646 / 744], [train main loss -8.212985], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 647 / 744], [train main loss -8.210706], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 648 / 744], [train main loss -8.208647], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 649 / 744], [train main loss -8.206461], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 650 / 744], [train main loss -8.214700], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 651 / 744], [train main loss -8.220829], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 652 / 744], [train main loss -8.215121], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 653 / 744], [train main loss -8.218096], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 654 / 744], [train main loss -8.221781], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 655 / 744], [train main loss -8.223354], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 656 / 744], [train main loss -8.233106], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 657 / 744], [train main loss -8.228843], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 658 / 744], [train main loss -8.239204], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 659 / 744], [train main loss -8.236764], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 660 / 744], [train main loss -8.233468], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 661 / 744], [train main loss -8.232849], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 662 / 744], [train main loss -8.227252], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 663 / 744], [train main loss -8.225559], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 664 / 744], [train main loss -8.221212], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 665 / 744], [train main loss -8.218929], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 666 / 744], [train main loss -8.219474], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 667 / 744], [train main loss -8.208454], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 668 / 744], [train main loss -8.202734], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 669 / 744], [train main loss -8.196249], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 670 / 744], [train main loss -8.190873], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 671 / 744], [train main loss -8.191312], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 672 / 744], [train main loss -8.194873], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 673 / 744], [train main loss -8.202811], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 674 / 744], [train main loss -8.199872], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 675 / 744], [train main loss -8.205738], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 676 / 744], [train main loss -8.209346], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 677 / 744], [train main loss -8.208000], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 678 / 744], [train main loss -8.205245], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 679 / 744], [train main loss -8.198203], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 680 / 744], [train main loss -8.194163], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 681 / 744], [train main loss -8.199646], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 682 / 744], [train main loss -8.198569], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 683 / 744], [train main loss -8.194766], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 684 / 744], [train main loss -8.194937], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 685 / 744], [train main loss -8.189153], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 686 / 744], [train main loss -8.190893], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 687 / 744], [train main loss -8.187584], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 688 / 744], [train main loss -8.189635], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 689 / 744], [train main loss -8.187911], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 690 / 744], [train main loss -8.196911], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 691 / 744], [train main loss -8.201102], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 692 / 744], [train main loss -8.198003], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 693 / 744], [train main loss -8.195919], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 694 / 744], [train main loss -8.199397], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 695 / 744], [train main loss -8.202716], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 696 / 744], [train main loss -8.204595], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 697 / 744], [train main loss -8.210959], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 698 / 744], [train main loss -8.217559], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 699 / 744], [train main loss -8.215496], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 700 / 744], [train main loss -8.220977], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 701 / 744], [train main loss -8.215828], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 702 / 744], [train main loss -8.220947], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 703 / 744], [train main loss -8.222856], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 704 / 744], [train main loss -8.221938], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 705 / 744], [train main loss -8.218690], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 706 / 744], [train main loss -8.211941], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 707 / 744], [train main loss -8.205498], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 708 / 744], [train main loss -8.214551], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 709 / 744], [train main loss -8.218401], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 710 / 744], [train main loss -8.225046], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 711 / 744], [train main loss -8.223909], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 712 / 744], [train main loss -8.218156], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 713 / 744], [train main loss -8.225830], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 714 / 744], [train main loss -8.221189], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 715 / 744], [train main loss -8.221714], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 716 / 744], [train main loss -8.216534], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 717 / 744], [train main loss -8.215732], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 718 / 744], [train main loss -8.215988], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 719 / 744], [train main loss -8.209004], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 720 / 744], [train main loss -8.212282], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 721 / 744], [train main loss -8.211917], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 722 / 744], [train main loss -8.212600], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 723 / 744], [train main loss -8.211330], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 724 / 744], [train main loss -8.210177], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 725 / 744], [train main loss -8.216031], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 726 / 744], [train main loss -8.215031], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 727 / 744], [train main loss -8.219450], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 728 / 744], [train main loss -8.219891], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 729 / 744], [train main loss -8.217789], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 730 / 744], [train main loss -8.226733], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 731 / 744], [train main loss -8.224292], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 732 / 744], [train main loss -8.221344], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 733 / 744], [train main loss -8.215826], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 734 / 744], [train main loss -8.213645], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 735 / 744], [train main loss -8.216948], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 736 / 744], [train main loss -8.212113], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 737 / 744], [train main loss -8.212203], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 738 / 744], [train main loss -8.208090], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 739 / 744], [train main loss -8.213436], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 740 / 744], [train main loss -8.211927], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 741 / 744], [train main loss -8.211778], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 742 / 744], [train main loss -8.204735], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 743 / 744], [train main loss -8.206986], [lr 0.004943] [batchtime 1.14]
[epoch 1], [iter 744 / 744], [train main loss -8.202797], [lr 0.004943] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              97.82  37.05  0.02  0.01         0.98      0.99
   1  sidewalk          82.84   5.10  0.06  0.15         0.94      0.87
   2  building          92.68  21.00  0.04  0.04         0.96      0.97
   3  wall              66.17   0.56  0.32  0.19         0.76      0.84
   4  fence             58.67   0.54  0.52  0.18         0.66      0.85
   5  pole              70.15   1.18  0.26  0.17         0.80      0.86
   6  traffic light     75.11   0.18  0.12  0.21         0.89      0.83
   7  traffic sign      82.02   0.58  0.14  0.08         0.88      0.93
   8  vegetation        92.57  16.75  0.03  0.05         0.97      0.96
   9  terrain           61.38   0.56  0.48  0.15         0.68      0.87
  10  sky               94.18   3.29  0.02  0.04         0.98      0.96
  11  person            79.97   1.21  0.07  0.18         0.93      0.85
  12  rider             65.20   0.18  0.17  0.36         0.85      0.73
  13  car               95.45   6.39  0.02  0.03         0.98      0.97
  14  truck             66.76   0.27  0.10  0.40         0.91      0.71
  15  bus               87.11   0.35  0.11  0.04         0.90      0.96
  16  train             51.80   0.10  0.10  0.83         0.91      0.55
  17  motorcycle        60.82   0.05  0.46  0.18         0.68      0.85
  18  bicycle           78.72   0.65  0.10  0.17         0.91      0.85
Mean: 76.81
-----------------------------------------------------------------------------------------------------------
this : [epoch 1], [val loss 0.14434], [acc 0.96002], [acc_cls 0.87212], [mean_iu 0.76811], [fwavacc 0.92626]
best : [epoch 1], [val loss 0.14434], [acc 0.96002], [acc_cls 0.87212], [mean_iu 0.76811], [fwavacc 0.92626]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 2], [iter 1 / 744], [train main loss -11.981383], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 2 / 744], [train main loss -13.701041], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 3 / 744], [train main loss -13.206292], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 4 / 744], [train main loss -11.725184], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 5 / 744], [train main loss -11.196326], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 6 / 744], [train main loss -10.846937], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 7 / 744], [train main loss -11.195434], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 8 / 744], [train main loss -10.734185], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 9 / 744], [train main loss -11.229870], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 10 / 744], [train main loss -11.441400], [lr 0.004886] [batchtime 0]
[epoch 2], [iter 11 / 744], [train main loss -11.252146], [lr 0.004886] [batchtime 1.13]
[epoch 2], [iter 12 / 744], [train main loss -11.143307], [lr 0.004886] [batchtime 1.13]
[epoch 2], [iter 13 / 744], [train main loss -10.746428], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 14 / 744], [train main loss -10.296226], [lr 0.004886] [batchtime 1.16]
[epoch 2], [iter 15 / 744], [train main loss -10.369874], [lr 0.004886] [batchtime 1.15]
[epoch 2], [iter 16 / 744], [train main loss -10.008512], [lr 0.004886] [batchtime 1.15]
[epoch 2], [iter 17 / 744], [train main loss -9.887593], [lr 0.004886] [batchtime 1.15]
[epoch 2], [iter 18 / 744], [train main loss -9.764277], [lr 0.004886] [batchtime 1.15]
[epoch 2], [iter 19 / 744], [train main loss -9.379656], [lr 0.004886] [batchtime 1.15]
[epoch 2], [iter 20 / 744], [train main loss -9.289658], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 21 / 744], [train main loss -9.132770], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 22 / 744], [train main loss -9.207445], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 23 / 744], [train main loss -9.144080], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 24 / 744], [train main loss -8.996943], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 25 / 744], [train main loss -9.056410], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 26 / 744], [train main loss -9.232438], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 27 / 744], [train main loss -9.274489], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 28 / 744], [train main loss -9.170253], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 29 / 744], [train main loss -9.095399], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 30 / 744], [train main loss -9.166963], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 31 / 744], [train main loss -9.006640], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 32 / 744], [train main loss -9.030904], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 33 / 744], [train main loss -8.991502], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 34 / 744], [train main loss -9.102848], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 35 / 744], [train main loss -9.210664], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 36 / 744], [train main loss -9.473246], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 37 / 744], [train main loss -9.406134], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 38 / 744], [train main loss -9.576200], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 39 / 744], [train main loss -9.576196], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 40 / 744], [train main loss -9.397652], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 41 / 744], [train main loss -9.367692], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 42 / 744], [train main loss -9.263976], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 43 / 744], [train main loss -9.382058], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 44 / 744], [train main loss -9.380381], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 45 / 744], [train main loss -9.215440], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 46 / 744], [train main loss -9.355793], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 47 / 744], [train main loss -9.410323], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 48 / 744], [train main loss -9.339444], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 49 / 744], [train main loss -9.282706], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 50 / 744], [train main loss -9.184026], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 51 / 744], [train main loss -9.150184], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 52 / 744], [train main loss -9.236746], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 53 / 744], [train main loss -9.208582], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 54 / 744], [train main loss -9.223184], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 55 / 744], [train main loss -9.231776], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 56 / 744], [train main loss -9.342823], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 57 / 744], [train main loss -9.284772], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 58 / 744], [train main loss -9.223983], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 59 / 744], [train main loss -9.181054], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 60 / 744], [train main loss -9.153401], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 61 / 744], [train main loss -9.095058], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 62 / 744], [train main loss -9.111636], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 63 / 744], [train main loss -9.105913], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 64 / 744], [train main loss -9.172595], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 65 / 744], [train main loss -9.158789], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 66 / 744], [train main loss -9.108929], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 67 / 744], [train main loss -9.137463], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 68 / 744], [train main loss -9.054281], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 69 / 744], [train main loss -9.108247], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 70 / 744], [train main loss -9.083490], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 71 / 744], [train main loss -9.036032], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 72 / 744], [train main loss -9.043210], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 73 / 744], [train main loss -9.073525], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 74 / 744], [train main loss -9.070421], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 75 / 744], [train main loss -9.076566], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 76 / 744], [train main loss -9.061664], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 77 / 744], [train main loss -8.997342], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 78 / 744], [train main loss -8.991503], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 79 / 744], [train main loss -8.981190], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 80 / 744], [train main loss -8.971791], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 81 / 744], [train main loss -8.954883], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 82 / 744], [train main loss -8.952921], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 83 / 744], [train main loss -8.944214], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 84 / 744], [train main loss -8.900506], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 85 / 744], [train main loss -8.904449], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 86 / 744], [train main loss -8.885439], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 87 / 744], [train main loss -8.905573], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 88 / 744], [train main loss -8.928096], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 89 / 744], [train main loss -9.009457], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 90 / 744], [train main loss -8.977427], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 91 / 744], [train main loss -8.987249], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 92 / 744], [train main loss -8.957059], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 93 / 744], [train main loss -8.959729], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 94 / 744], [train main loss -8.966112], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 95 / 744], [train main loss -8.966856], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 96 / 744], [train main loss -8.964184], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 97 / 744], [train main loss -9.024187], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 98 / 744], [train main loss -9.023653], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 99 / 744], [train main loss -9.021298], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 100 / 744], [train main loss -9.006448], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 101 / 744], [train main loss -9.026901], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 102 / 744], [train main loss -9.055605], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 103 / 744], [train main loss -9.028980], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 104 / 744], [train main loss -9.037999], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 105 / 744], [train main loss -9.048923], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 106 / 744], [train main loss -9.038719], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 107 / 744], [train main loss -9.018185], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 108 / 744], [train main loss -9.040078], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 109 / 744], [train main loss -9.065316], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 110 / 744], [train main loss -9.087998], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 111 / 744], [train main loss -9.071737], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 112 / 744], [train main loss -9.054936], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 113 / 744], [train main loss -9.037133], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 114 / 744], [train main loss -9.077171], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 115 / 744], [train main loss -9.077370], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 116 / 744], [train main loss -9.077172], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 117 / 744], [train main loss -9.076346], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 118 / 744], [train main loss -9.065603], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 119 / 744], [train main loss -9.020492], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 120 / 744], [train main loss -9.027821], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 121 / 744], [train main loss -9.014502], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 122 / 744], [train main loss -8.976582], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 123 / 744], [train main loss -8.989048], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 124 / 744], [train main loss -9.005773], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 125 / 744], [train main loss -9.018910], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 126 / 744], [train main loss -8.979395], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 127 / 744], [train main loss -8.974130], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 128 / 744], [train main loss -8.906406], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 129 / 744], [train main loss -8.894847], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 130 / 744], [train main loss -8.888356], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 131 / 744], [train main loss -8.874006], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 132 / 744], [train main loss -8.898663], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 133 / 744], [train main loss -8.853232], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 134 / 744], [train main loss -8.839085], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 135 / 744], [train main loss -8.866585], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 136 / 744], [train main loss -8.824084], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 137 / 744], [train main loss -8.834235], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 138 / 744], [train main loss -8.869835], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 139 / 744], [train main loss -8.845961], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 140 / 744], [train main loss -8.851317], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 141 / 744], [train main loss -8.812312], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 142 / 744], [train main loss -8.820642], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 143 / 744], [train main loss -8.831104], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 144 / 744], [train main loss -8.843550], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 145 / 744], [train main loss -8.832937], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 146 / 744], [train main loss -8.906558], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 147 / 744], [train main loss -8.914800], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 148 / 744], [train main loss -8.933743], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 149 / 744], [train main loss -8.917237], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 150 / 744], [train main loss -8.922463], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 151 / 744], [train main loss -8.928918], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 152 / 744], [train main loss -8.936906], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 153 / 744], [train main loss -8.937173], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 154 / 744], [train main loss -8.942659], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 155 / 744], [train main loss -8.934888], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 156 / 744], [train main loss -8.938918], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 157 / 744], [train main loss -8.964943], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 158 / 744], [train main loss -8.942544], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 159 / 744], [train main loss -8.939030], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 160 / 744], [train main loss -8.936257], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 161 / 744], [train main loss -8.922968], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 162 / 744], [train main loss -8.951923], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 163 / 744], [train main loss -8.943261], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 164 / 744], [train main loss -8.984014], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 165 / 744], [train main loss -8.966727], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 166 / 744], [train main loss -8.960008], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 167 / 744], [train main loss -8.968736], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 168 / 744], [train main loss -8.932450], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 169 / 744], [train main loss -8.943963], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 170 / 744], [train main loss -8.921010], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 171 / 744], [train main loss -8.907812], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 172 / 744], [train main loss -8.902093], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 173 / 744], [train main loss -8.877982], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 174 / 744], [train main loss -8.850951], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 175 / 744], [train main loss -8.841805], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 176 / 744], [train main loss -8.871874], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 177 / 744], [train main loss -8.857697], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 178 / 744], [train main loss -8.888402], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 179 / 744], [train main loss -8.864199], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 180 / 744], [train main loss -8.873071], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 181 / 744], [train main loss -8.859054], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 182 / 744], [train main loss -8.835695], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 183 / 744], [train main loss -8.806082], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 184 / 744], [train main loss -8.807867], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 185 / 744], [train main loss -8.847549], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 186 / 744], [train main loss -8.851483], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 187 / 744], [train main loss -8.883329], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 188 / 744], [train main loss -8.884893], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 189 / 744], [train main loss -8.895343], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 190 / 744], [train main loss -8.880447], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 191 / 744], [train main loss -8.880420], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 192 / 744], [train main loss -8.874395], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 193 / 744], [train main loss -8.876104], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 194 / 744], [train main loss -8.902339], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 195 / 744], [train main loss -8.907618], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 196 / 744], [train main loss -8.905771], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 197 / 744], [train main loss -8.902271], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 198 / 744], [train main loss -8.917788], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 199 / 744], [train main loss -8.918869], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 200 / 744], [train main loss -8.926908], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 201 / 744], [train main loss -8.931378], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 202 / 744], [train main loss -8.932231], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 203 / 744], [train main loss -8.926394], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 204 / 744], [train main loss -8.934349], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 205 / 744], [train main loss -8.927802], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 206 / 744], [train main loss -8.907259], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 207 / 744], [train main loss -8.900044], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 208 / 744], [train main loss -8.885347], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 209 / 744], [train main loss -8.892740], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 210 / 744], [train main loss -8.894249], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 211 / 744], [train main loss -8.897423], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 212 / 744], [train main loss -8.888883], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 213 / 744], [train main loss -8.898635], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 214 / 744], [train main loss -8.898690], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 215 / 744], [train main loss -8.929403], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 216 / 744], [train main loss -8.935842], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 217 / 744], [train main loss -8.927904], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 218 / 744], [train main loss -8.909091], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 219 / 744], [train main loss -8.919118], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 220 / 744], [train main loss -8.900702], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 221 / 744], [train main loss -8.934632], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 222 / 744], [train main loss -8.906956], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 223 / 744], [train main loss -8.873778], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 224 / 744], [train main loss -8.845823], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 225 / 744], [train main loss -8.865182], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 226 / 744], [train main loss -8.870402], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 227 / 744], [train main loss -8.866707], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 228 / 744], [train main loss -8.838920], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 229 / 744], [train main loss -8.836300], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 230 / 744], [train main loss -8.822627], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 231 / 744], [train main loss -8.825089], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 232 / 744], [train main loss -8.805710], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 233 / 744], [train main loss -8.807007], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 234 / 744], [train main loss -8.800311], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 235 / 744], [train main loss -8.799303], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 236 / 744], [train main loss -8.823342], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 237 / 744], [train main loss -8.829856], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 238 / 744], [train main loss -8.817254], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 239 / 744], [train main loss -8.816775], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 240 / 744], [train main loss -8.832064], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 241 / 744], [train main loss -8.841503], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 242 / 744], [train main loss -8.842356], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 243 / 744], [train main loss -8.844003], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 244 / 744], [train main loss -8.869501], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 245 / 744], [train main loss -8.898043], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 246 / 744], [train main loss -8.883382], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 247 / 744], [train main loss -8.903864], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 248 / 744], [train main loss -8.880232], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 249 / 744], [train main loss -8.884980], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 250 / 744], [train main loss -8.869556], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 251 / 744], [train main loss -8.853131], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 252 / 744], [train main loss -8.855266], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 253 / 744], [train main loss -8.844271], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 254 / 744], [train main loss -8.849539], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 255 / 744], [train main loss -8.865304], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 256 / 744], [train main loss -8.870781], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 257 / 744], [train main loss -8.890293], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 258 / 744], [train main loss -8.891601], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 259 / 744], [train main loss -8.896635], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 260 / 744], [train main loss -8.892860], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 261 / 744], [train main loss -8.898489], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 262 / 744], [train main loss -8.920583], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 263 / 744], [train main loss -8.887769], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 264 / 744], [train main loss -8.884647], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 265 / 744], [train main loss -8.901917], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 266 / 744], [train main loss -8.917516], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 267 / 744], [train main loss -8.919089], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 268 / 744], [train main loss -8.924318], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 269 / 744], [train main loss -8.927458], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 270 / 744], [train main loss -8.931568], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 271 / 744], [train main loss -8.928514], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 272 / 744], [train main loss -8.927103], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 273 / 744], [train main loss -8.922620], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 274 / 744], [train main loss -8.911288], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 275 / 744], [train main loss -8.878987], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 276 / 744], [train main loss -8.872648], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 277 / 744], [train main loss -8.878933], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 278 / 744], [train main loss -8.874100], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 279 / 744], [train main loss -8.884758], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 280 / 744], [train main loss -8.871668], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 281 / 744], [train main loss -8.853684], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 282 / 744], [train main loss -8.867651], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 283 / 744], [train main loss -8.869928], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 284 / 744], [train main loss -8.848216], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 285 / 744], [train main loss -8.835867], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 286 / 744], [train main loss -8.830512], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 287 / 744], [train main loss -8.836370], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 288 / 744], [train main loss -8.834312], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 289 / 744], [train main loss -8.833951], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 290 / 744], [train main loss -8.840861], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 291 / 744], [train main loss -8.859636], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 292 / 744], [train main loss -8.864523], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 293 / 744], [train main loss -8.876497], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 294 / 744], [train main loss -8.879109], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 295 / 744], [train main loss -8.900200], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 296 / 744], [train main loss -8.889193], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 297 / 744], [train main loss -8.901401], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 298 / 744], [train main loss -8.893251], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 299 / 744], [train main loss -8.879025], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 300 / 744], [train main loss -8.876630], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 301 / 744], [train main loss -8.851686], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 302 / 744], [train main loss -8.848135], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 303 / 744], [train main loss -8.837028], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 304 / 744], [train main loss -8.829286], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 305 / 744], [train main loss -8.815348], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 306 / 744], [train main loss -8.806900], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 307 / 744], [train main loss -8.808231], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 308 / 744], [train main loss -8.782780], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 309 / 744], [train main loss -8.785312], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 310 / 744], [train main loss -8.791356], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 311 / 744], [train main loss -8.787003], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 312 / 744], [train main loss -8.793092], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 313 / 744], [train main loss -8.812934], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 314 / 744], [train main loss -8.788404], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 315 / 744], [train main loss -8.786508], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 316 / 744], [train main loss -8.794409], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 317 / 744], [train main loss -8.767885], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 318 / 744], [train main loss -8.767742], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 319 / 744], [train main loss -8.752804], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 320 / 744], [train main loss -8.763175], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 321 / 744], [train main loss -8.782725], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 322 / 744], [train main loss -8.777687], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 323 / 744], [train main loss -8.763568], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 324 / 744], [train main loss -8.771131], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 325 / 744], [train main loss -8.773991], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 326 / 744], [train main loss -8.785702], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 327 / 744], [train main loss -8.784304], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 328 / 744], [train main loss -8.781874], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 329 / 744], [train main loss -8.773150], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 330 / 744], [train main loss -8.761109], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 331 / 744], [train main loss -8.763880], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 332 / 744], [train main loss -8.785452], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 333 / 744], [train main loss -8.789310], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 334 / 744], [train main loss -8.773388], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 335 / 744], [train main loss -8.772597], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 336 / 744], [train main loss -8.761124], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 337 / 744], [train main loss -8.767317], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 338 / 744], [train main loss -8.784519], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 339 / 744], [train main loss -8.795351], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 340 / 744], [train main loss -8.797332], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 341 / 744], [train main loss -8.808933], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 342 / 744], [train main loss -8.806613], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 343 / 744], [train main loss -8.807050], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 344 / 744], [train main loss -8.812967], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 345 / 744], [train main loss -8.817824], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 346 / 744], [train main loss -8.822260], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 347 / 744], [train main loss -8.856872], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 348 / 744], [train main loss -8.859237], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 349 / 744], [train main loss -8.864318], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 350 / 744], [train main loss -8.856592], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 351 / 744], [train main loss -8.866473], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 352 / 744], [train main loss -8.844239], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 353 / 744], [train main loss -8.832278], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 354 / 744], [train main loss -8.840573], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 355 / 744], [train main loss -8.838262], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 356 / 744], [train main loss -8.841941], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 357 / 744], [train main loss -8.831794], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 358 / 744], [train main loss -8.836878], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 359 / 744], [train main loss -8.822800], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 360 / 744], [train main loss -8.810487], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 361 / 744], [train main loss -8.809221], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 362 / 744], [train main loss -8.801147], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 363 / 744], [train main loss -8.791097], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 364 / 744], [train main loss -8.785719], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 365 / 744], [train main loss -8.771842], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 366 / 744], [train main loss -8.775173], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 367 / 744], [train main loss -8.765920], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 368 / 744], [train main loss -8.750425], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 369 / 744], [train main loss -8.742977], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 370 / 744], [train main loss -8.740251], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 371 / 744], [train main loss -8.728653], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 372 / 744], [train main loss -8.725553], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 373 / 744], [train main loss -8.736229], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 374 / 744], [train main loss -8.727371], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 375 / 744], [train main loss -8.743671], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 376 / 744], [train main loss -8.726134], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 377 / 744], [train main loss -8.718486], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 378 / 744], [train main loss -8.698781], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 379 / 744], [train main loss -8.704446], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 380 / 744], [train main loss -8.697713], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 381 / 744], [train main loss -8.697990], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 382 / 744], [train main loss -8.700745], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 383 / 744], [train main loss -8.695839], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 384 / 744], [train main loss -8.675362], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 385 / 744], [train main loss -8.679830], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 386 / 744], [train main loss -8.683353], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 387 / 744], [train main loss -8.673483], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 388 / 744], [train main loss -8.668044], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 389 / 744], [train main loss -8.666084], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 390 / 744], [train main loss -8.654653], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 391 / 744], [train main loss -8.657971], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 392 / 744], [train main loss -8.643057], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 393 / 744], [train main loss -8.638339], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 394 / 744], [train main loss -8.637478], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 395 / 744], [train main loss -8.650665], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 396 / 744], [train main loss -8.653535], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 397 / 744], [train main loss -8.646831], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 398 / 744], [train main loss -8.635871], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 399 / 744], [train main loss -8.628097], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 400 / 744], [train main loss -8.643584], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 401 / 744], [train main loss -8.649807], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 402 / 744], [train main loss -8.650885], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 403 / 744], [train main loss -8.645974], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 404 / 744], [train main loss -8.638151], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 405 / 744], [train main loss -8.630668], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 406 / 744], [train main loss -8.621464], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 407 / 744], [train main loss -8.630389], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 408 / 744], [train main loss -8.651181], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 409 / 744], [train main loss -8.645677], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 410 / 744], [train main loss -8.642113], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 411 / 744], [train main loss -8.633553], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 412 / 744], [train main loss -8.629594], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 413 / 744], [train main loss -8.630899], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 414 / 744], [train main loss -8.625966], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 415 / 744], [train main loss -8.621276], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 416 / 744], [train main loss -8.607696], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 417 / 744], [train main loss -8.612580], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 418 / 744], [train main loss -8.611595], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 419 / 744], [train main loss -8.601938], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 420 / 744], [train main loss -8.592902], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 421 / 744], [train main loss -8.579291], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 422 / 744], [train main loss -8.585012], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 423 / 744], [train main loss -8.580347], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 424 / 744], [train main loss -8.575130], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 425 / 744], [train main loss -8.567409], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 426 / 744], [train main loss -8.554529], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 427 / 744], [train main loss -8.558479], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 428 / 744], [train main loss -8.556927], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 429 / 744], [train main loss -8.557276], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 430 / 744], [train main loss -8.548051], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 431 / 744], [train main loss -8.559898], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 432 / 744], [train main loss -8.564378], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 433 / 744], [train main loss -8.552736], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 434 / 744], [train main loss -8.543002], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 435 / 744], [train main loss -8.555592], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 436 / 744], [train main loss -8.561774], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 437 / 744], [train main loss -8.549102], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 438 / 744], [train main loss -8.549303], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 439 / 744], [train main loss -8.542844], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 440 / 744], [train main loss -8.533103], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 441 / 744], [train main loss -8.528635], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 442 / 744], [train main loss -8.526077], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 443 / 744], [train main loss -8.530208], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 444 / 744], [train main loss -8.530402], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 445 / 744], [train main loss -8.523476], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 446 / 744], [train main loss -8.525904], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 447 / 744], [train main loss -8.533937], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 448 / 744], [train main loss -8.520951], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 449 / 744], [train main loss -8.517694], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 450 / 744], [train main loss -8.509078], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 451 / 744], [train main loss -8.508630], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 452 / 744], [train main loss -8.502969], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 453 / 744], [train main loss -8.498761], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 454 / 744], [train main loss -8.494701], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 455 / 744], [train main loss -8.498198], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 456 / 744], [train main loss -8.491149], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 457 / 744], [train main loss -8.474248], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 458 / 744], [train main loss -8.473719], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 459 / 744], [train main loss -8.468268], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 460 / 744], [train main loss -8.462384], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 461 / 744], [train main loss -8.464467], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 462 / 744], [train main loss -8.472917], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 463 / 744], [train main loss -8.472087], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 464 / 744], [train main loss -8.474796], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 465 / 744], [train main loss -8.468283], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 466 / 744], [train main loss -8.487839], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 467 / 744], [train main loss -8.490209], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 468 / 744], [train main loss -8.478469], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 469 / 744], [train main loss -8.484810], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 470 / 744], [train main loss -8.480226], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 471 / 744], [train main loss -8.485456], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 472 / 744], [train main loss -8.492653], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 473 / 744], [train main loss -8.502134], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 474 / 744], [train main loss -8.507828], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 475 / 744], [train main loss -8.504276], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 476 / 744], [train main loss -8.510361], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 477 / 744], [train main loss -8.513718], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 478 / 744], [train main loss -8.514414], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 479 / 744], [train main loss -8.500035], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 480 / 744], [train main loss -8.507797], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 481 / 744], [train main loss -8.508802], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 482 / 744], [train main loss -8.505158], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 483 / 744], [train main loss -8.512305], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 484 / 744], [train main loss -8.507861], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 485 / 744], [train main loss -8.513894], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 486 / 744], [train main loss -8.518825], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 487 / 744], [train main loss -8.524469], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 488 / 744], [train main loss -8.524505], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 489 / 744], [train main loss -8.518325], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 490 / 744], [train main loss -8.517032], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 491 / 744], [train main loss -8.504750], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 492 / 744], [train main loss -8.505806], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 493 / 744], [train main loss -8.497662], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 494 / 744], [train main loss -8.509331], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 495 / 744], [train main loss -8.505572], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 496 / 744], [train main loss -8.503064], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 497 / 744], [train main loss -8.519087], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 498 / 744], [train main loss -8.520692], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 499 / 744], [train main loss -8.525427], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 500 / 744], [train main loss -8.525851], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 501 / 744], [train main loss -8.532192], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 502 / 744], [train main loss -8.539798], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 503 / 744], [train main loss -8.544366], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 504 / 744], [train main loss -8.548460], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 505 / 744], [train main loss -8.542270], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 506 / 744], [train main loss -8.542636], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 507 / 744], [train main loss -8.529937], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 508 / 744], [train main loss -8.527186], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 509 / 744], [train main loss -8.523353], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 510 / 744], [train main loss -8.524916], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 511 / 744], [train main loss -8.522991], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 512 / 744], [train main loss -8.514587], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 513 / 744], [train main loss -8.506496], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 514 / 744], [train main loss -8.502727], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 515 / 744], [train main loss -8.498716], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 516 / 744], [train main loss -8.512028], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 517 / 744], [train main loss -8.499153], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 518 / 744], [train main loss -8.501735], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 519 / 744], [train main loss -8.500297], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 520 / 744], [train main loss -8.488734], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 521 / 744], [train main loss -8.488051], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 522 / 744], [train main loss -8.490622], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 523 / 744], [train main loss -8.498651], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 524 / 744], [train main loss -8.496307], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 525 / 744], [train main loss -8.496508], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 526 / 744], [train main loss -8.494118], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 527 / 744], [train main loss -8.486071], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 528 / 744], [train main loss -8.487898], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 529 / 744], [train main loss -8.482954], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 530 / 744], [train main loss -8.475787], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 531 / 744], [train main loss -8.475304], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 532 / 744], [train main loss -8.477278], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 533 / 744], [train main loss -8.485334], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 534 / 744], [train main loss -8.491639], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 535 / 744], [train main loss -8.487199], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 536 / 744], [train main loss -8.475284], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 537 / 744], [train main loss -8.487806], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 538 / 744], [train main loss -8.489890], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 539 / 744], [train main loss -8.483201], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 540 / 744], [train main loss -8.476420], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 541 / 744], [train main loss -8.481503], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 542 / 744], [train main loss -8.484156], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 543 / 744], [train main loss -8.483391], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 544 / 744], [train main loss -8.503442], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 545 / 744], [train main loss -8.507581], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 546 / 744], [train main loss -8.503046], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 547 / 744], [train main loss -8.507758], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 548 / 744], [train main loss -8.499916], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 549 / 744], [train main loss -8.497586], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 550 / 744], [train main loss -8.493460], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 551 / 744], [train main loss -8.499829], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 552 / 744], [train main loss -8.507205], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 553 / 744], [train main loss -8.505360], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 554 / 744], [train main loss -8.510040], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 555 / 744], [train main loss -8.513088], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 556 / 744], [train main loss -8.516949], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 557 / 744], [train main loss -8.508679], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 558 / 744], [train main loss -8.511515], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 559 / 744], [train main loss -8.505732], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 560 / 744], [train main loss -8.497791], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 561 / 744], [train main loss -8.499264], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 562 / 744], [train main loss -8.494443], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 563 / 744], [train main loss -8.502426], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 564 / 744], [train main loss -8.505149], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 565 / 744], [train main loss -8.505507], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 566 / 744], [train main loss -8.501366], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 567 / 744], [train main loss -8.497255], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 568 / 744], [train main loss -8.482446], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 569 / 744], [train main loss -8.488598], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 570 / 744], [train main loss -8.489082], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 571 / 744], [train main loss -8.477802], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 572 / 744], [train main loss -8.473129], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 573 / 744], [train main loss -8.475885], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 574 / 744], [train main loss -8.475879], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 575 / 744], [train main loss -8.477451], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 576 / 744], [train main loss -8.472561], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 577 / 744], [train main loss -8.472608], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 578 / 744], [train main loss -8.467491], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 579 / 744], [train main loss -8.458242], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 580 / 744], [train main loss -8.454259], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 581 / 744], [train main loss -8.443833], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 582 / 744], [train main loss -8.437308], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 583 / 744], [train main loss -8.439338], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 584 / 744], [train main loss -8.438899], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 585 / 744], [train main loss -8.437292], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 586 / 744], [train main loss -8.435517], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 587 / 744], [train main loss -8.427295], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 588 / 744], [train main loss -8.422596], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 589 / 744], [train main loss -8.417326], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 590 / 744], [train main loss -8.412570], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 591 / 744], [train main loss -8.413693], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 592 / 744], [train main loss -8.411413], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 593 / 744], [train main loss -8.408108], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 594 / 744], [train main loss -8.415786], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 595 / 744], [train main loss -8.406206], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 596 / 744], [train main loss -8.404325], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 597 / 744], [train main loss -8.397276], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 598 / 744], [train main loss -8.407338], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 599 / 744], [train main loss -8.399350], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 600 / 744], [train main loss -8.397857], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 601 / 744], [train main loss -8.389593], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 602 / 744], [train main loss -8.398028], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 603 / 744], [train main loss -8.396893], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 604 / 744], [train main loss -8.404184], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 605 / 744], [train main loss -8.402417], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 606 / 744], [train main loss -8.395146], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 607 / 744], [train main loss -8.402788], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 608 / 744], [train main loss -8.399293], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 609 / 744], [train main loss -8.397761], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 610 / 744], [train main loss -8.397970], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 611 / 744], [train main loss -8.400341], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 612 / 744], [train main loss -8.399669], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 613 / 744], [train main loss -8.400439], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 614 / 744], [train main loss -8.405095], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 615 / 744], [train main loss -8.412642], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 616 / 744], [train main loss -8.404107], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 617 / 744], [train main loss -8.403920], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 618 / 744], [train main loss -8.412177], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 619 / 744], [train main loss -8.413797], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 620 / 744], [train main loss -8.406193], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 621 / 744], [train main loss -8.415635], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 622 / 744], [train main loss -8.423178], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 623 / 744], [train main loss -8.432957], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 624 / 744], [train main loss -8.428392], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 625 / 744], [train main loss -8.424161], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 626 / 744], [train main loss -8.425647], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 627 / 744], [train main loss -8.428916], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 628 / 744], [train main loss -8.433238], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 629 / 744], [train main loss -8.431922], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 630 / 744], [train main loss -8.432248], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 631 / 744], [train main loss -8.426874], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 632 / 744], [train main loss -8.422944], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 633 / 744], [train main loss -8.422583], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 634 / 744], [train main loss -8.421798], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 635 / 744], [train main loss -8.419787], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 636 / 744], [train main loss -8.434776], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 637 / 744], [train main loss -8.442883], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 638 / 744], [train main loss -8.434097], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 639 / 744], [train main loss -8.433155], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 640 / 744], [train main loss -8.447097], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 641 / 744], [train main loss -8.446884], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 642 / 744], [train main loss -8.442000], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 643 / 744], [train main loss -8.438654], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 644 / 744], [train main loss -8.437364], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 645 / 744], [train main loss -8.430981], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 646 / 744], [train main loss -8.421744], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 647 / 744], [train main loss -8.420999], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 648 / 744], [train main loss -8.425328], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 649 / 744], [train main loss -8.432963], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 650 / 744], [train main loss -8.434923], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 651 / 744], [train main loss -8.433536], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 652 / 744], [train main loss -8.438125], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 653 / 744], [train main loss -8.434805], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 654 / 744], [train main loss -8.440305], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 655 / 744], [train main loss -8.429343], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 656 / 744], [train main loss -8.432945], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 657 / 744], [train main loss -8.430557], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 658 / 744], [train main loss -8.430744], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 659 / 744], [train main loss -8.428029], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 660 / 744], [train main loss -8.432760], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 661 / 744], [train main loss -8.424091], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 662 / 744], [train main loss -8.423032], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 663 / 744], [train main loss -8.418818], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 664 / 744], [train main loss -8.422554], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 665 / 744], [train main loss -8.428351], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 666 / 744], [train main loss -8.426691], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 667 / 744], [train main loss -8.430268], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 668 / 744], [train main loss -8.428309], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 669 / 744], [train main loss -8.432012], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 670 / 744], [train main loss -8.440757], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 671 / 744], [train main loss -8.437143], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 672 / 744], [train main loss -8.442885], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 673 / 744], [train main loss -8.442857], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 674 / 744], [train main loss -8.435057], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 675 / 744], [train main loss -8.428954], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 676 / 744], [train main loss -8.430604], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 677 / 744], [train main loss -8.422815], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 678 / 744], [train main loss -8.414250], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 679 / 744], [train main loss -8.416386], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 680 / 744], [train main loss -8.411388], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 681 / 744], [train main loss -8.404500], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 682 / 744], [train main loss -8.409393], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 683 / 744], [train main loss -8.402715], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 684 / 744], [train main loss -8.405461], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 685 / 744], [train main loss -8.401673], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 686 / 744], [train main loss -8.409152], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 687 / 744], [train main loss -8.408522], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 688 / 744], [train main loss -8.406693], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 689 / 744], [train main loss -8.400210], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 690 / 744], [train main loss -8.412948], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 691 / 744], [train main loss -8.416401], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 692 / 744], [train main loss -8.422744], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 693 / 744], [train main loss -8.418714], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 694 / 744], [train main loss -8.424974], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 695 / 744], [train main loss -8.423950], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 696 / 744], [train main loss -8.422418], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 697 / 744], [train main loss -8.428391], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 698 / 744], [train main loss -8.438741], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 699 / 744], [train main loss -8.442516], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 700 / 744], [train main loss -8.443337], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 701 / 744], [train main loss -8.441843], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 702 / 744], [train main loss -8.442200], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 703 / 744], [train main loss -8.445739], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 704 / 744], [train main loss -8.448498], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 705 / 744], [train main loss -8.448236], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 706 / 744], [train main loss -8.449708], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 707 / 744], [train main loss -8.446980], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 708 / 744], [train main loss -8.441575], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 709 / 744], [train main loss -8.441766], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 710 / 744], [train main loss -8.440798], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 711 / 744], [train main loss -8.441837], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 712 / 744], [train main loss -8.448920], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 713 / 744], [train main loss -8.442938], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 714 / 744], [train main loss -8.439935], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 715 / 744], [train main loss -8.433516], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 716 / 744], [train main loss -8.433571], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 717 / 744], [train main loss -8.434844], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 718 / 744], [train main loss -8.432195], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 719 / 744], [train main loss -8.435130], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 720 / 744], [train main loss -8.438551], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 721 / 744], [train main loss -8.435755], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 722 / 744], [train main loss -8.440440], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 723 / 744], [train main loss -8.443521], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 724 / 744], [train main loss -8.445386], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 725 / 744], [train main loss -8.439678], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 726 / 744], [train main loss -8.443121], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 727 / 744], [train main loss -8.442518], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 728 / 744], [train main loss -8.439087], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 729 / 744], [train main loss -8.437088], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 730 / 744], [train main loss -8.442602], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 731 / 744], [train main loss -8.441491], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 732 / 744], [train main loss -8.437985], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 733 / 744], [train main loss -8.435698], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 734 / 744], [train main loss -8.431743], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 735 / 744], [train main loss -8.432028], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 736 / 744], [train main loss -8.433248], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 737 / 744], [train main loss -8.428022], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 738 / 744], [train main loss -8.430693], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 739 / 744], [train main loss -8.434795], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 740 / 744], [train main loss -8.439410], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 741 / 744], [train main loss -8.438841], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 742 / 744], [train main loss -8.445136], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 743 / 744], [train main loss -8.452978], [lr 0.004886] [batchtime 1.14]
[epoch 2], [iter 744 / 744], [train main loss -8.447866], [lr 0.004886] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              97.33  36.82  0.02  0.00         0.98      1.00
   1  sidewalk          80.39   5.14  0.05  0.19         0.95      0.84
   2  building          92.90  20.85  0.05  0.03         0.95      0.98
   3  wall              59.85   0.53  0.38  0.29         0.73      0.77
   4  fence             62.84   0.59  0.40  0.20         0.72      0.84
   5  pole              69.34   1.18  0.25  0.19         0.80      0.84
   6  traffic light     74.72   0.16  0.24  0.10         0.81      0.91
   7  traffic sign      82.78   0.58  0.15  0.05         0.87      0.95
   8  vegetation        92.12  16.94  0.02  0.06         0.98      0.94
   9  terrain           60.56   0.58  0.43  0.22         0.70      0.82
  10  sky               94.52   3.30  0.02  0.04         0.98      0.96
  11  person            82.98   1.22  0.06  0.14         0.94      0.87
  12  rider             65.23   0.16  0.33  0.20         0.75      0.83
  13  car               94.49   6.42  0.01  0.04         0.99      0.96
  14  truck             63.33   0.22  0.37  0.21         0.73      0.83
  15  bus               88.24   0.36  0.09  0.04         0.92      0.96
  16  train             72.12   0.09  0.23  0.16         0.81      0.86
  17  motorcycle        61.01   0.05  0.46  0.18         0.69      0.85
  18  bicycle           78.23   0.60  0.17  0.10         0.85      0.91
Mean: 77.53
-----------------------------------------------------------------------------------------------------------
this : [epoch 2], [val loss 0.15303], [acc 0.95799], [acc_cls 0.84888], [mean_iu 0.77525], [fwavacc 0.92257]
best : [epoch 2], [val loss 0.15303], [acc 0.95799], [acc_cls 0.84888], [mean_iu 0.77525], [fwavacc 0.92257]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 3], [iter 1 / 744], [train main loss -9.562456], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 2 / 744], [train main loss -7.007895], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 3 / 744], [train main loss -9.050496], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 4 / 744], [train main loss -8.268156], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 5 / 744], [train main loss -9.113734], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 6 / 744], [train main loss -9.018025], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 7 / 744], [train main loss -8.573038], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 8 / 744], [train main loss -8.802008], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 9 / 744], [train main loss -9.234020], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 10 / 744], [train main loss -9.139721], [lr 0.004830] [batchtime 0]
[epoch 3], [iter 11 / 744], [train main loss -8.959299], [lr 0.004830] [batchtime 1.12]
[epoch 3], [iter 12 / 744], [train main loss -9.032875], [lr 0.004830] [batchtime 1.17]
[epoch 3], [iter 13 / 744], [train main loss -8.946423], [lr 0.004830] [batchtime 1.17]
[epoch 3], [iter 14 / 744], [train main loss -8.998198], [lr 0.004830] [batchtime 1.16]
[epoch 3], [iter 15 / 744], [train main loss -8.750201], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 16 / 744], [train main loss -8.549830], [lr 0.004830] [batchtime 1.17]
[epoch 3], [iter 17 / 744], [train main loss -8.754400], [lr 0.004830] [batchtime 1.16]
[epoch 3], [iter 18 / 744], [train main loss -8.633254], [lr 0.004830] [batchtime 1.16]
[epoch 3], [iter 19 / 744], [train main loss -8.511286], [lr 0.004830] [batchtime 1.16]
[epoch 3], [iter 20 / 744], [train main loss -8.556581], [lr 0.004830] [batchtime 1.16]
[epoch 3], [iter 21 / 744], [train main loss -8.649168], [lr 0.004830] [batchtime 1.16]
[epoch 3], [iter 22 / 744], [train main loss -8.886230], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 23 / 744], [train main loss -8.607104], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 24 / 744], [train main loss -8.620806], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 25 / 744], [train main loss -8.535088], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 26 / 744], [train main loss -8.622724], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 27 / 744], [train main loss -8.447093], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 28 / 744], [train main loss -8.389137], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 29 / 744], [train main loss -8.236985], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 30 / 744], [train main loss -8.166111], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 31 / 744], [train main loss -8.277045], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 32 / 744], [train main loss -8.164760], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 33 / 744], [train main loss -8.519977], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 34 / 744], [train main loss -8.503879], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 35 / 744], [train main loss -8.320318], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 36 / 744], [train main loss -8.293279], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 37 / 744], [train main loss -8.284457], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 38 / 744], [train main loss -8.328844], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 39 / 744], [train main loss -8.431301], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 40 / 744], [train main loss -8.533890], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 41 / 744], [train main loss -8.512804], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 42 / 744], [train main loss -8.441891], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 43 / 744], [train main loss -8.338579], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 44 / 744], [train main loss -8.221687], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 45 / 744], [train main loss -8.198768], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 46 / 744], [train main loss -8.245953], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 47 / 744], [train main loss -8.178564], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 48 / 744], [train main loss -8.161845], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 49 / 744], [train main loss -8.148189], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 50 / 744], [train main loss -8.025472], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 51 / 744], [train main loss -8.107114], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 52 / 744], [train main loss -8.061863], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 53 / 744], [train main loss -8.098842], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 54 / 744], [train main loss -8.084134], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 55 / 744], [train main loss -8.112421], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 56 / 744], [train main loss -8.096052], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 57 / 744], [train main loss -8.103434], [lr 0.004830] [batchtime 1.15]
[epoch 3], [iter 58 / 744], [train main loss -8.033854], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 59 / 744], [train main loss -8.003694], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 60 / 744], [train main loss -7.977339], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 61 / 744], [train main loss -7.997064], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 62 / 744], [train main loss -8.015961], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 63 / 744], [train main loss -8.111787], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 64 / 744], [train main loss -8.133433], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 65 / 744], [train main loss -8.231931], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 66 / 744], [train main loss -8.174540], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 67 / 744], [train main loss -8.179695], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 68 / 744], [train main loss -8.205916], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 69 / 744], [train main loss -8.212231], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 70 / 744], [train main loss -8.226463], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 71 / 744], [train main loss -8.201005], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 72 / 744], [train main loss -8.297135], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 73 / 744], [train main loss -8.318735], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 74 / 744], [train main loss -8.278201], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 75 / 744], [train main loss -8.304757], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 76 / 744], [train main loss -8.305580], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 77 / 744], [train main loss -8.307851], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 78 / 744], [train main loss -8.341248], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 79 / 744], [train main loss -8.359759], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 80 / 744], [train main loss -8.326607], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 81 / 744], [train main loss -8.397659], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 82 / 744], [train main loss -8.428864], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 83 / 744], [train main loss -8.424186], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 84 / 744], [train main loss -8.405328], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 85 / 744], [train main loss -8.359468], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 86 / 744], [train main loss -8.295773], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 87 / 744], [train main loss -8.283390], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 88 / 744], [train main loss -8.286589], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 89 / 744], [train main loss -8.245379], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 90 / 744], [train main loss -8.225589], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 91 / 744], [train main loss -8.293005], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 92 / 744], [train main loss -8.291492], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 93 / 744], [train main loss -8.269881], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 94 / 744], [train main loss -8.261068], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 95 / 744], [train main loss -8.205817], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 96 / 744], [train main loss -8.227300], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 97 / 744], [train main loss -8.282084], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 98 / 744], [train main loss -8.253799], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 99 / 744], [train main loss -8.254924], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 100 / 744], [train main loss -8.247129], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 101 / 744], [train main loss -8.190794], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 102 / 744], [train main loss -8.214951], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 103 / 744], [train main loss -8.189679], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 104 / 744], [train main loss -8.222890], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 105 / 744], [train main loss -8.239162], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 106 / 744], [train main loss -8.259383], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 107 / 744], [train main loss -8.240784], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 108 / 744], [train main loss -8.228639], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 109 / 744], [train main loss -8.223914], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 110 / 744], [train main loss -8.264907], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 111 / 744], [train main loss -8.242780], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 112 / 744], [train main loss -8.286842], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 113 / 744], [train main loss -8.303013], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 114 / 744], [train main loss -8.283753], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 115 / 744], [train main loss -8.298721], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 116 / 744], [train main loss -8.342079], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 117 / 744], [train main loss -8.361359], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 118 / 744], [train main loss -8.353851], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 119 / 744], [train main loss -8.390890], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 120 / 744], [train main loss -8.395406], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 121 / 744], [train main loss -8.401594], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 122 / 744], [train main loss -8.404288], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 123 / 744], [train main loss -8.417123], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 124 / 744], [train main loss -8.421604], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 125 / 744], [train main loss -8.419709], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 126 / 744], [train main loss -8.383993], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 127 / 744], [train main loss -8.420365], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 128 / 744], [train main loss -8.422378], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 129 / 744], [train main loss -8.405172], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 130 / 744], [train main loss -8.442660], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 131 / 744], [train main loss -8.448805], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 132 / 744], [train main loss -8.462021], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 133 / 744], [train main loss -8.442701], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 134 / 744], [train main loss -8.417382], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 135 / 744], [train main loss -8.399472], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 136 / 744], [train main loss -8.448050], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 137 / 744], [train main loss -8.414768], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 138 / 744], [train main loss -8.388355], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 139 / 744], [train main loss -8.362394], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 140 / 744], [train main loss -8.373971], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 141 / 744], [train main loss -8.391512], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 142 / 744], [train main loss -8.376273], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 143 / 744], [train main loss -8.369935], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 144 / 744], [train main loss -8.344521], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 145 / 744], [train main loss -8.332496], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 146 / 744], [train main loss -8.292917], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 147 / 744], [train main loss -8.319001], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 148 / 744], [train main loss -8.262974], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 149 / 744], [train main loss -8.246388], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 150 / 744], [train main loss -8.260523], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 151 / 744], [train main loss -8.306443], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 152 / 744], [train main loss -8.280343], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 153 / 744], [train main loss -8.287757], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 154 / 744], [train main loss -8.254016], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 155 / 744], [train main loss -8.276895], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 156 / 744], [train main loss -8.257546], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 157 / 744], [train main loss -8.231264], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 158 / 744], [train main loss -8.244771], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 159 / 744], [train main loss -8.236589], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 160 / 744], [train main loss -8.239291], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 161 / 744], [train main loss -8.225514], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 162 / 744], [train main loss -8.238593], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 163 / 744], [train main loss -8.263136], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 164 / 744], [train main loss -8.255945], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 165 / 744], [train main loss -8.271894], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 166 / 744], [train main loss -8.260051], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 167 / 744], [train main loss -8.267759], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 168 / 744], [train main loss -8.285724], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 169 / 744], [train main loss -8.297848], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 170 / 744], [train main loss -8.282891], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 171 / 744], [train main loss -8.284874], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 172 / 744], [train main loss -8.273259], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 173 / 744], [train main loss -8.253517], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 174 / 744], [train main loss -8.241599], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 175 / 744], [train main loss -8.271880], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 176 / 744], [train main loss -8.243344], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 177 / 744], [train main loss -8.224726], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 178 / 744], [train main loss -8.211194], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 179 / 744], [train main loss -8.188029], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 180 / 744], [train main loss -8.145036], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 181 / 744], [train main loss -8.143052], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 182 / 744], [train main loss -8.152094], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 183 / 744], [train main loss -8.139558], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 184 / 744], [train main loss -8.137900], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 185 / 744], [train main loss -8.120141], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 186 / 744], [train main loss -8.125933], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 187 / 744], [train main loss -8.130961], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 188 / 744], [train main loss -8.126312], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 189 / 744], [train main loss -8.124845], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 190 / 744], [train main loss -8.117877], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 191 / 744], [train main loss -8.128864], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 192 / 744], [train main loss -8.126969], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 193 / 744], [train main loss -8.098382], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 194 / 744], [train main loss -8.082975], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 195 / 744], [train main loss -8.072913], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 196 / 744], [train main loss -8.041134], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 197 / 744], [train main loss -8.045920], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 198 / 744], [train main loss -8.067536], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 199 / 744], [train main loss -8.079532], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 200 / 744], [train main loss -8.090248], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 201 / 744], [train main loss -8.090318], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 202 / 744], [train main loss -8.081140], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 203 / 744], [train main loss -8.069599], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 204 / 744], [train main loss -8.085421], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 205 / 744], [train main loss -8.086476], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 206 / 744], [train main loss -8.107692], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 207 / 744], [train main loss -8.123716], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 208 / 744], [train main loss -8.125469], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 209 / 744], [train main loss -8.139029], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 210 / 744], [train main loss -8.158903], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 211 / 744], [train main loss -8.162708], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 212 / 744], [train main loss -8.148259], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 213 / 744], [train main loss -8.165990], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 214 / 744], [train main loss -8.182690], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 215 / 744], [train main loss -8.194102], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 216 / 744], [train main loss -8.184747], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 217 / 744], [train main loss -8.162763], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 218 / 744], [train main loss -8.170111], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 219 / 744], [train main loss -8.190638], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 220 / 744], [train main loss -8.180591], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 221 / 744], [train main loss -8.181161], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 222 / 744], [train main loss -8.153311], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 223 / 744], [train main loss -8.146885], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 224 / 744], [train main loss -8.142756], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 225 / 744], [train main loss -8.154715], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 226 / 744], [train main loss -8.130676], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 227 / 744], [train main loss -8.151421], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 228 / 744], [train main loss -8.139048], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 229 / 744], [train main loss -8.152954], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 230 / 744], [train main loss -8.146956], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 231 / 744], [train main loss -8.119897], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 232 / 744], [train main loss -8.115458], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 233 / 744], [train main loss -8.117157], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 234 / 744], [train main loss -8.124760], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 235 / 744], [train main loss -8.111880], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 236 / 744], [train main loss -8.133192], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 237 / 744], [train main loss -8.136185], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 238 / 744], [train main loss -8.148729], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 239 / 744], [train main loss -8.160307], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 240 / 744], [train main loss -8.159366], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 241 / 744], [train main loss -8.181714], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 242 / 744], [train main loss -8.179520], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 243 / 744], [train main loss -8.173572], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 244 / 744], [train main loss -8.162369], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 245 / 744], [train main loss -8.152891], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 246 / 744], [train main loss -8.135694], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 247 / 744], [train main loss -8.131876], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 248 / 744], [train main loss -8.121843], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 249 / 744], [train main loss -8.119123], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 250 / 744], [train main loss -8.103152], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 251 / 744], [train main loss -8.101936], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 252 / 744], [train main loss -8.097457], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 253 / 744], [train main loss -8.107202], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 254 / 744], [train main loss -8.114850], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 255 / 744], [train main loss -8.109556], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 256 / 744], [train main loss -8.129965], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 257 / 744], [train main loss -8.118960], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 258 / 744], [train main loss -8.104309], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 259 / 744], [train main loss -8.113665], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 260 / 744], [train main loss -8.124665], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 261 / 744], [train main loss -8.119422], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 262 / 744], [train main loss -8.127956], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 263 / 744], [train main loss -8.127902], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 264 / 744], [train main loss -8.156625], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 265 / 744], [train main loss -8.159052], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 266 / 744], [train main loss -8.177068], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 267 / 744], [train main loss -8.196254], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 268 / 744], [train main loss -8.208548], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 269 / 744], [train main loss -8.210758], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 270 / 744], [train main loss -8.217651], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 271 / 744], [train main loss -8.211848], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 272 / 744], [train main loss -8.206986], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 273 / 744], [train main loss -8.205432], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 274 / 744], [train main loss -8.198512], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 275 / 744], [train main loss -8.182508], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 276 / 744], [train main loss -8.186266], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 277 / 744], [train main loss -8.186631], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 278 / 744], [train main loss -8.209898], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 279 / 744], [train main loss -8.216193], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 280 / 744], [train main loss -8.209121], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 281 / 744], [train main loss -8.206559], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 282 / 744], [train main loss -8.226128], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 283 / 744], [train main loss -8.211986], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 284 / 744], [train main loss -8.209197], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 285 / 744], [train main loss -8.202964], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 286 / 744], [train main loss -8.186443], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 287 / 744], [train main loss -8.162959], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 288 / 744], [train main loss -8.146589], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 289 / 744], [train main loss -8.131610], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 290 / 744], [train main loss -8.131981], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 291 / 744], [train main loss -8.141328], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 292 / 744], [train main loss -8.156796], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 293 / 744], [train main loss -8.151356], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 294 / 744], [train main loss -8.161963], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 295 / 744], [train main loss -8.171266], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 296 / 744], [train main loss -8.162008], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 297 / 744], [train main loss -8.175997], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 298 / 744], [train main loss -8.158074], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 299 / 744], [train main loss -8.147919], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 300 / 744], [train main loss -8.154464], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 301 / 744], [train main loss -8.152395], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 302 / 744], [train main loss -8.159383], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 303 / 744], [train main loss -8.188583], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 304 / 744], [train main loss -8.173371], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 305 / 744], [train main loss -8.169777], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 306 / 744], [train main loss -8.183932], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 307 / 744], [train main loss -8.203333], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 308 / 744], [train main loss -8.209986], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 309 / 744], [train main loss -8.195993], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 310 / 744], [train main loss -8.195010], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 311 / 744], [train main loss -8.179102], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 312 / 744], [train main loss -8.200758], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 313 / 744], [train main loss -8.198492], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 314 / 744], [train main loss -8.205477], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 315 / 744], [train main loss -8.200320], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 316 / 744], [train main loss -8.222245], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 317 / 744], [train main loss -8.220802], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 318 / 744], [train main loss -8.225941], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 319 / 744], [train main loss -8.236709], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 320 / 744], [train main loss -8.221103], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 321 / 744], [train main loss -8.229293], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 322 / 744], [train main loss -8.241240], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 323 / 744], [train main loss -8.238396], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 324 / 744], [train main loss -8.244949], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 325 / 744], [train main loss -8.234694], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 326 / 744], [train main loss -8.227520], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 327 / 744], [train main loss -8.238626], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 328 / 744], [train main loss -8.242014], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 329 / 744], [train main loss -8.239252], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 330 / 744], [train main loss -8.238232], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 331 / 744], [train main loss -8.246452], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 332 / 744], [train main loss -8.248341], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 333 / 744], [train main loss -8.255460], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 334 / 744], [train main loss -8.248948], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 335 / 744], [train main loss -8.240049], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 336 / 744], [train main loss -8.226195], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 337 / 744], [train main loss -8.216314], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 338 / 744], [train main loss -8.205299], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 339 / 744], [train main loss -8.198084], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 340 / 744], [train main loss -8.218732], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 341 / 744], [train main loss -8.217237], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 342 / 744], [train main loss -8.213113], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 343 / 744], [train main loss -8.188862], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 344 / 744], [train main loss -8.203947], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 345 / 744], [train main loss -8.219056], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 346 / 744], [train main loss -8.226077], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 347 / 744], [train main loss -8.245478], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 348 / 744], [train main loss -8.244844], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 349 / 744], [train main loss -8.231670], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 350 / 744], [train main loss -8.236341], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 351 / 744], [train main loss -8.233706], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 352 / 744], [train main loss -8.235083], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 353 / 744], [train main loss -8.239793], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 354 / 744], [train main loss -8.275468], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 355 / 744], [train main loss -8.300357], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 356 / 744], [train main loss -8.304093], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 357 / 744], [train main loss -8.293460], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 358 / 744], [train main loss -8.311460], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 359 / 744], [train main loss -8.330673], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 360 / 744], [train main loss -8.331159], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 361 / 744], [train main loss -8.330971], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 362 / 744], [train main loss -8.324203], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 363 / 744], [train main loss -8.322738], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 364 / 744], [train main loss -8.325933], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 365 / 744], [train main loss -8.324976], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 366 / 744], [train main loss -8.338295], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 367 / 744], [train main loss -8.334062], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 368 / 744], [train main loss -8.331668], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 369 / 744], [train main loss -8.331394], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 370 / 744], [train main loss -8.321464], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 371 / 744], [train main loss -8.336364], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 372 / 744], [train main loss -8.347452], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 373 / 744], [train main loss -8.339884], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 374 / 744], [train main loss -8.349303], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 375 / 744], [train main loss -8.339122], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 376 / 744], [train main loss -8.346843], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 377 / 744], [train main loss -8.341829], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 378 / 744], [train main loss -8.328615], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 379 / 744], [train main loss -8.339488], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 380 / 744], [train main loss -8.347875], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 381 / 744], [train main loss -8.343220], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 382 / 744], [train main loss -8.330535], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 383 / 744], [train main loss -8.331936], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 384 / 744], [train main loss -8.320634], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 385 / 744], [train main loss -8.326141], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 386 / 744], [train main loss -8.323238], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 387 / 744], [train main loss -8.334214], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 388 / 744], [train main loss -8.339585], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 389 / 744], [train main loss -8.345289], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 390 / 744], [train main loss -8.349981], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 391 / 744], [train main loss -8.349807], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 392 / 744], [train main loss -8.360550], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 393 / 744], [train main loss -8.366019], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 394 / 744], [train main loss -8.363330], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 395 / 744], [train main loss -8.356946], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 396 / 744], [train main loss -8.351667], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 397 / 744], [train main loss -8.355763], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 398 / 744], [train main loss -8.354422], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 399 / 744], [train main loss -8.345342], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 400 / 744], [train main loss -8.332187], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 401 / 744], [train main loss -8.346398], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 402 / 744], [train main loss -8.346975], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 403 / 744], [train main loss -8.333254], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 404 / 744], [train main loss -8.333691], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 405 / 744], [train main loss -8.357134], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 406 / 744], [train main loss -8.355379], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 407 / 744], [train main loss -8.353050], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 408 / 744], [train main loss -8.334872], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 409 / 744], [train main loss -8.318513], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 410 / 744], [train main loss -8.305741], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 411 / 744], [train main loss -8.308330], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 412 / 744], [train main loss -8.308342], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 413 / 744], [train main loss -8.299048], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 414 / 744], [train main loss -8.300044], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 415 / 744], [train main loss -8.304409], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 416 / 744], [train main loss -8.310065], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 417 / 744], [train main loss -8.319601], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 418 / 744], [train main loss -8.321579], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 419 / 744], [train main loss -8.333282], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 420 / 744], [train main loss -8.344686], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 421 / 744], [train main loss -8.340046], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 422 / 744], [train main loss -8.354718], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 423 / 744], [train main loss -8.360469], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 424 / 744], [train main loss -8.385964], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 425 / 744], [train main loss -8.375236], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 426 / 744], [train main loss -8.380032], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 427 / 744], [train main loss -8.381488], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 428 / 744], [train main loss -8.387261], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 429 / 744], [train main loss -8.394760], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 430 / 744], [train main loss -8.386185], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 431 / 744], [train main loss -8.390811], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 432 / 744], [train main loss -8.392996], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 433 / 744], [train main loss -8.389374], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 434 / 744], [train main loss -8.384229], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 435 / 744], [train main loss -8.384087], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 436 / 744], [train main loss -8.388605], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 437 / 744], [train main loss -8.384900], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 438 / 744], [train main loss -8.386084], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 439 / 744], [train main loss -8.369003], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 440 / 744], [train main loss -8.372922], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 441 / 744], [train main loss -8.371587], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 442 / 744], [train main loss -8.363993], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 443 / 744], [train main loss -8.354311], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 444 / 744], [train main loss -8.372318], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 445 / 744], [train main loss -8.377348], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 446 / 744], [train main loss -8.380495], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 447 / 744], [train main loss -8.385410], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 448 / 744], [train main loss -8.381332], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 449 / 744], [train main loss -8.391932], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 450 / 744], [train main loss -8.396096], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 451 / 744], [train main loss -8.401250], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 452 / 744], [train main loss -8.390455], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 453 / 744], [train main loss -8.389117], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 454 / 744], [train main loss -8.387541], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 455 / 744], [train main loss -8.382896], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 456 / 744], [train main loss -8.383825], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 457 / 744], [train main loss -8.378074], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 458 / 744], [train main loss -8.386260], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 459 / 744], [train main loss -8.377557], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 460 / 744], [train main loss -8.375105], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 461 / 744], [train main loss -8.380774], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 462 / 744], [train main loss -8.376248], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 463 / 744], [train main loss -8.377682], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 464 / 744], [train main loss -8.382049], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 465 / 744], [train main loss -8.386584], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 466 / 744], [train main loss -8.379368], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 467 / 744], [train main loss -8.387576], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 468 / 744], [train main loss -8.391226], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 469 / 744], [train main loss -8.382960], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 470 / 744], [train main loss -8.377928], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 471 / 744], [train main loss -8.372521], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 472 / 744], [train main loss -8.371135], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 473 / 744], [train main loss -8.374892], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 474 / 744], [train main loss -8.372542], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 475 / 744], [train main loss -8.364774], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 476 / 744], [train main loss -8.355248], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 477 / 744], [train main loss -8.370220], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 478 / 744], [train main loss -8.364130], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 479 / 744], [train main loss -8.380375], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 480 / 744], [train main loss -8.393096], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 481 / 744], [train main loss -8.396630], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 482 / 744], [train main loss -8.406655], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 483 / 744], [train main loss -8.397554], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 484 / 744], [train main loss -8.411864], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 485 / 744], [train main loss -8.409520], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 486 / 744], [train main loss -8.416777], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 487 / 744], [train main loss -8.419286], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 488 / 744], [train main loss -8.419465], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 489 / 744], [train main loss -8.417218], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 490 / 744], [train main loss -8.413975], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 491 / 744], [train main loss -8.426253], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 492 / 744], [train main loss -8.420253], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 493 / 744], [train main loss -8.414475], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 494 / 744], [train main loss -8.411409], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 495 / 744], [train main loss -8.413155], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 496 / 744], [train main loss -8.420419], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 497 / 744], [train main loss -8.426104], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 498 / 744], [train main loss -8.415324], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 499 / 744], [train main loss -8.426094], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 500 / 744], [train main loss -8.430571], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 501 / 744], [train main loss -8.446971], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 502 / 744], [train main loss -8.449720], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 503 / 744], [train main loss -8.458305], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 504 / 744], [train main loss -8.462722], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 505 / 744], [train main loss -8.452196], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 506 / 744], [train main loss -8.449726], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 507 / 744], [train main loss -8.443359], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 508 / 744], [train main loss -8.443228], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 509 / 744], [train main loss -8.446517], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 510 / 744], [train main loss -8.443440], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 511 / 744], [train main loss -8.448642], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 512 / 744], [train main loss -8.453984], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 513 / 744], [train main loss -8.448509], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 514 / 744], [train main loss -8.451650], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 515 / 744], [train main loss -8.447390], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 516 / 744], [train main loss -8.452867], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 517 / 744], [train main loss -8.449180], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 518 / 744], [train main loss -8.436566], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 519 / 744], [train main loss -8.444095], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 520 / 744], [train main loss -8.443424], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 521 / 744], [train main loss -8.435395], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 522 / 744], [train main loss -8.443134], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 523 / 744], [train main loss -8.445015], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 524 / 744], [train main loss -8.442959], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 525 / 744], [train main loss -8.426948], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 526 / 744], [train main loss -8.431850], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 527 / 744], [train main loss -8.433096], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 528 / 744], [train main loss -8.426091], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 529 / 744], [train main loss -8.434455], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 530 / 744], [train main loss -8.440036], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 531 / 744], [train main loss -8.436784], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 532 / 744], [train main loss -8.433703], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 533 / 744], [train main loss -8.438400], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 534 / 744], [train main loss -8.442480], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 535 / 744], [train main loss -8.441809], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 536 / 744], [train main loss -8.447917], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 537 / 744], [train main loss -8.454169], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 538 / 744], [train main loss -8.453956], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 539 / 744], [train main loss -8.445604], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 540 / 744], [train main loss -8.458920], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 541 / 744], [train main loss -8.462121], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 542 / 744], [train main loss -8.454839], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 543 / 744], [train main loss -8.457353], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 544 / 744], [train main loss -8.468336], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 545 / 744], [train main loss -8.462228], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 546 / 744], [train main loss -8.466611], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 547 / 744], [train main loss -8.455553], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 548 / 744], [train main loss -8.456761], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 549 / 744], [train main loss -8.466639], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 550 / 744], [train main loss -8.465974], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 551 / 744], [train main loss -8.465683], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 552 / 744], [train main loss -8.465579], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 553 / 744], [train main loss -8.470340], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 554 / 744], [train main loss -8.462236], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 555 / 744], [train main loss -8.458341], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 556 / 744], [train main loss -8.458257], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 557 / 744], [train main loss -8.459794], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 558 / 744], [train main loss -8.460326], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 559 / 744], [train main loss -8.448917], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 560 / 744], [train main loss -8.443248], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 561 / 744], [train main loss -8.452939], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 562 / 744], [train main loss -8.455214], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 563 / 744], [train main loss -8.451760], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 564 / 744], [train main loss -8.441521], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 565 / 744], [train main loss -8.439350], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 566 / 744], [train main loss -8.436912], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 567 / 744], [train main loss -8.439961], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 568 / 744], [train main loss -8.438261], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 569 / 744], [train main loss -8.435895], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 570 / 744], [train main loss -8.445642], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 571 / 744], [train main loss -8.441704], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 572 / 744], [train main loss -8.433050], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 573 / 744], [train main loss -8.434975], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 574 / 744], [train main loss -8.436796], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 575 / 744], [train main loss -8.438620], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 576 / 744], [train main loss -8.444362], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 577 / 744], [train main loss -8.438661], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 578 / 744], [train main loss -8.435846], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 579 / 744], [train main loss -8.435333], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 580 / 744], [train main loss -8.431225], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 581 / 744], [train main loss -8.420303], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 582 / 744], [train main loss -8.432432], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 583 / 744], [train main loss -8.428859], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 584 / 744], [train main loss -8.437042], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 585 / 744], [train main loss -8.441354], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 586 / 744], [train main loss -8.440216], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 587 / 744], [train main loss -8.444785], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 588 / 744], [train main loss -8.442855], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 589 / 744], [train main loss -8.441511], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 590 / 744], [train main loss -8.440844], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 591 / 744], [train main loss -8.443244], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 592 / 744], [train main loss -8.435945], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 593 / 744], [train main loss -8.432324], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 594 / 744], [train main loss -8.428712], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 595 / 744], [train main loss -8.429355], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 596 / 744], [train main loss -8.436930], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 597 / 744], [train main loss -8.431509], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 598 / 744], [train main loss -8.430899], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 599 / 744], [train main loss -8.430504], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 600 / 744], [train main loss -8.428230], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 601 / 744], [train main loss -8.425816], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 602 / 744], [train main loss -8.422949], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 603 / 744], [train main loss -8.418671], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 604 / 744], [train main loss -8.418895], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 605 / 744], [train main loss -8.425405], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 606 / 744], [train main loss -8.430238], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 607 / 744], [train main loss -8.433169], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 608 / 744], [train main loss -8.430053], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 609 / 744], [train main loss -8.422474], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 610 / 744], [train main loss -8.426025], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 611 / 744], [train main loss -8.416416], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 612 / 744], [train main loss -8.419178], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 613 / 744], [train main loss -8.414742], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 614 / 744], [train main loss -8.415462], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 615 / 744], [train main loss -8.422902], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 616 / 744], [train main loss -8.422667], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 617 / 744], [train main loss -8.418297], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 618 / 744], [train main loss -8.408250], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 619 / 744], [train main loss -8.406451], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 620 / 744], [train main loss -8.405583], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 621 / 744], [train main loss -8.412732], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 622 / 744], [train main loss -8.415724], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 623 / 744], [train main loss -8.412835], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 624 / 744], [train main loss -8.417860], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 625 / 744], [train main loss -8.417913], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 626 / 744], [train main loss -8.422315], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 627 / 744], [train main loss -8.430597], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 628 / 744], [train main loss -8.433540], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 629 / 744], [train main loss -8.427734], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 630 / 744], [train main loss -8.428656], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 631 / 744], [train main loss -8.429962], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 632 / 744], [train main loss -8.421884], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 633 / 744], [train main loss -8.426227], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 634 / 744], [train main loss -8.429970], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 635 / 744], [train main loss -8.429913], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 636 / 744], [train main loss -8.423712], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 637 / 744], [train main loss -8.434795], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 638 / 744], [train main loss -8.439672], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 639 / 744], [train main loss -8.438489], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 640 / 744], [train main loss -8.438555], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 641 / 744], [train main loss -8.442753], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 642 / 744], [train main loss -8.435376], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 643 / 744], [train main loss -8.439782], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 644 / 744], [train main loss -8.434970], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 645 / 744], [train main loss -8.439380], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 646 / 744], [train main loss -8.433603], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 647 / 744], [train main loss -8.435521], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 648 / 744], [train main loss -8.435264], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 649 / 744], [train main loss -8.433255], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 650 / 744], [train main loss -8.429868], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 651 / 744], [train main loss -8.424519], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 652 / 744], [train main loss -8.425921], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 653 / 744], [train main loss -8.428896], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 654 / 744], [train main loss -8.430429], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 655 / 744], [train main loss -8.426276], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 656 / 744], [train main loss -8.423386], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 657 / 744], [train main loss -8.425907], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 658 / 744], [train main loss -8.429628], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 659 / 744], [train main loss -8.424514], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 660 / 744], [train main loss -8.427062], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 661 / 744], [train main loss -8.433272], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 662 / 744], [train main loss -8.436798], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 663 / 744], [train main loss -8.441913], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 664 / 744], [train main loss -8.449853], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 665 / 744], [train main loss -8.455010], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 666 / 744], [train main loss -8.451121], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 667 / 744], [train main loss -8.445280], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 668 / 744], [train main loss -8.448978], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 669 / 744], [train main loss -8.446423], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 670 / 744], [train main loss -8.455786], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 671 / 744], [train main loss -8.461470], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 672 / 744], [train main loss -8.460134], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 673 / 744], [train main loss -8.468967], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 674 / 744], [train main loss -8.470171], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 675 / 744], [train main loss -8.469307], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 676 / 744], [train main loss -8.469768], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 677 / 744], [train main loss -8.465907], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 678 / 744], [train main loss -8.466770], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 679 / 744], [train main loss -8.462810], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 680 / 744], [train main loss -8.468330], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 681 / 744], [train main loss -8.469132], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 682 / 744], [train main loss -8.471392], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 683 / 744], [train main loss -8.467096], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 684 / 744], [train main loss -8.468908], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 685 / 744], [train main loss -8.470855], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 686 / 744], [train main loss -8.468696], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 687 / 744], [train main loss -8.464442], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 688 / 744], [train main loss -8.471753], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 689 / 744], [train main loss -8.473476], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 690 / 744], [train main loss -8.469860], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 691 / 744], [train main loss -8.472155], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 692 / 744], [train main loss -8.472250], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 693 / 744], [train main loss -8.475662], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 694 / 744], [train main loss -8.491944], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 695 / 744], [train main loss -8.486616], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 696 / 744], [train main loss -8.484837], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 697 / 744], [train main loss -8.483353], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 698 / 744], [train main loss -8.487143], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 699 / 744], [train main loss -8.487085], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 700 / 744], [train main loss -8.492143], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 701 / 744], [train main loss -8.485158], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 702 / 744], [train main loss -8.489464], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 703 / 744], [train main loss -8.487650], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 704 / 744], [train main loss -8.499469], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 705 / 744], [train main loss -8.499673], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 706 / 744], [train main loss -8.496186], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 707 / 744], [train main loss -8.498306], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 708 / 744], [train main loss -8.492379], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 709 / 744], [train main loss -8.499985], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 710 / 744], [train main loss -8.507517], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 711 / 744], [train main loss -8.502710], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 712 / 744], [train main loss -8.506839], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 713 / 744], [train main loss -8.507421], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 714 / 744], [train main loss -8.506704], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 715 / 744], [train main loss -8.500698], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 716 / 744], [train main loss -8.498462], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 717 / 744], [train main loss -8.492566], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 718 / 744], [train main loss -8.484119], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 719 / 744], [train main loss -8.479579], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 720 / 744], [train main loss -8.482657], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 721 / 744], [train main loss -8.481464], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 722 / 744], [train main loss -8.477756], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 723 / 744], [train main loss -8.483639], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 724 / 744], [train main loss -8.484515], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 725 / 744], [train main loss -8.490764], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 726 / 744], [train main loss -8.495851], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 727 / 744], [train main loss -8.501476], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 728 / 744], [train main loss -8.504877], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 729 / 744], [train main loss -8.508810], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 730 / 744], [train main loss -8.507271], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 731 / 744], [train main loss -8.506925], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 732 / 744], [train main loss -8.511628], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 733 / 744], [train main loss -8.511134], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 734 / 744], [train main loss -8.509898], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 735 / 744], [train main loss -8.502601], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 736 / 744], [train main loss -8.495975], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 737 / 744], [train main loss -8.502339], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 738 / 744], [train main loss -8.494122], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 739 / 744], [train main loss -8.497475], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 740 / 744], [train main loss -8.502074], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 741 / 744], [train main loss -8.494627], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 742 / 744], [train main loss -8.494183], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 743 / 744], [train main loss -8.492550], [lr 0.004830] [batchtime 1.14]
[epoch 3], [iter 744 / 744], [train main loss -8.489394], [lr 0.004830] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              98.15  37.22  0.01  0.01         0.99      0.99
   1  sidewalk          85.28   5.01  0.08  0.09         0.93      0.91
   2  building          92.59  21.23  0.03  0.05         0.97      0.95
   3  wall              57.47   0.53  0.39  0.35         0.72      0.74
   4  fence             59.57   0.57  0.44  0.24         0.70      0.80
   5  pole              70.09   1.17  0.26  0.17         0.79      0.86
   6  traffic light     75.27   0.18  0.12  0.21         0.89      0.83
   7  traffic sign      81.02   0.56  0.19  0.05         0.84      0.96
   8  vegetation        90.46  16.16  0.07  0.03         0.93      0.97
   9  terrain           48.66   0.71  0.16  0.89         0.86      0.53
  10  sky               94.06   3.32  0.01  0.05         0.99      0.95
  11  person            81.82   1.21  0.07  0.15         0.93      0.87
  12  rider             63.74   0.16  0.32  0.25         0.76      0.80
  13  car               95.59   6.40  0.02  0.03         0.98      0.97
  14  truck             85.63   0.27  0.13  0.03         0.88      0.97
  15  bus               84.91   0.33  0.16  0.01         0.86      0.99
  16  train             67.68   0.10  0.13  0.35         0.89      0.74
  17  motorcycle        58.81   0.05  0.53  0.17         0.66      0.85
  18  bicycle           77.93   0.61  0.16  0.12         0.86      0.89
Mean: 77.30
-----------------------------------------------------------------------------------------------------------
this : [epoch 3], [val loss 0.15364], [acc 0.95792], [acc_cls 0.86463], [mean_iu 0.77303], [fwavacc 0.92418]
best : [epoch 2], [val loss 0.15303], [acc 0.95799], [acc_cls 0.84888], [mean_iu 0.77525], [fwavacc 0.92257]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 4], [iter 1 / 744], [train main loss -12.379910], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 2 / 744], [train main loss -10.244112], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 3 / 744], [train main loss -10.017487], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 4 / 744], [train main loss -10.195479], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 5 / 744], [train main loss -10.548919], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 6 / 744], [train main loss -10.017047], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 7 / 744], [train main loss -9.507161], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 8 / 744], [train main loss -9.001111], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 9 / 744], [train main loss -9.247105], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 10 / 744], [train main loss -9.793587], [lr 0.004774] [batchtime 0]
[epoch 4], [iter 11 / 744], [train main loss -9.214832], [lr 0.004774] [batchtime 1.13]
[epoch 4], [iter 12 / 744], [train main loss -9.740123], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 13 / 744], [train main loss -9.873991], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 14 / 744], [train main loss -9.865583], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 15 / 744], [train main loss -9.721901], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 16 / 744], [train main loss -9.537126], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 17 / 744], [train main loss -9.748068], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 18 / 744], [train main loss -9.467511], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 19 / 744], [train main loss -9.440364], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 20 / 744], [train main loss -9.738635], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 21 / 744], [train main loss -9.665685], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 22 / 744], [train main loss -9.540122], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 23 / 744], [train main loss -9.528771], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 24 / 744], [train main loss -9.519715], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 25 / 744], [train main loss -9.519919], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 26 / 744], [train main loss -9.249460], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 27 / 744], [train main loss -9.378835], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 28 / 744], [train main loss -9.397497], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 29 / 744], [train main loss -9.520337], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 30 / 744], [train main loss -9.476443], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 31 / 744], [train main loss -9.583675], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 32 / 744], [train main loss -9.594582], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 33 / 744], [train main loss -9.487916], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 34 / 744], [train main loss -9.291925], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 35 / 744], [train main loss -9.432763], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 36 / 744], [train main loss -9.430760], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 37 / 744], [train main loss -9.337532], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 38 / 744], [train main loss -9.556729], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 39 / 744], [train main loss -9.583905], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 40 / 744], [train main loss -9.568773], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 41 / 744], [train main loss -9.642603], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 42 / 744], [train main loss -9.502968], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 43 / 744], [train main loss -9.452039], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 44 / 744], [train main loss -9.518703], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 45 / 744], [train main loss -9.363352], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 46 / 744], [train main loss -9.473511], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 47 / 744], [train main loss -9.395236], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 48 / 744], [train main loss -9.476200], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 49 / 744], [train main loss -9.419406], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 50 / 744], [train main loss -9.452663], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 51 / 744], [train main loss -9.429361], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 52 / 744], [train main loss -9.382180], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 53 / 744], [train main loss -9.391737], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 54 / 744], [train main loss -9.518284], [lr 0.004774] [batchtime 1.15]
[epoch 4], [iter 55 / 744], [train main loss -9.520824], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 56 / 744], [train main loss -9.547551], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 57 / 744], [train main loss -9.490155], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 58 / 744], [train main loss -9.392086], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 59 / 744], [train main loss -9.327949], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 60 / 744], [train main loss -9.358627], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 61 / 744], [train main loss -9.312081], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 62 / 744], [train main loss -9.255358], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 63 / 744], [train main loss -9.266677], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 64 / 744], [train main loss -9.223222], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 65 / 744], [train main loss -9.288439], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 66 / 744], [train main loss -9.330136], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 67 / 744], [train main loss -9.281335], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 68 / 744], [train main loss -9.248494], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 69 / 744], [train main loss -9.333038], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 70 / 744], [train main loss -9.266097], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 71 / 744], [train main loss -9.263239], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 72 / 744], [train main loss -9.195402], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 73 / 744], [train main loss -9.178219], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 74 / 744], [train main loss -9.146194], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 75 / 744], [train main loss -9.121084], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 76 / 744], [train main loss -9.083005], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 77 / 744], [train main loss -9.033476], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 78 / 744], [train main loss -9.081427], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 79 / 744], [train main loss -9.076503], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 80 / 744], [train main loss -9.094399], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 81 / 744], [train main loss -9.144536], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 82 / 744], [train main loss -9.173122], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 83 / 744], [train main loss -9.223450], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 84 / 744], [train main loss -9.225873], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 85 / 744], [train main loss -9.222712], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 86 / 744], [train main loss -9.197650], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 87 / 744], [train main loss -9.152099], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 88 / 744], [train main loss -9.107614], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 89 / 744], [train main loss -9.115261], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 90 / 744], [train main loss -9.118007], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 91 / 744], [train main loss -9.174652], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 92 / 744], [train main loss -9.156036], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 93 / 744], [train main loss -9.171376], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 94 / 744], [train main loss -9.091652], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 95 / 744], [train main loss -9.079240], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 96 / 744], [train main loss -9.041004], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 97 / 744], [train main loss -9.015566], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 98 / 744], [train main loss -9.030920], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 99 / 744], [train main loss -9.006214], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 100 / 744], [train main loss -8.991099], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 101 / 744], [train main loss -9.006964], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 102 / 744], [train main loss -9.013636], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 103 / 744], [train main loss -8.959958], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 104 / 744], [train main loss -8.942275], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 105 / 744], [train main loss -8.964934], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 106 / 744], [train main loss -8.990193], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 107 / 744], [train main loss -9.034886], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 108 / 744], [train main loss -9.002240], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 109 / 744], [train main loss -9.038838], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 110 / 744], [train main loss -9.029165], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 111 / 744], [train main loss -8.996934], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 112 / 744], [train main loss -9.016302], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 113 / 744], [train main loss -9.036681], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 114 / 744], [train main loss -9.001426], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 115 / 744], [train main loss -8.966508], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 116 / 744], [train main loss -8.999977], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 117 / 744], [train main loss -8.991154], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 118 / 744], [train main loss -9.008988], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 119 / 744], [train main loss -8.974846], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 120 / 744], [train main loss -8.950898], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 121 / 744], [train main loss -8.905153], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 122 / 744], [train main loss -8.948012], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 123 / 744], [train main loss -8.917397], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 124 / 744], [train main loss -8.935878], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 125 / 744], [train main loss -8.906520], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 126 / 744], [train main loss -8.890019], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 127 / 744], [train main loss -8.859551], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 128 / 744], [train main loss -8.854445], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 129 / 744], [train main loss -8.841156], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 130 / 744], [train main loss -8.848867], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 131 / 744], [train main loss -8.837147], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 132 / 744], [train main loss -8.890366], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 133 / 744], [train main loss -8.900233], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 134 / 744], [train main loss -8.900378], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 135 / 744], [train main loss -8.896242], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 136 / 744], [train main loss -8.915782], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 137 / 744], [train main loss -8.884699], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 138 / 744], [train main loss -8.887386], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 139 / 744], [train main loss -8.869096], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 140 / 744], [train main loss -8.893206], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 141 / 744], [train main loss -8.937103], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 142 / 744], [train main loss -8.894149], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 143 / 744], [train main loss -8.928274], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 144 / 744], [train main loss -8.938136], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 145 / 744], [train main loss -8.937757], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 146 / 744], [train main loss -8.880323], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 147 / 744], [train main loss -8.896287], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 148 / 744], [train main loss -8.869318], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 149 / 744], [train main loss -8.830359], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 150 / 744], [train main loss -8.835240], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 151 / 744], [train main loss -8.862127], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 152 / 744], [train main loss -8.850658], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 153 / 744], [train main loss -8.888679], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 154 / 744], [train main loss -8.885425], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 155 / 744], [train main loss -8.902764], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 156 / 744], [train main loss -8.887209], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 157 / 744], [train main loss -8.891551], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 158 / 744], [train main loss -8.926489], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 159 / 744], [train main loss -8.936008], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 160 / 744], [train main loss -8.921313], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 161 / 744], [train main loss -8.949137], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 162 / 744], [train main loss -8.945107], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 163 / 744], [train main loss -8.972295], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 164 / 744], [train main loss -8.927117], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 165 / 744], [train main loss -8.918027], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 166 / 744], [train main loss -8.921349], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 167 / 744], [train main loss -8.926860], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 168 / 744], [train main loss -8.928604], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 169 / 744], [train main loss -8.925704], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 170 / 744], [train main loss -8.909338], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 171 / 744], [train main loss -8.902227], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 172 / 744], [train main loss -8.913741], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 173 / 744], [train main loss -8.913494], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 174 / 744], [train main loss -8.924192], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 175 / 744], [train main loss -8.883882], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 176 / 744], [train main loss -8.905528], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 177 / 744], [train main loss -8.903714], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 178 / 744], [train main loss -8.948478], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 179 / 744], [train main loss -8.927619], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 180 / 744], [train main loss -8.930426], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 181 / 744], [train main loss -8.954620], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 182 / 744], [train main loss -8.936879], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 183 / 744], [train main loss -8.924045], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 184 / 744], [train main loss -8.886225], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 185 / 744], [train main loss -8.882172], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 186 / 744], [train main loss -8.884011], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 187 / 744], [train main loss -8.869796], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 188 / 744], [train main loss -8.873990], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 189 / 744], [train main loss -8.871199], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 190 / 744], [train main loss -8.854144], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 191 / 744], [train main loss -8.854588], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 192 / 744], [train main loss -8.862381], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 193 / 744], [train main loss -8.850177], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 194 / 744], [train main loss -8.854541], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 195 / 744], [train main loss -8.850233], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 196 / 744], [train main loss -8.877806], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 197 / 744], [train main loss -8.874508], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 198 / 744], [train main loss -8.877090], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 199 / 744], [train main loss -8.904555], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 200 / 744], [train main loss -8.890129], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 201 / 744], [train main loss -8.915921], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 202 / 744], [train main loss -8.901503], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 203 / 744], [train main loss -8.910226], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 204 / 744], [train main loss -8.899565], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 205 / 744], [train main loss -8.886546], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 206 / 744], [train main loss -8.875068], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 207 / 744], [train main loss -8.866533], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 208 / 744], [train main loss -8.864051], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 209 / 744], [train main loss -8.896378], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 210 / 744], [train main loss -8.883048], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 211 / 744], [train main loss -8.859618], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 212 / 744], [train main loss -8.887389], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 213 / 744], [train main loss -8.871716], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 214 / 744], [train main loss -8.882652], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 215 / 744], [train main loss -8.884060], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 216 / 744], [train main loss -8.887754], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 217 / 744], [train main loss -8.873753], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 218 / 744], [train main loss -8.870539], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 219 / 744], [train main loss -8.870459], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 220 / 744], [train main loss -8.841714], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 221 / 744], [train main loss -8.847260], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 222 / 744], [train main loss -8.839387], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 223 / 744], [train main loss -8.819866], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 224 / 744], [train main loss -8.825685], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 225 / 744], [train main loss -8.837193], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 226 / 744], [train main loss -8.826205], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 227 / 744], [train main loss -8.813497], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 228 / 744], [train main loss -8.830280], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 229 / 744], [train main loss -8.837024], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 230 / 744], [train main loss -8.817333], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 231 / 744], [train main loss -8.800863], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 232 / 744], [train main loss -8.809885], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 233 / 744], [train main loss -8.816928], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 234 / 744], [train main loss -8.824524], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 235 / 744], [train main loss -8.840186], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 236 / 744], [train main loss -8.813622], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 237 / 744], [train main loss -8.801710], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 238 / 744], [train main loss -8.805740], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 239 / 744], [train main loss -8.801000], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 240 / 744], [train main loss -8.773759], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 241 / 744], [train main loss -8.787648], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 242 / 744], [train main loss -8.794954], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 243 / 744], [train main loss -8.799089], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 244 / 744], [train main loss -8.809279], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 245 / 744], [train main loss -8.821707], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 246 / 744], [train main loss -8.816040], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 247 / 744], [train main loss -8.806765], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 248 / 744], [train main loss -8.802503], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 249 / 744], [train main loss -8.826676], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 250 / 744], [train main loss -8.810215], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 251 / 744], [train main loss -8.811314], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 252 / 744], [train main loss -8.817991], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 253 / 744], [train main loss -8.816546], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 254 / 744], [train main loss -8.801387], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 255 / 744], [train main loss -8.833207], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 256 / 744], [train main loss -8.835906], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 257 / 744], [train main loss -8.837832], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 258 / 744], [train main loss -8.861287], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 259 / 744], [train main loss -8.855773], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 260 / 744], [train main loss -8.849178], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 261 / 744], [train main loss -8.850129], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 262 / 744], [train main loss -8.847238], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 263 / 744], [train main loss -8.858184], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 264 / 744], [train main loss -8.853289], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 265 / 744], [train main loss -8.856950], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 266 / 744], [train main loss -8.844507], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 267 / 744], [train main loss -8.833202], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 268 / 744], [train main loss -8.825763], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 269 / 744], [train main loss -8.815084], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 270 / 744], [train main loss -8.817377], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 271 / 744], [train main loss -8.816005], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 272 / 744], [train main loss -8.818403], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 273 / 744], [train main loss -8.801703], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 274 / 744], [train main loss -8.792812], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 275 / 744], [train main loss -8.801522], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 276 / 744], [train main loss -8.783465], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 277 / 744], [train main loss -8.801339], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 278 / 744], [train main loss -8.777244], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 279 / 744], [train main loss -8.798934], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 280 / 744], [train main loss -8.797098], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 281 / 744], [train main loss -8.796286], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 282 / 744], [train main loss -8.781501], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 283 / 744], [train main loss -8.782926], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 284 / 744], [train main loss -8.777223], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 285 / 744], [train main loss -8.788743], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 286 / 744], [train main loss -8.788236], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 287 / 744], [train main loss -8.769316], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 288 / 744], [train main loss -8.753615], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 289 / 744], [train main loss -8.756905], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 290 / 744], [train main loss -8.760400], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 291 / 744], [train main loss -8.740544], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 292 / 744], [train main loss -8.732156], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 293 / 744], [train main loss -8.724474], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 294 / 744], [train main loss -8.734333], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 295 / 744], [train main loss -8.737933], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 296 / 744], [train main loss -8.724622], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 297 / 744], [train main loss -8.724642], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 298 / 744], [train main loss -8.725892], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 299 / 744], [train main loss -8.722183], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 300 / 744], [train main loss -8.719568], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 301 / 744], [train main loss -8.691560], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 302 / 744], [train main loss -8.689515], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 303 / 744], [train main loss -8.690593], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 304 / 744], [train main loss -8.685202], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 305 / 744], [train main loss -8.673673], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 306 / 744], [train main loss -8.682864], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 307 / 744], [train main loss -8.685768], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 308 / 744], [train main loss -8.687861], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 309 / 744], [train main loss -8.688567], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 310 / 744], [train main loss -8.676852], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 311 / 744], [train main loss -8.671391], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 312 / 744], [train main loss -8.679954], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 313 / 744], [train main loss -8.686741], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 314 / 744], [train main loss -8.702870], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 315 / 744], [train main loss -8.690003], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 316 / 744], [train main loss -8.699204], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 317 / 744], [train main loss -8.696568], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 318 / 744], [train main loss -8.695017], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 319 / 744], [train main loss -8.695062], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 320 / 744], [train main loss -8.697781], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 321 / 744], [train main loss -8.695126], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 322 / 744], [train main loss -8.683986], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 323 / 744], [train main loss -8.676271], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 324 / 744], [train main loss -8.671991], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 325 / 744], [train main loss -8.685149], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 326 / 744], [train main loss -8.674706], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 327 / 744], [train main loss -8.657720], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 328 / 744], [train main loss -8.653317], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 329 / 744], [train main loss -8.643322], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 330 / 744], [train main loss -8.664324], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 331 / 744], [train main loss -8.663401], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 332 / 744], [train main loss -8.669474], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 333 / 744], [train main loss -8.665893], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 334 / 744], [train main loss -8.655891], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 335 / 744], [train main loss -8.644675], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 336 / 744], [train main loss -8.668535], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 337 / 744], [train main loss -8.661670], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 338 / 744], [train main loss -8.660674], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 339 / 744], [train main loss -8.665283], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 340 / 744], [train main loss -8.650304], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 341 / 744], [train main loss -8.657470], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 342 / 744], [train main loss -8.657703], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 343 / 744], [train main loss -8.648004], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 344 / 744], [train main loss -8.691015], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 345 / 744], [train main loss -8.687306], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 346 / 744], [train main loss -8.671544], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 347 / 744], [train main loss -8.682970], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 348 / 744], [train main loss -8.688012], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 349 / 744], [train main loss -8.682127], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 350 / 744], [train main loss -8.690054], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 351 / 744], [train main loss -8.688998], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 352 / 744], [train main loss -8.693734], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 353 / 744], [train main loss -8.699410], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 354 / 744], [train main loss -8.722126], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 355 / 744], [train main loss -8.709168], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 356 / 744], [train main loss -8.696644], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 357 / 744], [train main loss -8.679017], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 358 / 744], [train main loss -8.678710], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 359 / 744], [train main loss -8.690023], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 360 / 744], [train main loss -8.699142], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 361 / 744], [train main loss -8.702452], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 362 / 744], [train main loss -8.697852], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 363 / 744], [train main loss -8.697775], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 364 / 744], [train main loss -8.693380], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 365 / 744], [train main loss -8.687906], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 366 / 744], [train main loss -8.698348], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 367 / 744], [train main loss -8.691227], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 368 / 744], [train main loss -8.705196], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 369 / 744], [train main loss -8.704839], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 370 / 744], [train main loss -8.689503], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 371 / 744], [train main loss -8.693671], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 372 / 744], [train main loss -8.677002], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 373 / 744], [train main loss -8.692187], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 374 / 744], [train main loss -8.700899], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 375 / 744], [train main loss -8.717139], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 376 / 744], [train main loss -8.720590], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 377 / 744], [train main loss -8.717313], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 378 / 744], [train main loss -8.723926], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 379 / 744], [train main loss -8.709396], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 380 / 744], [train main loss -8.704703], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 381 / 744], [train main loss -8.711576], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 382 / 744], [train main loss -8.725011], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 383 / 744], [train main loss -8.729738], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 384 / 744], [train main loss -8.730127], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 385 / 744], [train main loss -8.731434], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 386 / 744], [train main loss -8.745035], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 387 / 744], [train main loss -8.758490], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 388 / 744], [train main loss -8.763398], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 389 / 744], [train main loss -8.757439], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 390 / 744], [train main loss -8.749853], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 391 / 744], [train main loss -8.743145], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 392 / 744], [train main loss -8.760595], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 393 / 744], [train main loss -8.757414], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 394 / 744], [train main loss -8.749443], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 395 / 744], [train main loss -8.747452], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 396 / 744], [train main loss -8.743427], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 397 / 744], [train main loss -8.751805], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 398 / 744], [train main loss -8.739077], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 399 / 744], [train main loss -8.748782], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 400 / 744], [train main loss -8.752371], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 401 / 744], [train main loss -8.757409], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 402 / 744], [train main loss -8.749311], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 403 / 744], [train main loss -8.752663], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 404 / 744], [train main loss -8.756226], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 405 / 744], [train main loss -8.751082], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 406 / 744], [train main loss -8.746627], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 407 / 744], [train main loss -8.752423], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 408 / 744], [train main loss -8.747994], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 409 / 744], [train main loss -8.755023], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 410 / 744], [train main loss -8.736381], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 411 / 744], [train main loss -8.756710], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 412 / 744], [train main loss -8.753793], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 413 / 744], [train main loss -8.750044], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 414 / 744], [train main loss -8.755709], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 415 / 744], [train main loss -8.747741], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 416 / 744], [train main loss -8.751001], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 417 / 744], [train main loss -8.758572], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 418 / 744], [train main loss -8.752203], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 419 / 744], [train main loss -8.735040], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 420 / 744], [train main loss -8.734673], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 421 / 744], [train main loss -8.742285], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 422 / 744], [train main loss -8.732825], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 423 / 744], [train main loss -8.740454], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 424 / 744], [train main loss -8.746017], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 425 / 744], [train main loss -8.743139], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 426 / 744], [train main loss -8.734726], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 427 / 744], [train main loss -8.743200], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 428 / 744], [train main loss -8.745241], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 429 / 744], [train main loss -8.751006], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 430 / 744], [train main loss -8.736831], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 431 / 744], [train main loss -8.725472], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 432 / 744], [train main loss -8.718743], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 433 / 744], [train main loss -8.723406], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 434 / 744], [train main loss -8.722994], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 435 / 744], [train main loss -8.723802], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 436 / 744], [train main loss -8.741560], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 437 / 744], [train main loss -8.736586], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 438 / 744], [train main loss -8.739973], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 439 / 744], [train main loss -8.746017], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 440 / 744], [train main loss -8.736826], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 441 / 744], [train main loss -8.730365], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 442 / 744], [train main loss -8.711702], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 443 / 744], [train main loss -8.707996], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 444 / 744], [train main loss -8.706792], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 445 / 744], [train main loss -8.695029], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 446 / 744], [train main loss -8.693116], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 447 / 744], [train main loss -8.702696], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 448 / 744], [train main loss -8.697855], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 449 / 744], [train main loss -8.687455], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 450 / 744], [train main loss -8.685665], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 451 / 744], [train main loss -8.682077], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 452 / 744], [train main loss -8.678457], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 453 / 744], [train main loss -8.680295], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 454 / 744], [train main loss -8.672632], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 455 / 744], [train main loss -8.676874], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 456 / 744], [train main loss -8.674477], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 457 / 744], [train main loss -8.676647], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 458 / 744], [train main loss -8.672020], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 459 / 744], [train main loss -8.672877], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 460 / 744], [train main loss -8.685101], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 461 / 744], [train main loss -8.678614], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 462 / 744], [train main loss -8.675332], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 463 / 744], [train main loss -8.673492], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 464 / 744], [train main loss -8.683513], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 465 / 744], [train main loss -8.672353], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 466 / 744], [train main loss -8.664857], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 467 / 744], [train main loss -8.663669], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 468 / 744], [train main loss -8.672086], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 469 / 744], [train main loss -8.683944], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 470 / 744], [train main loss -8.695746], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 471 / 744], [train main loss -8.692041], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 472 / 744], [train main loss -8.688763], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 473 / 744], [train main loss -8.691276], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 474 / 744], [train main loss -8.680133], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 475 / 744], [train main loss -8.665611], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 476 / 744], [train main loss -8.669731], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 477 / 744], [train main loss -8.675895], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 478 / 744], [train main loss -8.672296], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 479 / 744], [train main loss -8.667814], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 480 / 744], [train main loss -8.662697], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 481 / 744], [train main loss -8.656934], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 482 / 744], [train main loss -8.653644], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 483 / 744], [train main loss -8.645660], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 484 / 744], [train main loss -8.661468], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 485 / 744], [train main loss -8.663554], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 486 / 744], [train main loss -8.657692], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 487 / 744], [train main loss -8.658232], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 488 / 744], [train main loss -8.663746], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 489 / 744], [train main loss -8.662658], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 490 / 744], [train main loss -8.672248], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 491 / 744], [train main loss -8.690428], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 492 / 744], [train main loss -8.686700], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 493 / 744], [train main loss -8.685258], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 494 / 744], [train main loss -8.675473], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 495 / 744], [train main loss -8.667174], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 496 / 744], [train main loss -8.665267], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 497 / 744], [train main loss -8.665590], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 498 / 744], [train main loss -8.661873], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 499 / 744], [train main loss -8.664025], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 500 / 744], [train main loss -8.664825], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 501 / 744], [train main loss -8.655188], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 502 / 744], [train main loss -8.656601], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 503 / 744], [train main loss -8.666513], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 504 / 744], [train main loss -8.656549], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 505 / 744], [train main loss -8.650954], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 506 / 744], [train main loss -8.646818], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 507 / 744], [train main loss -8.662139], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 508 / 744], [train main loss -8.669933], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 509 / 744], [train main loss -8.660983], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 510 / 744], [train main loss -8.664857], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 511 / 744], [train main loss -8.659589], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 512 / 744], [train main loss -8.665391], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 513 / 744], [train main loss -8.658114], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 514 / 744], [train main loss -8.651698], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 515 / 744], [train main loss -8.656622], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 516 / 744], [train main loss -8.658995], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 517 / 744], [train main loss -8.655952], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 518 / 744], [train main loss -8.657922], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 519 / 744], [train main loss -8.651404], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 520 / 744], [train main loss -8.657371], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 521 / 744], [train main loss -8.653551], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 522 / 744], [train main loss -8.655961], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 523 / 744], [train main loss -8.648762], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 524 / 744], [train main loss -8.646652], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 525 / 744], [train main loss -8.653760], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 526 / 744], [train main loss -8.657248], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 527 / 744], [train main loss -8.658852], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 528 / 744], [train main loss -8.663453], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 529 / 744], [train main loss -8.662909], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 530 / 744], [train main loss -8.664527], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 531 / 744], [train main loss -8.663372], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 532 / 744], [train main loss -8.655709], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 533 / 744], [train main loss -8.650330], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 534 / 744], [train main loss -8.653537], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 535 / 744], [train main loss -8.659906], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 536 / 744], [train main loss -8.659518], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 537 / 744], [train main loss -8.654179], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 538 / 744], [train main loss -8.654994], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 539 / 744], [train main loss -8.659115], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 540 / 744], [train main loss -8.663443], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 541 / 744], [train main loss -8.656218], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 542 / 744], [train main loss -8.660773], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 543 / 744], [train main loss -8.658327], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 544 / 744], [train main loss -8.653620], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 545 / 744], [train main loss -8.660737], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 546 / 744], [train main loss -8.659987], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 547 / 744], [train main loss -8.656574], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 548 / 744], [train main loss -8.657929], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 549 / 744], [train main loss -8.664853], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 550 / 744], [train main loss -8.671593], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 551 / 744], [train main loss -8.670753], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 552 / 744], [train main loss -8.682748], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 553 / 744], [train main loss -8.687155], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 554 / 744], [train main loss -8.680821], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 555 / 744], [train main loss -8.675916], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 556 / 744], [train main loss -8.680364], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 557 / 744], [train main loss -8.689042], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 558 / 744], [train main loss -8.679970], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 559 / 744], [train main loss -8.674550], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 560 / 744], [train main loss -8.683372], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 561 / 744], [train main loss -8.685554], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 562 / 744], [train main loss -8.691632], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 563 / 744], [train main loss -8.696573], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 564 / 744], [train main loss -8.694368], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 565 / 744], [train main loss -8.690522], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 566 / 744], [train main loss -8.692164], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 567 / 744], [train main loss -8.699189], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 568 / 744], [train main loss -8.700296], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 569 / 744], [train main loss -8.692919], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 570 / 744], [train main loss -8.700867], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 571 / 744], [train main loss -8.698472], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 572 / 744], [train main loss -8.697906], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 573 / 744], [train main loss -8.692781], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 574 / 744], [train main loss -8.687878], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 575 / 744], [train main loss -8.691390], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 576 / 744], [train main loss -8.683481], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 577 / 744], [train main loss -8.681501], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 578 / 744], [train main loss -8.677448], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 579 / 744], [train main loss -8.676418], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 580 / 744], [train main loss -8.690573], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 581 / 744], [train main loss -8.694250], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 582 / 744], [train main loss -8.701525], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 583 / 744], [train main loss -8.702193], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 584 / 744], [train main loss -8.706826], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 585 / 744], [train main loss -8.710832], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 586 / 744], [train main loss -8.718199], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 587 / 744], [train main loss -8.718331], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 588 / 744], [train main loss -8.721251], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 589 / 744], [train main loss -8.715467], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 590 / 744], [train main loss -8.723135], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 591 / 744], [train main loss -8.719445], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 592 / 744], [train main loss -8.714473], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 593 / 744], [train main loss -8.713617], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 594 / 744], [train main loss -8.708452], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 595 / 744], [train main loss -8.700390], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 596 / 744], [train main loss -8.698472], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 597 / 744], [train main loss -8.700165], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 598 / 744], [train main loss -8.694303], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 599 / 744], [train main loss -8.705938], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 600 / 744], [train main loss -8.702395], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 601 / 744], [train main loss -8.685378], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 602 / 744], [train main loss -8.678352], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 603 / 744], [train main loss -8.679229], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 604 / 744], [train main loss -8.678444], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 605 / 744], [train main loss -8.676561], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 606 / 744], [train main loss -8.683042], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 607 / 744], [train main loss -8.680091], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 608 / 744], [train main loss -8.676382], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 609 / 744], [train main loss -8.674484], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 610 / 744], [train main loss -8.682954], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 611 / 744], [train main loss -8.683990], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 612 / 744], [train main loss -8.689166], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 613 / 744], [train main loss -8.696239], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 614 / 744], [train main loss -8.698360], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 615 / 744], [train main loss -8.699471], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 616 / 744], [train main loss -8.695576], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 617 / 744], [train main loss -8.700215], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 618 / 744], [train main loss -8.699906], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 619 / 744], [train main loss -8.694492], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 620 / 744], [train main loss -8.695737], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 621 / 744], [train main loss -8.693954], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 622 / 744], [train main loss -8.691455], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 623 / 744], [train main loss -8.693630], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 624 / 744], [train main loss -8.689292], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 625 / 744], [train main loss -8.686132], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 626 / 744], [train main loss -8.684640], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 627 / 744], [train main loss -8.678923], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 628 / 744], [train main loss -8.674505], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 629 / 744], [train main loss -8.679286], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 630 / 744], [train main loss -8.679262], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 631 / 744], [train main loss -8.679257], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 632 / 744], [train main loss -8.679030], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 633 / 744], [train main loss -8.683240], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 634 / 744], [train main loss -8.682231], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 635 / 744], [train main loss -8.684041], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 636 / 744], [train main loss -8.678214], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 637 / 744], [train main loss -8.683315], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 638 / 744], [train main loss -8.676069], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 639 / 744], [train main loss -8.678757], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 640 / 744], [train main loss -8.675016], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 641 / 744], [train main loss -8.677022], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 642 / 744], [train main loss -8.684115], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 643 / 744], [train main loss -8.685370], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 644 / 744], [train main loss -8.695866], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 645 / 744], [train main loss -8.703944], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 646 / 744], [train main loss -8.707214], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 647 / 744], [train main loss -8.706191], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 648 / 744], [train main loss -8.699818], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 649 / 744], [train main loss -8.703040], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 650 / 744], [train main loss -8.697669], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 651 / 744], [train main loss -8.702474], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 652 / 744], [train main loss -8.701936], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 653 / 744], [train main loss -8.697940], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 654 / 744], [train main loss -8.700664], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 655 / 744], [train main loss -8.693489], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 656 / 744], [train main loss -8.692241], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 657 / 744], [train main loss -8.694104], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 658 / 744], [train main loss -8.690197], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 659 / 744], [train main loss -8.688854], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 660 / 744], [train main loss -8.689933], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 661 / 744], [train main loss -8.685572], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 662 / 744], [train main loss -8.686308], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 663 / 744], [train main loss -8.680561], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 664 / 744], [train main loss -8.679553], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 665 / 744], [train main loss -8.681856], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 666 / 744], [train main loss -8.682566], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 667 / 744], [train main loss -8.689241], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 668 / 744], [train main loss -8.686505], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 669 / 744], [train main loss -8.687503], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 670 / 744], [train main loss -8.695066], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 671 / 744], [train main loss -8.687162], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 672 / 744], [train main loss -8.691006], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 673 / 744], [train main loss -8.689308], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 674 / 744], [train main loss -8.691731], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 675 / 744], [train main loss -8.700525], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 676 / 744], [train main loss -8.698293], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 677 / 744], [train main loss -8.702501], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 678 / 744], [train main loss -8.700069], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 679 / 744], [train main loss -8.699188], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 680 / 744], [train main loss -8.700385], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 681 / 744], [train main loss -8.703519], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 682 / 744], [train main loss -8.702616], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 683 / 744], [train main loss -8.699655], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 684 / 744], [train main loss -8.693986], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 685 / 744], [train main loss -8.685753], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 686 / 744], [train main loss -8.688887], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 687 / 744], [train main loss -8.687785], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 688 / 744], [train main loss -8.691599], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 689 / 744], [train main loss -8.689888], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 690 / 744], [train main loss -8.681305], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 691 / 744], [train main loss -8.674046], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 692 / 744], [train main loss -8.673536], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 693 / 744], [train main loss -8.669325], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 694 / 744], [train main loss -8.666256], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 695 / 744], [train main loss -8.666318], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 696 / 744], [train main loss -8.664775], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 697 / 744], [train main loss -8.659054], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 698 / 744], [train main loss -8.660917], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 699 / 744], [train main loss -8.657216], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 700 / 744], [train main loss -8.647025], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 701 / 744], [train main loss -8.641004], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 702 / 744], [train main loss -8.636930], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 703 / 744], [train main loss -8.632603], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 704 / 744], [train main loss -8.633833], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 705 / 744], [train main loss -8.635477], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 706 / 744], [train main loss -8.639107], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 707 / 744], [train main loss -8.638585], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 708 / 744], [train main loss -8.633424], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 709 / 744], [train main loss -8.630891], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 710 / 744], [train main loss -8.626837], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 711 / 744], [train main loss -8.631413], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 712 / 744], [train main loss -8.629113], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 713 / 744], [train main loss -8.631028], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 714 / 744], [train main loss -8.636678], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 715 / 744], [train main loss -8.631590], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 716 / 744], [train main loss -8.625392], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 717 / 744], [train main loss -8.631217], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 718 / 744], [train main loss -8.639836], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 719 / 744], [train main loss -8.633175], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 720 / 744], [train main loss -8.624850], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 721 / 744], [train main loss -8.623943], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 722 / 744], [train main loss -8.621951], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 723 / 744], [train main loss -8.620880], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 724 / 744], [train main loss -8.611532], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 725 / 744], [train main loss -8.610013], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 726 / 744], [train main loss -8.604890], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 727 / 744], [train main loss -8.600685], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 728 / 744], [train main loss -8.605532], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 729 / 744], [train main loss -8.604558], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 730 / 744], [train main loss -8.604602], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 731 / 744], [train main loss -8.607792], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 732 / 744], [train main loss -8.615613], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 733 / 744], [train main loss -8.620344], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 734 / 744], [train main loss -8.619244], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 735 / 744], [train main loss -8.616287], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 736 / 744], [train main loss -8.619790], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 737 / 744], [train main loss -8.616087], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 738 / 744], [train main loss -8.617381], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 739 / 744], [train main loss -8.617830], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 740 / 744], [train main loss -8.622465], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 741 / 744], [train main loss -8.615641], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 742 / 744], [train main loss -8.614246], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 743 / 744], [train main loss -8.609955], [lr 0.004774] [batchtime 1.14]
[epoch 4], [iter 744 / 744], [train main loss -8.605138], [lr 0.004774] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              97.42  36.88  0.02  0.01         0.98      0.99
   1  sidewalk          81.45   5.12  0.06  0.17         0.95      0.85
   2  building          92.47  21.22  0.03  0.05         0.97      0.95
   3  wall              63.86   0.53  0.37  0.19         0.73      0.84
   4  fence             59.62   0.57  0.44  0.23         0.69      0.81
   5  pole              64.67   1.01  0.46  0.09         0.68      0.92
   6  traffic light     74.53   0.17  0.15  0.19         0.87      0.84
   7  traffic sign      79.85   0.57  0.16  0.09         0.86      0.92
   8  vegetation        91.94  16.78  0.03  0.06         0.97      0.95
   9  terrain           51.39   0.49  0.69  0.26         0.59      0.80
  10  sky               94.55   3.29  0.02  0.04         0.98      0.96
  11  person            80.59   1.21  0.07  0.17         0.93      0.85
  12  rider             43.99   0.10  1.12  0.15         0.47      0.87
  13  car               94.56   6.28  0.04  0.02         0.96      0.98
  14  truck             80.43   0.28  0.07  0.17         0.93      0.86
  15  bus               81.55   0.36  0.08  0.15         0.93      0.87
  16  train             76.97   0.10  0.14  0.16         0.88      0.86
  17  motorcycle        61.67   0.06  0.26  0.36         0.79      0.73
  18  bicycle           77.60   0.65  0.10  0.19         0.91      0.84
Mean: 76.27
-----------------------------------------------------------------------------------------------------------
this : [epoch 4], [val loss 0.14236], [acc 0.95686], [acc_cls 0.84642], [mean_iu 0.76269], [fwavacc 0.92016]
best : [epoch 2], [val loss 0.15303], [acc 0.95799], [acc_cls 0.84888], [mean_iu 0.77525], [fwavacc 0.92257]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 5], [iter 1 / 744], [train main loss -4.414470], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 2 / 744], [train main loss -8.956578], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 3 / 744], [train main loss -7.178562], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 4 / 744], [train main loss -7.782704], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 5 / 744], [train main loss -8.344178], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 6 / 744], [train main loss -8.233554], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 7 / 744], [train main loss -7.633294], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 8 / 744], [train main loss -7.966323], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 9 / 744], [train main loss -8.448525], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 10 / 744], [train main loss -8.366337], [lr 0.004718] [batchtime 0]
[epoch 5], [iter 11 / 744], [train main loss -8.785227], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 12 / 744], [train main loss -8.661578], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 13 / 744], [train main loss -8.374075], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 14 / 744], [train main loss -8.118642], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 15 / 744], [train main loss -8.329335], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 16 / 744], [train main loss -8.379903], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 17 / 744], [train main loss -8.800534], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 18 / 744], [train main loss -8.909645], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 19 / 744], [train main loss -8.799776], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 20 / 744], [train main loss -8.485531], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 21 / 744], [train main loss -8.377495], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 22 / 744], [train main loss -8.197744], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 23 / 744], [train main loss -8.315135], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 24 / 744], [train main loss -8.391250], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 25 / 744], [train main loss -8.329602], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 26 / 744], [train main loss -8.196986], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 27 / 744], [train main loss -8.377730], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 28 / 744], [train main loss -8.632929], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 29 / 744], [train main loss -8.756014], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 30 / 744], [train main loss -8.876139], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 31 / 744], [train main loss -8.772979], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 32 / 744], [train main loss -8.651475], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 33 / 744], [train main loss -8.696834], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 34 / 744], [train main loss -8.638590], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 35 / 744], [train main loss -8.606730], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 36 / 744], [train main loss -8.698428], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 37 / 744], [train main loss -8.664475], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 38 / 744], [train main loss -8.634324], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 39 / 744], [train main loss -8.466949], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 40 / 744], [train main loss -8.413976], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 41 / 744], [train main loss -8.376347], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 42 / 744], [train main loss -8.285135], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 43 / 744], [train main loss -8.384476], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 44 / 744], [train main loss -8.277308], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 45 / 744], [train main loss -8.282875], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 46 / 744], [train main loss -8.250068], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 47 / 744], [train main loss -8.221039], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 48 / 744], [train main loss -8.235675], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 49 / 744], [train main loss -8.317015], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 50 / 744], [train main loss -8.267246], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 51 / 744], [train main loss -8.346077], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 52 / 744], [train main loss -8.344211], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 53 / 744], [train main loss -8.309859], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 54 / 744], [train main loss -8.332560], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 55 / 744], [train main loss -8.191175], [lr 0.004718] [batchtime 1.15]
[epoch 5], [iter 56 / 744], [train main loss -8.297689], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 57 / 744], [train main loss -8.309147], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 58 / 744], [train main loss -8.268160], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 59 / 744], [train main loss -8.276578], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 60 / 744], [train main loss -8.211768], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 61 / 744], [train main loss -8.194839], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 62 / 744], [train main loss -8.165646], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 63 / 744], [train main loss -8.124295], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 64 / 744], [train main loss -8.070428], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 65 / 744], [train main loss -8.104511], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 66 / 744], [train main loss -8.087838], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 67 / 744], [train main loss -8.033977], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 68 / 744], [train main loss -7.997731], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 69 / 744], [train main loss -8.073371], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 70 / 744], [train main loss -8.163455], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 71 / 744], [train main loss -8.241364], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 72 / 744], [train main loss -8.292489], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 73 / 744], [train main loss -8.271399], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 74 / 744], [train main loss -8.208483], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 75 / 744], [train main loss -8.181612], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 76 / 744], [train main loss -8.179307], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 77 / 744], [train main loss -8.264317], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 78 / 744], [train main loss -8.192467], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 79 / 744], [train main loss -8.189872], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 80 / 744], [train main loss -8.217586], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 81 / 744], [train main loss -8.185319], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 82 / 744], [train main loss -8.137854], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 83 / 744], [train main loss -8.165715], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 84 / 744], [train main loss -8.195038], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 85 / 744], [train main loss -8.159164], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 86 / 744], [train main loss -8.211863], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 87 / 744], [train main loss -8.196105], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 88 / 744], [train main loss -8.196808], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 89 / 744], [train main loss -8.195350], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 90 / 744], [train main loss -8.176437], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 91 / 744], [train main loss -8.199709], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 92 / 744], [train main loss -8.207104], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 93 / 744], [train main loss -8.249747], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 94 / 744], [train main loss -8.275593], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 95 / 744], [train main loss -8.246155], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 96 / 744], [train main loss -8.362319], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 97 / 744], [train main loss -8.409018], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 98 / 744], [train main loss -8.425070], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 99 / 744], [train main loss -8.443907], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 100 / 744], [train main loss -8.484569], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 101 / 744], [train main loss -8.496053], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 102 / 744], [train main loss -8.454797], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 103 / 744], [train main loss -8.465473], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 104 / 744], [train main loss -8.467010], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 105 / 744], [train main loss -8.532463], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 106 / 744], [train main loss -8.518031], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 107 / 744], [train main loss -8.536685], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 108 / 744], [train main loss -8.530949], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 109 / 744], [train main loss -8.517581], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 110 / 744], [train main loss -8.520883], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 111 / 744], [train main loss -8.494510], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 112 / 744], [train main loss -8.516128], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 113 / 744], [train main loss -8.459684], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 114 / 744], [train main loss -8.474143], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 115 / 744], [train main loss -8.472294], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 116 / 744], [train main loss -8.450930], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 117 / 744], [train main loss -8.496158], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 118 / 744], [train main loss -8.514246], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 119 / 744], [train main loss -8.495884], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 120 / 744], [train main loss -8.484448], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 121 / 744], [train main loss -8.474988], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 122 / 744], [train main loss -8.457217], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 123 / 744], [train main loss -8.510782], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 124 / 744], [train main loss -8.513458], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 125 / 744], [train main loss -8.508373], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 126 / 744], [train main loss -8.507801], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 127 / 744], [train main loss -8.553499], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 128 / 744], [train main loss -8.537565], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 129 / 744], [train main loss -8.561955], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 130 / 744], [train main loss -8.539977], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 131 / 744], [train main loss -8.529371], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 132 / 744], [train main loss -8.575897], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 133 / 744], [train main loss -8.567991], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 134 / 744], [train main loss -8.556896], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 135 / 744], [train main loss -8.562661], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 136 / 744], [train main loss -8.587440], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 137 / 744], [train main loss -8.539269], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 138 / 744], [train main loss -8.558226], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 139 / 744], [train main loss -8.572193], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 140 / 744], [train main loss -8.596465], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 141 / 744], [train main loss -8.609325], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 142 / 744], [train main loss -8.614792], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 143 / 744], [train main loss -8.587687], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 144 / 744], [train main loss -8.551568], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 145 / 744], [train main loss -8.556813], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 146 / 744], [train main loss -8.559208], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 147 / 744], [train main loss -8.541541], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 148 / 744], [train main loss -8.581673], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 149 / 744], [train main loss -8.564757], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 150 / 744], [train main loss -8.532796], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 151 / 744], [train main loss -8.545039], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 152 / 744], [train main loss -8.535922], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 153 / 744], [train main loss -8.561759], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 154 / 744], [train main loss -8.613602], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 155 / 744], [train main loss -8.620883], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 156 / 744], [train main loss -8.642507], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 157 / 744], [train main loss -8.672364], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 158 / 744], [train main loss -8.660422], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 159 / 744], [train main loss -8.647059], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 160 / 744], [train main loss -8.630925], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 161 / 744], [train main loss -8.620419], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 162 / 744], [train main loss -8.673975], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 163 / 744], [train main loss -8.674329], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 164 / 744], [train main loss -8.656257], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 165 / 744], [train main loss -8.670342], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 166 / 744], [train main loss -8.714552], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 167 / 744], [train main loss -8.713896], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 168 / 744], [train main loss -8.697230], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 169 / 744], [train main loss -8.733502], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 170 / 744], [train main loss -8.753208], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 171 / 744], [train main loss -8.747108], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 172 / 744], [train main loss -8.746674], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 173 / 744], [train main loss -8.741897], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 174 / 744], [train main loss -8.757452], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 175 / 744], [train main loss -8.749101], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 176 / 744], [train main loss -8.760137], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 177 / 744], [train main loss -8.770201], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 178 / 744], [train main loss -8.745896], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 179 / 744], [train main loss -8.746542], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 180 / 744], [train main loss -8.736576], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 181 / 744], [train main loss -8.750617], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 182 / 744], [train main loss -8.763006], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 183 / 744], [train main loss -8.757071], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 184 / 744], [train main loss -8.800111], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 185 / 744], [train main loss -8.781579], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 186 / 744], [train main loss -8.780458], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 187 / 744], [train main loss -8.767178], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 188 / 744], [train main loss -8.793562], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 189 / 744], [train main loss -8.791723], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 190 / 744], [train main loss -8.757054], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 191 / 744], [train main loss -8.763588], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 192 / 744], [train main loss -8.747179], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 193 / 744], [train main loss -8.738569], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 194 / 744], [train main loss -8.741482], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 195 / 744], [train main loss -8.736123], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 196 / 744], [train main loss -8.728254], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 197 / 744], [train main loss -8.718824], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 198 / 744], [train main loss -8.698518], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 199 / 744], [train main loss -8.713807], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 200 / 744], [train main loss -8.710047], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 201 / 744], [train main loss -8.704529], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 202 / 744], [train main loss -8.706383], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 203 / 744], [train main loss -8.684864], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 204 / 744], [train main loss -8.710554], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 205 / 744], [train main loss -8.703664], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 206 / 744], [train main loss -8.666300], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 207 / 744], [train main loss -8.684738], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 208 / 744], [train main loss -8.682884], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 209 / 744], [train main loss -8.691894], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 210 / 744], [train main loss -8.718115], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 211 / 744], [train main loss -8.691742], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 212 / 744], [train main loss -8.671134], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 213 / 744], [train main loss -8.630681], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 214 / 744], [train main loss -8.638032], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 215 / 744], [train main loss -8.640664], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 216 / 744], [train main loss -8.650800], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 217 / 744], [train main loss -8.657031], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 218 / 744], [train main loss -8.675364], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 219 / 744], [train main loss -8.636869], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 220 / 744], [train main loss -8.633823], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 221 / 744], [train main loss -8.608580], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 222 / 744], [train main loss -8.618190], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 223 / 744], [train main loss -8.604717], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 224 / 744], [train main loss -8.597895], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 225 / 744], [train main loss -8.627241], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 226 / 744], [train main loss -8.623510], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 227 / 744], [train main loss -8.613512], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 228 / 744], [train main loss -8.622115], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 229 / 744], [train main loss -8.638588], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 230 / 744], [train main loss -8.652686], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 231 / 744], [train main loss -8.672750], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 232 / 744], [train main loss -8.657873], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 233 / 744], [train main loss -8.673620], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 234 / 744], [train main loss -8.659947], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 235 / 744], [train main loss -8.642479], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 236 / 744], [train main loss -8.644017], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 237 / 744], [train main loss -8.628683], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 238 / 744], [train main loss -8.619164], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 239 / 744], [train main loss -8.628994], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 240 / 744], [train main loss -8.635465], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 241 / 744], [train main loss -8.639184], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 242 / 744], [train main loss -8.640306], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 243 / 744], [train main loss -8.649379], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 244 / 744], [train main loss -8.629119], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 245 / 744], [train main loss -8.642896], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 246 / 744], [train main loss -8.642463], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 247 / 744], [train main loss -8.656574], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 248 / 744], [train main loss -8.638751], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 249 / 744], [train main loss -8.646757], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 250 / 744], [train main loss -8.644969], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 251 / 744], [train main loss -8.628506], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 252 / 744], [train main loss -8.646382], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 253 / 744], [train main loss -8.667924], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 254 / 744], [train main loss -8.673173], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 255 / 744], [train main loss -8.684525], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 256 / 744], [train main loss -8.663129], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 257 / 744], [train main loss -8.659150], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 258 / 744], [train main loss -8.628407], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 259 / 744], [train main loss -8.617925], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 260 / 744], [train main loss -8.623930], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 261 / 744], [train main loss -8.671234], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 262 / 744], [train main loss -8.657721], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 263 / 744], [train main loss -8.660953], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 264 / 744], [train main loss -8.646227], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 265 / 744], [train main loss -8.635323], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 266 / 744], [train main loss -8.624127], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 267 / 744], [train main loss -8.615106], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 268 / 744], [train main loss -8.615966], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 269 / 744], [train main loss -8.637623], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 270 / 744], [train main loss -8.631386], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 271 / 744], [train main loss -8.642836], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 272 / 744], [train main loss -8.636967], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 273 / 744], [train main loss -8.636212], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 274 / 744], [train main loss -8.620999], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 275 / 744], [train main loss -8.619604], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 276 / 744], [train main loss -8.625048], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 277 / 744], [train main loss -8.629885], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 278 / 744], [train main loss -8.649434], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 279 / 744], [train main loss -8.634638], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 280 / 744], [train main loss -8.649808], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 281 / 744], [train main loss -8.645624], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 282 / 744], [train main loss -8.650695], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 283 / 744], [train main loss -8.670731], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 284 / 744], [train main loss -8.683848], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 285 / 744], [train main loss -8.683935], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 286 / 744], [train main loss -8.664640], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 287 / 744], [train main loss -8.677166], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 288 / 744], [train main loss -8.668956], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 289 / 744], [train main loss -8.668102], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 290 / 744], [train main loss -8.668344], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 291 / 744], [train main loss -8.670176], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 292 / 744], [train main loss -8.659911], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 293 / 744], [train main loss -8.653635], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 294 / 744], [train main loss -8.652382], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 295 / 744], [train main loss -8.651674], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 296 / 744], [train main loss -8.664039], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 297 / 744], [train main loss -8.668967], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 298 / 744], [train main loss -8.659997], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 299 / 744], [train main loss -8.668845], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 300 / 744], [train main loss -8.673107], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 301 / 744], [train main loss -8.678361], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 302 / 744], [train main loss -8.679732], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 303 / 744], [train main loss -8.699579], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 304 / 744], [train main loss -8.687626], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 305 / 744], [train main loss -8.671156], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 306 / 744], [train main loss -8.703201], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 307 / 744], [train main loss -8.707637], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 308 / 744], [train main loss -8.704582], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 309 / 744], [train main loss -8.689909], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 310 / 744], [train main loss -8.697520], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 311 / 744], [train main loss -8.717810], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 312 / 744], [train main loss -8.732635], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 313 / 744], [train main loss -8.719058], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 314 / 744], [train main loss -8.700647], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 315 / 744], [train main loss -8.690892], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 316 / 744], [train main loss -8.700177], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 317 / 744], [train main loss -8.690388], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 318 / 744], [train main loss -8.698616], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 319 / 744], [train main loss -8.690204], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 320 / 744], [train main loss -8.676667], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 321 / 744], [train main loss -8.687935], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 322 / 744], [train main loss -8.677134], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 323 / 744], [train main loss -8.652888], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 324 / 744], [train main loss -8.665847], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 325 / 744], [train main loss -8.675240], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 326 / 744], [train main loss -8.675146], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 327 / 744], [train main loss -8.674533], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 328 / 744], [train main loss -8.690382], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 329 / 744], [train main loss -8.683479], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 330 / 744], [train main loss -8.695768], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 331 / 744], [train main loss -8.697401], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 332 / 744], [train main loss -8.696050], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 333 / 744], [train main loss -8.717433], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 334 / 744], [train main loss -8.718393], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 335 / 744], [train main loss -8.729785], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 336 / 744], [train main loss -8.703396], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 337 / 744], [train main loss -8.713360], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 338 / 744], [train main loss -8.704736], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 339 / 744], [train main loss -8.703859], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 340 / 744], [train main loss -8.706381], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 341 / 744], [train main loss -8.699401], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 342 / 744], [train main loss -8.700422], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 343 / 744], [train main loss -8.695180], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 344 / 744], [train main loss -8.685249], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 345 / 744], [train main loss -8.693551], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 346 / 744], [train main loss -8.692472], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 347 / 744], [train main loss -8.693722], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 348 / 744], [train main loss -8.689976], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 349 / 744], [train main loss -8.683696], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 350 / 744], [train main loss -8.682731], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 351 / 744], [train main loss -8.672231], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 352 / 744], [train main loss -8.679630], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 353 / 744], [train main loss -8.681505], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 354 / 744], [train main loss -8.680599], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 355 / 744], [train main loss -8.669707], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 356 / 744], [train main loss -8.684437], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 357 / 744], [train main loss -8.677790], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 358 / 744], [train main loss -8.684106], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 359 / 744], [train main loss -8.682506], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 360 / 744], [train main loss -8.677815], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 361 / 744], [train main loss -8.688023], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 362 / 744], [train main loss -8.686487], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 363 / 744], [train main loss -8.693880], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 364 / 744], [train main loss -8.680076], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 365 / 744], [train main loss -8.667818], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 366 / 744], [train main loss -8.676990], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 367 / 744], [train main loss -8.672539], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 368 / 744], [train main loss -8.679708], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 369 / 744], [train main loss -8.684467], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 370 / 744], [train main loss -8.675304], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 371 / 744], [train main loss -8.674289], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 372 / 744], [train main loss -8.682367], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 373 / 744], [train main loss -8.689162], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 374 / 744], [train main loss -8.675911], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 375 / 744], [train main loss -8.669817], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 376 / 744], [train main loss -8.678013], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 377 / 744], [train main loss -8.689648], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 378 / 744], [train main loss -8.696520], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 379 / 744], [train main loss -8.700424], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 380 / 744], [train main loss -8.700808], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 381 / 744], [train main loss -8.698106], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 382 / 744], [train main loss -8.686136], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 383 / 744], [train main loss -8.689280], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 384 / 744], [train main loss -8.682341], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 385 / 744], [train main loss -8.687666], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 386 / 744], [train main loss -8.687710], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 387 / 744], [train main loss -8.675516], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 388 / 744], [train main loss -8.671722], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 389 / 744], [train main loss -8.663131], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 390 / 744], [train main loss -8.649631], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 391 / 744], [train main loss -8.642803], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 392 / 744], [train main loss -8.642050], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 393 / 744], [train main loss -8.644114], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 394 / 744], [train main loss -8.625496], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 395 / 744], [train main loss -8.618671], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 396 / 744], [train main loss -8.611996], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 397 / 744], [train main loss -8.620724], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 398 / 744], [train main loss -8.624000], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 399 / 744], [train main loss -8.619228], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 400 / 744], [train main loss -8.614513], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 401 / 744], [train main loss -8.615715], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 402 / 744], [train main loss -8.618684], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 403 / 744], [train main loss -8.624251], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 404 / 744], [train main loss -8.631057], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 405 / 744], [train main loss -8.649261], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 406 / 744], [train main loss -8.649166], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 407 / 744], [train main loss -8.640339], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 408 / 744], [train main loss -8.641983], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 409 / 744], [train main loss -8.649364], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 410 / 744], [train main loss -8.660119], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 411 / 744], [train main loss -8.652669], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 412 / 744], [train main loss -8.654605], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 413 / 744], [train main loss -8.648775], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 414 / 744], [train main loss -8.658440], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 415 / 744], [train main loss -8.661881], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 416 / 744], [train main loss -8.660027], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 417 / 744], [train main loss -8.654479], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 418 / 744], [train main loss -8.660766], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 419 / 744], [train main loss -8.647603], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 420 / 744], [train main loss -8.644816], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 421 / 744], [train main loss -8.646375], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 422 / 744], [train main loss -8.647946], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 423 / 744], [train main loss -8.650133], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 424 / 744], [train main loss -8.654840], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 425 / 744], [train main loss -8.661325], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 426 / 744], [train main loss -8.657219], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 427 / 744], [train main loss -8.657257], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 428 / 744], [train main loss -8.665706], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 429 / 744], [train main loss -8.671906], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 430 / 744], [train main loss -8.671681], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 431 / 744], [train main loss -8.678308], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 432 / 744], [train main loss -8.668411], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 433 / 744], [train main loss -8.673537], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 434 / 744], [train main loss -8.670398], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 435 / 744], [train main loss -8.677389], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 436 / 744], [train main loss -8.673820], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 437 / 744], [train main loss -8.675348], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 438 / 744], [train main loss -8.672205], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 439 / 744], [train main loss -8.682142], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 440 / 744], [train main loss -8.686292], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 441 / 744], [train main loss -8.688721], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 442 / 744], [train main loss -8.681692], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 443 / 744], [train main loss -8.678629], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 444 / 744], [train main loss -8.680275], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 445 / 744], [train main loss -8.683781], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 446 / 744], [train main loss -8.675284], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 447 / 744], [train main loss -8.683652], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 448 / 744], [train main loss -8.687719], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 449 / 744], [train main loss -8.685462], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 450 / 744], [train main loss -8.680206], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 451 / 744], [train main loss -8.691650], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 452 / 744], [train main loss -8.701522], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 453 / 744], [train main loss -8.697245], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 454 / 744], [train main loss -8.705058], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 455 / 744], [train main loss -8.706975], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 456 / 744], [train main loss -8.716100], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 457 / 744], [train main loss -8.702792], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 458 / 744], [train main loss -8.710519], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 459 / 744], [train main loss -8.717673], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 460 / 744], [train main loss -8.716011], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 461 / 744], [train main loss -8.721468], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 462 / 744], [train main loss -8.732555], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 463 / 744], [train main loss -8.718811], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 464 / 744], [train main loss -8.720841], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 465 / 744], [train main loss -8.719387], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 466 / 744], [train main loss -8.726224], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 467 / 744], [train main loss -8.722563], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 468 / 744], [train main loss -8.713992], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 469 / 744], [train main loss -8.710430], [lr 0.004718] [batchtime 1.14]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0

Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
[epoch 5], [iter 470 / 744], [train main loss -8.713627], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 471 / 744], [train main loss -8.710541], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 472 / 744], [train main loss -8.712751], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 473 / 744], [train main loss -8.715804], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 474 / 744], [train main loss -8.718052], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 475 / 744], [train main loss -8.726813], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 476 / 744], [train main loss -8.731233], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 477 / 744], [train main loss -8.728347], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 478 / 744], [train main loss -8.732406], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 479 / 744], [train main loss -8.732839], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 480 / 744], [train main loss -8.726289], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 481 / 744], [train main loss -8.726674], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 482 / 744], [train main loss -8.721552], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 483 / 744], [train main loss -8.718223], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 484 / 744], [train main loss -8.713990], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 485 / 744], [train main loss -8.725089], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 486 / 744], [train main loss -8.724959], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 487 / 744], [train main loss -8.735222], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 488 / 744], [train main loss -8.750650], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 489 / 744], [train main loss -8.753044], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 490 / 744], [train main loss -8.752670], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 491 / 744], [train main loss -8.746276], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 492 / 744], [train main loss -8.745623], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 493 / 744], [train main loss -8.733026], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 494 / 744], [train main loss -8.733610], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 495 / 744], [train main loss -8.723949], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 496 / 744], [train main loss -8.720997], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 497 / 744], [train main loss -8.727319], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 498 / 744], [train main loss -8.723953], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 499 / 744], [train main loss -8.739052], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 500 / 744], [train main loss -8.749021], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 501 / 744], [train main loss -8.753480], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 502 / 744], [train main loss -8.755352], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 503 / 744], [train main loss -8.756622], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 504 / 744], [train main loss -8.768755], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 505 / 744], [train main loss -8.764813], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 506 / 744], [train main loss -8.757131], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 507 / 744], [train main loss -8.763985], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 508 / 744], [train main loss -8.766027], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 509 / 744], [train main loss -8.770200], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 510 / 744], [train main loss -8.770508], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 511 / 744], [train main loss -8.764955], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 512 / 744], [train main loss -8.765811], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 513 / 744], [train main loss -8.777466], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 514 / 744], [train main loss -8.769366], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 515 / 744], [train main loss -8.772047], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 516 / 744], [train main loss -8.778303], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 517 / 744], [train main loss -8.781713], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 518 / 744], [train main loss -8.777832], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 519 / 744], [train main loss -8.776144], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 520 / 744], [train main loss -8.767775], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 521 / 744], [train main loss -8.756585], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 522 / 744], [train main loss -8.752009], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 523 / 744], [train main loss -8.753651], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 524 / 744], [train main loss -8.750385], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 525 / 744], [train main loss -8.752470], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 526 / 744], [train main loss -8.751795], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 527 / 744], [train main loss -8.749655], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 528 / 744], [train main loss -8.750496], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 529 / 744], [train main loss -8.743886], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 530 / 744], [train main loss -8.741885], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 531 / 744], [train main loss -8.731559], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 532 / 744], [train main loss -8.740004], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 533 / 744], [train main loss -8.743983], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 534 / 744], [train main loss -8.740502], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 535 / 744], [train main loss -8.734728], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 536 / 744], [train main loss -8.738573], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 537 / 744], [train main loss -8.736806], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 538 / 744], [train main loss -8.738178], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 539 / 744], [train main loss -8.734029], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 540 / 744], [train main loss -8.733437], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 541 / 744], [train main loss -8.724511], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 542 / 744], [train main loss -8.717318], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 543 / 744], [train main loss -8.715734], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 544 / 744], [train main loss -8.714143], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 545 / 744], [train main loss -8.713670], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 546 / 744], [train main loss -8.706747], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 547 / 744], [train main loss -8.721636], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 548 / 744], [train main loss -8.722513], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 549 / 744], [train main loss -8.722478], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 550 / 744], [train main loss -8.723390], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 551 / 744], [train main loss -8.727074], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 552 / 744], [train main loss -8.731470], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 553 / 744], [train main loss -8.732683], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 554 / 744], [train main loss -8.735641], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 555 / 744], [train main loss -8.733928], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 556 / 744], [train main loss -8.731447], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 557 / 744], [train main loss -8.724459], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 558 / 744], [train main loss -8.732624], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 559 / 744], [train main loss -8.728415], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 560 / 744], [train main loss -8.733468], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 561 / 744], [train main loss -8.728069], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 562 / 744], [train main loss -8.733316], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 563 / 744], [train main loss -8.751256], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 564 / 744], [train main loss -8.747210], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 565 / 744], [train main loss -8.740613], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 566 / 744], [train main loss -8.741361], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 567 / 744], [train main loss -8.745129], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 568 / 744], [train main loss -8.743789], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 569 / 744], [train main loss -8.754876], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 570 / 744], [train main loss -8.758172], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 571 / 744], [train main loss -8.763561], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 572 / 744], [train main loss -8.766299], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 573 / 744], [train main loss -8.763521], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 574 / 744], [train main loss -8.768866], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 575 / 744], [train main loss -8.775619], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 576 / 744], [train main loss -8.780443], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 577 / 744], [train main loss -8.776588], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 578 / 744], [train main loss -8.769516], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 579 / 744], [train main loss -8.767310], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 580 / 744], [train main loss -8.764292], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 581 / 744], [train main loss -8.763616], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 582 / 744], [train main loss -8.756971], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 583 / 744], [train main loss -8.754095], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 584 / 744], [train main loss -8.753441], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 585 / 744], [train main loss -8.754423], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 586 / 744], [train main loss -8.764090], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 587 / 744], [train main loss -8.760756], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 588 / 744], [train main loss -8.748571], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 589 / 744], [train main loss -8.739109], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 590 / 744], [train main loss -8.746910], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 591 / 744], [train main loss -8.751384], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 592 / 744], [train main loss -8.747611], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 593 / 744], [train main loss -8.740468], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 594 / 744], [train main loss -8.736219], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 595 / 744], [train main loss -8.740277], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 596 / 744], [train main loss -8.734775], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 597 / 744], [train main loss -8.735297], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 598 / 744], [train main loss -8.736864], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 599 / 744], [train main loss -8.729600], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 600 / 744], [train main loss -8.737330], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 601 / 744], [train main loss -8.740819], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 602 / 744], [train main loss -8.737938], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 603 / 744], [train main loss -8.736907], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 604 / 744], [train main loss -8.732345], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 605 / 744], [train main loss -8.727863], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 606 / 744], [train main loss -8.733685], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 607 / 744], [train main loss -8.732315], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 608 / 744], [train main loss -8.724990], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 609 / 744], [train main loss -8.723311], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 610 / 744], [train main loss -8.725209], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 611 / 744], [train main loss -8.720898], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 612 / 744], [train main loss -8.727841], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 613 / 744], [train main loss -8.733413], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 614 / 744], [train main loss -8.735037], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 615 / 744], [train main loss -8.732006], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 616 / 744], [train main loss -8.728157], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 617 / 744], [train main loss -8.728428], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 618 / 744], [train main loss -8.725197], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 619 / 744], [train main loss -8.727588], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 620 / 744], [train main loss -8.740958], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 621 / 744], [train main loss -8.736094], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 622 / 744], [train main loss -8.734734], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 623 / 744], [train main loss -8.734039], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 624 / 744], [train main loss -8.741226], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 625 / 744], [train main loss -8.743428], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 626 / 744], [train main loss -8.756187], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 627 / 744], [train main loss -8.758900], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 628 / 744], [train main loss -8.757060], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 629 / 744], [train main loss -8.759049], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 630 / 744], [train main loss -8.772581], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 631 / 744], [train main loss -8.775320], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 632 / 744], [train main loss -8.777370], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 633 / 744], [train main loss -8.774576], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 634 / 744], [train main loss -8.771205], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 635 / 744], [train main loss -8.770261], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 636 / 744], [train main loss -8.775673], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 637 / 744], [train main loss -8.773023], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 638 / 744], [train main loss -8.772836], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 639 / 744], [train main loss -8.769302], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 640 / 744], [train main loss -8.770501], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 641 / 744], [train main loss -8.779905], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 642 / 744], [train main loss -8.777973], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 643 / 744], [train main loss -8.787523], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 644 / 744], [train main loss -8.784999], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 645 / 744], [train main loss -8.786528], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 646 / 744], [train main loss -8.787248], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 647 / 744], [train main loss -8.787856], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 648 / 744], [train main loss -8.783637], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 649 / 744], [train main loss -8.788118], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 650 / 744], [train main loss -8.789678], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 651 / 744], [train main loss -8.786494], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 652 / 744], [train main loss -8.793368], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 653 / 744], [train main loss -8.786767], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 654 / 744], [train main loss -8.789399], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 655 / 744], [train main loss -8.792884], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 656 / 744], [train main loss -8.790487], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 657 / 744], [train main loss -8.789102], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 658 / 744], [train main loss -8.792508], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 659 / 744], [train main loss -8.794058], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 660 / 744], [train main loss -8.787794], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 661 / 744], [train main loss -8.795678], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 662 / 744], [train main loss -8.791311], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 663 / 744], [train main loss -8.789303], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 664 / 744], [train main loss -8.794769], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 665 / 744], [train main loss -8.797274], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 666 / 744], [train main loss -8.796147], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 667 / 744], [train main loss -8.796261], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 668 / 744], [train main loss -8.797033], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 669 / 744], [train main loss -8.791451], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 670 / 744], [train main loss -8.791511], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 671 / 744], [train main loss -8.787238], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 672 / 744], [train main loss -8.786767], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 673 / 744], [train main loss -8.787906], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 674 / 744], [train main loss -8.790228], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 675 / 744], [train main loss -8.794922], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 676 / 744], [train main loss -8.797006], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 677 / 744], [train main loss -8.796923], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 678 / 744], [train main loss -8.799484], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 679 / 744], [train main loss -8.798613], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 680 / 744], [train main loss -8.804073], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 681 / 744], [train main loss -8.811872], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 682 / 744], [train main loss -8.811770], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 683 / 744], [train main loss -8.800864], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 684 / 744], [train main loss -8.806281], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 685 / 744], [train main loss -8.811709], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 686 / 744], [train main loss -8.811327], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 687 / 744], [train main loss -8.804936], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 688 / 744], [train main loss -8.796379], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 689 / 744], [train main loss -8.792301], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 690 / 744], [train main loss -8.785324], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 691 / 744], [train main loss -8.773425], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 692 / 744], [train main loss -8.770931], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 693 / 744], [train main loss -8.769703], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 694 / 744], [train main loss -8.773423], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 695 / 744], [train main loss -8.773024], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 696 / 744], [train main loss -8.777614], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 697 / 744], [train main loss -8.776597], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 698 / 744], [train main loss -8.778038], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 699 / 744], [train main loss -8.770270], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 700 / 744], [train main loss -8.775976], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 701 / 744], [train main loss -8.772881], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 702 / 744], [train main loss -8.778302], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 703 / 744], [train main loss -8.781326], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 704 / 744], [train main loss -8.785801], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 705 / 744], [train main loss -8.786746], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 706 / 744], [train main loss -8.790164], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 707 / 744], [train main loss -8.787839], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 708 / 744], [train main loss -8.794473], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 709 / 744], [train main loss -8.793380], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 710 / 744], [train main loss -8.792878], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 711 / 744], [train main loss -8.793565], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 712 / 744], [train main loss -8.800067], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 713 / 744], [train main loss -8.800470], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 714 / 744], [train main loss -8.800053], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 715 / 744], [train main loss -8.799386], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 716 / 744], [train main loss -8.801582], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 717 / 744], [train main loss -8.801292], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 718 / 744], [train main loss -8.803257], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 719 / 744], [train main loss -8.799618], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 720 / 744], [train main loss -8.808849], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 721 / 744], [train main loss -8.806941], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 722 / 744], [train main loss -8.805490], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 723 / 744], [train main loss -8.805089], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 724 / 744], [train main loss -8.804380], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 725 / 744], [train main loss -8.804775], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 726 / 744], [train main loss -8.805879], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 727 / 744], [train main loss -8.807485], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 728 / 744], [train main loss -8.808373], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 729 / 744], [train main loss -8.807287], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 730 / 744], [train main loss -8.807784], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 731 / 744], [train main loss -8.811654], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 732 / 744], [train main loss -8.823649], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 733 / 744], [train main loss -8.825176], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 734 / 744], [train main loss -8.828490], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 735 / 744], [train main loss -8.829084], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 736 / 744], [train main loss -8.824457], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 737 / 744], [train main loss -8.821007], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 738 / 744], [train main loss -8.823927], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 739 / 744], [train main loss -8.822755], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 740 / 744], [train main loss -8.819366], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 741 / 744], [train main loss -8.817483], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 742 / 744], [train main loss -8.812570], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 743 / 744], [train main loss -8.815589], [lr 0.004718] [batchtime 1.14]
[epoch 5], [iter 744 / 744], [train main loss -8.811330], [lr 0.004718] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              97.81  37.06  0.02  0.01         0.98      0.99
   1  sidewalk          83.03   5.12  0.06  0.15         0.95      0.87
   2  building          93.18  21.14  0.04  0.04         0.96      0.96
   3  wall              61.21   0.57  0.28  0.35         0.78      0.74
   4  fence             62.36   0.62  0.32  0.28         0.76      0.78
   5  pole              68.82   1.15  0.29  0.17         0.78      0.86
   6  traffic light     77.69   0.17  0.14  0.14         0.87      0.87
   7  traffic sign      80.88   0.57  0.17  0.06         0.85      0.94
   8  vegetation        90.86  16.29  0.06  0.04         0.94      0.96
   9  terrain           48.67   0.69  0.21  0.84         0.83      0.54
  10  sky               94.24   3.31  0.01  0.05         0.99      0.95
  11  person            81.63   1.13  0.15  0.07         0.87      0.93
  12  rider             66.11   0.18  0.21  0.30         0.83      0.77
  13  car               94.02   6.22  0.05  0.02         0.96      0.98
  14  truck             83.59   0.28  0.07  0.12         0.93      0.89
  15  bus               90.41   0.37  0.05  0.06         0.95      0.95
  16  train             80.27   0.09  0.22  0.03         0.82      0.98
  17  motorcycle        27.34   0.07  0.18  2.48         0.85      0.29
  18  bicycle           77.94   0.65  0.09  0.19         0.92      0.84
Mean: 76.85
-----------------------------------------------------------------------------------------------------------
this : [epoch 5], [val loss 0.14703], [acc 0.95675], [acc_cls 0.88460], [mean_iu 0.76845], [fwavacc 0.92312]
best : [epoch 2], [val loss 0.15303], [acc 0.95799], [acc_cls 0.84888], [mean_iu 0.77525], [fwavacc 0.92257]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 6], [iter 1 / 744], [train main loss -12.977031], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 2 / 744], [train main loss -12.308443], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 3 / 744], [train main loss -8.800893], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 4 / 744], [train main loss -8.424495], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 5 / 744], [train main loss -8.308654], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 6 / 744], [train main loss -8.586197], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 7 / 744], [train main loss -8.420083], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 8 / 744], [train main loss -8.180635], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 9 / 744], [train main loss -8.448462], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 10 / 744], [train main loss -8.554482], [lr 0.004663] [batchtime 0]
[epoch 6], [iter 11 / 744], [train main loss -8.656266], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 12 / 744], [train main loss -8.318735], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 13 / 744], [train main loss -7.883604], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 14 / 744], [train main loss -7.578374], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 15 / 744], [train main loss -7.640833], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 16 / 744], [train main loss -7.625687], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 17 / 744], [train main loss -7.632748], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 18 / 744], [train main loss -7.690227], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 19 / 744], [train main loss -7.674530], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 20 / 744], [train main loss -7.580793], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 21 / 744], [train main loss -7.796356], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 22 / 744], [train main loss -7.765369], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 23 / 744], [train main loss -7.786093], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 24 / 744], [train main loss -7.661095], [lr 0.004663] [batchtime 1.13]
[epoch 6], [iter 25 / 744], [train main loss -7.566357], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 26 / 744], [train main loss -7.605309], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 27 / 744], [train main loss -7.496196], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 28 / 744], [train main loss -7.428481], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 29 / 744], [train main loss -7.238051], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 30 / 744], [train main loss -7.117289], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 31 / 744], [train main loss -7.023135], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 32 / 744], [train main loss -7.142373], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 33 / 744], [train main loss -7.327302], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 34 / 744], [train main loss -7.288294], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 35 / 744], [train main loss -7.185163], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 36 / 744], [train main loss -7.246589], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 37 / 744], [train main loss -7.064153], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 38 / 744], [train main loss -7.100292], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 39 / 744], [train main loss -7.193183], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 40 / 744], [train main loss -7.080273], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 41 / 744], [train main loss -7.066568], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 42 / 744], [train main loss -7.041971], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 43 / 744], [train main loss -7.061748], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 44 / 744], [train main loss -6.976118], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 45 / 744], [train main loss -6.962394], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 46 / 744], [train main loss -7.172024], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 47 / 744], [train main loss -7.312887], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 48 / 744], [train main loss -7.338721], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 49 / 744], [train main loss -7.296339], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 50 / 744], [train main loss -7.296545], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 51 / 744], [train main loss -7.265668], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 52 / 744], [train main loss -7.361959], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 53 / 744], [train main loss -7.329095], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 54 / 744], [train main loss -7.386075], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 55 / 744], [train main loss -7.400400], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 56 / 744], [train main loss -7.466512], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 57 / 744], [train main loss -7.489928], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 58 / 744], [train main loss -7.465776], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 59 / 744], [train main loss -7.496340], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 60 / 744], [train main loss -7.587052], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 61 / 744], [train main loss -7.618955], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 62 / 744], [train main loss -7.592184], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 63 / 744], [train main loss -7.584672], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 64 / 744], [train main loss -7.595772], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 65 / 744], [train main loss -7.571658], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 66 / 744], [train main loss -7.496399], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 67 / 744], [train main loss -7.459252], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 68 / 744], [train main loss -7.443533], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 69 / 744], [train main loss -7.379741], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 70 / 744], [train main loss -7.380075], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 71 / 744], [train main loss -7.379534], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 72 / 744], [train main loss -7.357380], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 73 / 744], [train main loss -7.400152], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 74 / 744], [train main loss -7.370794], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 75 / 744], [train main loss -7.366267], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 76 / 744], [train main loss -7.336425], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 77 / 744], [train main loss -7.356947], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 78 / 744], [train main loss -7.332812], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 79 / 744], [train main loss -7.371513], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 80 / 744], [train main loss -7.427776], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 81 / 744], [train main loss -7.437269], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 82 / 744], [train main loss -7.461007], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 83 / 744], [train main loss -7.473691], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 84 / 744], [train main loss -7.531456], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 85 / 744], [train main loss -7.440259], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 86 / 744], [train main loss -7.435071], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 87 / 744], [train main loss -7.437674], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 88 / 744], [train main loss -7.446294], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 89 / 744], [train main loss -7.459077], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 90 / 744], [train main loss -7.529548], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 91 / 744], [train main loss -7.506119], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 92 / 744], [train main loss -7.477320], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 93 / 744], [train main loss -7.440396], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 94 / 744], [train main loss -7.435101], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 95 / 744], [train main loss -7.448689], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 96 / 744], [train main loss -7.449482], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 97 / 744], [train main loss -7.463284], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 98 / 744], [train main loss -7.498699], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 99 / 744], [train main loss -7.533745], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 100 / 744], [train main loss -7.562690], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 101 / 744], [train main loss -7.541329], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 102 / 744], [train main loss -7.542140], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 103 / 744], [train main loss -7.551829], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 104 / 744], [train main loss -7.559496], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 105 / 744], [train main loss -7.602423], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 106 / 744], [train main loss -7.641280], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 107 / 744], [train main loss -7.611192], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 108 / 744], [train main loss -7.600826], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 109 / 744], [train main loss -7.565328], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 110 / 744], [train main loss -7.652445], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 111 / 744], [train main loss -7.603505], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 112 / 744], [train main loss -7.597672], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 113 / 744], [train main loss -7.615867], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 114 / 744], [train main loss -7.656036], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 115 / 744], [train main loss -7.650728], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 116 / 744], [train main loss -7.702736], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 117 / 744], [train main loss -7.719140], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 118 / 744], [train main loss -7.704625], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 119 / 744], [train main loss -7.739385], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 120 / 744], [train main loss -7.826108], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 121 / 744], [train main loss -7.813038], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 122 / 744], [train main loss -7.874223], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 123 / 744], [train main loss -7.872881], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 124 / 744], [train main loss -7.846160], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 125 / 744], [train main loss -7.904463], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 126 / 744], [train main loss -7.896607], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 127 / 744], [train main loss -7.927141], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 128 / 744], [train main loss -7.925380], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 129 / 744], [train main loss -7.905355], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 130 / 744], [train main loss -7.882544], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 131 / 744], [train main loss -7.928085], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 132 / 744], [train main loss -7.918334], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 133 / 744], [train main loss -7.938398], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 134 / 744], [train main loss -7.935646], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 135 / 744], [train main loss -7.941240], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 136 / 744], [train main loss -7.914336], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 137 / 744], [train main loss -7.942736], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 138 / 744], [train main loss -7.993980], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 139 / 744], [train main loss -7.985300], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 140 / 744], [train main loss -7.979771], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 141 / 744], [train main loss -7.977539], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 142 / 744], [train main loss -7.993096], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 143 / 744], [train main loss -8.015109], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 144 / 744], [train main loss -8.010305], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 145 / 744], [train main loss -7.969207], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 146 / 744], [train main loss -7.975755], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 147 / 744], [train main loss -7.981693], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 148 / 744], [train main loss -7.982529], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 149 / 744], [train main loss -7.998004], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 150 / 744], [train main loss -8.005948], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 151 / 744], [train main loss -8.024439], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 152 / 744], [train main loss -8.023314], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 153 / 744], [train main loss -8.037857], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 154 / 744], [train main loss -8.078426], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 155 / 744], [train main loss -8.088605], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 156 / 744], [train main loss -8.110452], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 157 / 744], [train main loss -8.133695], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 158 / 744], [train main loss -8.139163], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 159 / 744], [train main loss -8.144495], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 160 / 744], [train main loss -8.127301], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 161 / 744], [train main loss -8.149968], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 162 / 744], [train main loss -8.165769], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 163 / 744], [train main loss -8.175260], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 164 / 744], [train main loss -8.150554], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 165 / 744], [train main loss -8.165734], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 166 / 744], [train main loss -8.143505], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 167 / 744], [train main loss -8.147861], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 168 / 744], [train main loss -8.124312], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 169 / 744], [train main loss -8.118151], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 170 / 744], [train main loss -8.122405], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 171 / 744], [train main loss -8.103920], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 172 / 744], [train main loss -8.094563], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 173 / 744], [train main loss -8.082180], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 174 / 744], [train main loss -8.102371], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 175 / 744], [train main loss -8.098968], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 176 / 744], [train main loss -8.104387], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 177 / 744], [train main loss -8.140625], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 178 / 744], [train main loss -8.126953], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 179 / 744], [train main loss -8.147718], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 180 / 744], [train main loss -8.159307], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 181 / 744], [train main loss -8.178011], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 182 / 744], [train main loss -8.167998], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 183 / 744], [train main loss -8.135649], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 184 / 744], [train main loss -8.127654], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 185 / 744], [train main loss -8.146849], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 186 / 744], [train main loss -8.129851], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 187 / 744], [train main loss -8.124735], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 188 / 744], [train main loss -8.160123], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 189 / 744], [train main loss -8.205032], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 190 / 744], [train main loss -8.207869], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 191 / 744], [train main loss -8.218242], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 192 / 744], [train main loss -8.225830], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 193 / 744], [train main loss -8.234897], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 194 / 744], [train main loss -8.236054], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 195 / 744], [train main loss -8.267568], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 196 / 744], [train main loss -8.278819], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 197 / 744], [train main loss -8.273971], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 198 / 744], [train main loss -8.250930], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 199 / 744], [train main loss -8.239961], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 200 / 744], [train main loss -8.231970], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 201 / 744], [train main loss -8.218737], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 202 / 744], [train main loss -8.209849], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 203 / 744], [train main loss -8.194466], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 204 / 744], [train main loss -8.189158], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 205 / 744], [train main loss -8.204341], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 206 / 744], [train main loss -8.233695], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 207 / 744], [train main loss -8.224870], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 208 / 744], [train main loss -8.254293], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 209 / 744], [train main loss -8.264103], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 210 / 744], [train main loss -8.270883], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 211 / 744], [train main loss -8.259853], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 212 / 744], [train main loss -8.269430], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 213 / 744], [train main loss -8.286313], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 214 / 744], [train main loss -8.280251], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 215 / 744], [train main loss -8.270123], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 216 / 744], [train main loss -8.269138], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 217 / 744], [train main loss -8.282632], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 218 / 744], [train main loss -8.285081], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 219 / 744], [train main loss -8.258495], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 220 / 744], [train main loss -8.284608], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 221 / 744], [train main loss -8.329556], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 222 / 744], [train main loss -8.347795], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 223 / 744], [train main loss -8.326808], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 224 / 744], [train main loss -8.323254], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 225 / 744], [train main loss -8.314786], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 226 / 744], [train main loss -8.308418], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 227 / 744], [train main loss -8.325060], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 228 / 744], [train main loss -8.334904], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 229 / 744], [train main loss -8.333216], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 230 / 744], [train main loss -8.352577], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 231 / 744], [train main loss -8.372017], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 232 / 744], [train main loss -8.392183], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 233 / 744], [train main loss -8.377556], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 234 / 744], [train main loss -8.402110], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 235 / 744], [train main loss -8.400782], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 236 / 744], [train main loss -8.425029], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 237 / 744], [train main loss -8.433010], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 238 / 744], [train main loss -8.457768], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 239 / 744], [train main loss -8.448921], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 240 / 744], [train main loss -8.452247], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 241 / 744], [train main loss -8.438138], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 242 / 744], [train main loss -8.419180], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 243 / 744], [train main loss -8.407440], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 244 / 744], [train main loss -8.410450], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 245 / 744], [train main loss -8.418092], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 246 / 744], [train main loss -8.403893], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 247 / 744], [train main loss -8.416948], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 248 / 744], [train main loss -8.413752], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 249 / 744], [train main loss -8.447541], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 250 / 744], [train main loss -8.427209], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 251 / 744], [train main loss -8.435853], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 252 / 744], [train main loss -8.420914], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 253 / 744], [train main loss -8.407632], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 254 / 744], [train main loss -8.394071], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 255 / 744], [train main loss -8.397251], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 256 / 744], [train main loss -8.404466], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 257 / 744], [train main loss -8.390277], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 258 / 744], [train main loss -8.369641], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 259 / 744], [train main loss -8.390019], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 260 / 744], [train main loss -8.382304], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 261 / 744], [train main loss -8.389011], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 262 / 744], [train main loss -8.420084], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 263 / 744], [train main loss -8.409865], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 264 / 744], [train main loss -8.396245], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 265 / 744], [train main loss -8.390157], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 266 / 744], [train main loss -8.362299], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 267 / 744], [train main loss -8.384573], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 268 / 744], [train main loss -8.376775], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 269 / 744], [train main loss -8.370236], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 270 / 744], [train main loss -8.377242], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 271 / 744], [train main loss -8.365748], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 272 / 744], [train main loss -8.385265], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 273 / 744], [train main loss -8.373235], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 274 / 744], [train main loss -8.367773], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 275 / 744], [train main loss -8.366296], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 276 / 744], [train main loss -8.379244], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 277 / 744], [train main loss -8.381009], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 278 / 744], [train main loss -8.393370], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 279 / 744], [train main loss -8.364228], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 280 / 744], [train main loss -8.361986], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 281 / 744], [train main loss -8.389035], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 282 / 744], [train main loss -8.379435], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 283 / 744], [train main loss -8.352279], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 284 / 744], [train main loss -8.349023], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 285 / 744], [train main loss -8.377783], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 286 / 744], [train main loss -8.378136], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 287 / 744], [train main loss -8.369965], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 288 / 744], [train main loss -8.362316], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 289 / 744], [train main loss -8.371667], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 290 / 744], [train main loss -8.372818], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 291 / 744], [train main loss -8.376723], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 292 / 744], [train main loss -8.378425], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 293 / 744], [train main loss -8.404533], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 294 / 744], [train main loss -8.391097], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 295 / 744], [train main loss -8.369729], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 296 / 744], [train main loss -8.396343], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 297 / 744], [train main loss -8.401459], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 298 / 744], [train main loss -8.395248], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 299 / 744], [train main loss -8.390767], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 300 / 744], [train main loss -8.386425], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 301 / 744], [train main loss -8.385807], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 302 / 744], [train main loss -8.382399], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 303 / 744], [train main loss -8.415569], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 304 / 744], [train main loss -8.411352], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 305 / 744], [train main loss -8.418799], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 306 / 744], [train main loss -8.437859], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 307 / 744], [train main loss -8.434098], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 308 / 744], [train main loss -8.429628], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 309 / 744], [train main loss -8.419635], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 310 / 744], [train main loss -8.422826], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 311 / 744], [train main loss -8.422980], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 312 / 744], [train main loss -8.414508], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 313 / 744], [train main loss -8.422858], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 314 / 744], [train main loss -8.412254], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 315 / 744], [train main loss -8.404662], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 316 / 744], [train main loss -8.396573], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 317 / 744], [train main loss -8.387190], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 318 / 744], [train main loss -8.382828], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 319 / 744], [train main loss -8.385381], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 320 / 744], [train main loss -8.384752], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 321 / 744], [train main loss -8.402184], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 322 / 744], [train main loss -8.399560], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 323 / 744], [train main loss -8.404854], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 324 / 744], [train main loss -8.407384], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 325 / 744], [train main loss -8.406921], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 326 / 744], [train main loss -8.408468], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 327 / 744], [train main loss -8.408354], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 328 / 744], [train main loss -8.416245], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 329 / 744], [train main loss -8.397374], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 330 / 744], [train main loss -8.409527], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 331 / 744], [train main loss -8.412405], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 332 / 744], [train main loss -8.406065], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 333 / 744], [train main loss -8.408409], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 334 / 744], [train main loss -8.409155], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 335 / 744], [train main loss -8.432137], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 336 / 744], [train main loss -8.430714], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 337 / 744], [train main loss -8.429543], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 338 / 744], [train main loss -8.423404], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 339 / 744], [train main loss -8.428857], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 340 / 744], [train main loss -8.447599], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 341 / 744], [train main loss -8.449118], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 342 / 744], [train main loss -8.440317], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 343 / 744], [train main loss -8.431018], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 344 / 744], [train main loss -8.442120], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 345 / 744], [train main loss -8.460391], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 346 / 744], [train main loss -8.452739], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 347 / 744], [train main loss -8.439638], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 348 / 744], [train main loss -8.435734], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 349 / 744], [train main loss -8.430448], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 350 / 744], [train main loss -8.419256], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 351 / 744], [train main loss -8.410599], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 352 / 744], [train main loss -8.404723], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 353 / 744], [train main loss -8.387373], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 354 / 744], [train main loss -8.391423], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 355 / 744], [train main loss -8.398541], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 356 / 744], [train main loss -8.388611], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 357 / 744], [train main loss -8.381941], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 358 / 744], [train main loss -8.388805], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 359 / 744], [train main loss -8.392606], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 360 / 744], [train main loss -8.400291], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 361 / 744], [train main loss -8.404339], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 362 / 744], [train main loss -8.387424], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 363 / 744], [train main loss -8.392788], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 364 / 744], [train main loss -8.387211], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 365 / 744], [train main loss -8.373197], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 366 / 744], [train main loss -8.369813], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 367 / 744], [train main loss -8.384685], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 368 / 744], [train main loss -8.377984], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 369 / 744], [train main loss -8.369217], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 370 / 744], [train main loss -8.363522], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 371 / 744], [train main loss -8.350665], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 372 / 744], [train main loss -8.346695], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 373 / 744], [train main loss -8.366580], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 374 / 744], [train main loss -8.360429], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 375 / 744], [train main loss -8.360944], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 376 / 744], [train main loss -8.363146], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 377 / 744], [train main loss -8.360521], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 378 / 744], [train main loss -8.352623], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 379 / 744], [train main loss -8.348355], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 380 / 744], [train main loss -8.361725], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 381 / 744], [train main loss -8.373144], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 382 / 744], [train main loss -8.373198], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 383 / 744], [train main loss -8.380816], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 384 / 744], [train main loss -8.377045], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 385 / 744], [train main loss -8.385871], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 386 / 744], [train main loss -8.380164], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 387 / 744], [train main loss -8.374195], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 388 / 744], [train main loss -8.379824], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 389 / 744], [train main loss -8.380441], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 390 / 744], [train main loss -8.394286], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 391 / 744], [train main loss -8.379446], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 392 / 744], [train main loss -8.380060], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 393 / 744], [train main loss -8.404503], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 394 / 744], [train main loss -8.398020], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 395 / 744], [train main loss -8.381229], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 396 / 744], [train main loss -8.375147], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 397 / 744], [train main loss -8.371964], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 398 / 744], [train main loss -8.358756], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 399 / 744], [train main loss -8.364256], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 400 / 744], [train main loss -8.364875], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 401 / 744], [train main loss -8.364539], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 402 / 744], [train main loss -8.360973], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 403 / 744], [train main loss -8.369681], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 404 / 744], [train main loss -8.357930], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 405 / 744], [train main loss -8.353993], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 406 / 744], [train main loss -8.346402], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 407 / 744], [train main loss -8.340715], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 408 / 744], [train main loss -8.349152], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 409 / 744], [train main loss -8.352158], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 410 / 744], [train main loss -8.343790], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 411 / 744], [train main loss -8.343260], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 412 / 744], [train main loss -8.348496], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 413 / 744], [train main loss -8.353269], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 414 / 744], [train main loss -8.354925], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 415 / 744], [train main loss -8.350871], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 416 / 744], [train main loss -8.349036], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 417 / 744], [train main loss -8.356588], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 418 / 744], [train main loss -8.356740], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 419 / 744], [train main loss -8.356458], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 420 / 744], [train main loss -8.360561], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 421 / 744], [train main loss -8.350695], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 422 / 744], [train main loss -8.355266], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 423 / 744], [train main loss -8.338470], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 424 / 744], [train main loss -8.334089], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 425 / 744], [train main loss -8.332978], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 426 / 744], [train main loss -8.325679], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 427 / 744], [train main loss -8.326094], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 428 / 744], [train main loss -8.332854], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 429 / 744], [train main loss -8.327299], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 430 / 744], [train main loss -8.326837], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 431 / 744], [train main loss -8.329185], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 432 / 744], [train main loss -8.332675], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 433 / 744], [train main loss -8.322790], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 434 / 744], [train main loss -8.317471], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 435 / 744], [train main loss -8.325204], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 436 / 744], [train main loss -8.331802], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 437 / 744], [train main loss -8.341775], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 438 / 744], [train main loss -8.344820], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 439 / 744], [train main loss -8.347522], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 440 / 744], [train main loss -8.355568], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 441 / 744], [train main loss -8.341832], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 442 / 744], [train main loss -8.336571], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 443 / 744], [train main loss -8.352169], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 444 / 744], [train main loss -8.351048], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 445 / 744], [train main loss -8.341750], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 446 / 744], [train main loss -8.358494], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 447 / 744], [train main loss -8.351077], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 448 / 744], [train main loss -8.339212], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 449 / 744], [train main loss -8.341257], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 450 / 744], [train main loss -8.340545], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 451 / 744], [train main loss -8.329016], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 452 / 744], [train main loss -8.322438], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 453 / 744], [train main loss -8.319398], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 454 / 744], [train main loss -8.315351], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 455 / 744], [train main loss -8.311651], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 456 / 744], [train main loss -8.313394], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 457 / 744], [train main loss -8.301309], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 458 / 744], [train main loss -8.306370], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 459 / 744], [train main loss -8.305666], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 460 / 744], [train main loss -8.299471], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 461 / 744], [train main loss -8.295080], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 462 / 744], [train main loss -8.300399], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 463 / 744], [train main loss -8.301874], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 464 / 744], [train main loss -8.313047], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 465 / 744], [train main loss -8.313257], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 466 / 744], [train main loss -8.325959], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 467 / 744], [train main loss -8.327889], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 468 / 744], [train main loss -8.344542], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 469 / 744], [train main loss -8.351549], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 470 / 744], [train main loss -8.366714], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 471 / 744], [train main loss -8.351920], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 472 / 744], [train main loss -8.358488], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 473 / 744], [train main loss -8.355072], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 474 / 744], [train main loss -8.352730], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 475 / 744], [train main loss -8.351416], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 476 / 744], [train main loss -8.357208], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 477 / 744], [train main loss -8.364867], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 478 / 744], [train main loss -8.370290], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 479 / 744], [train main loss -8.363943], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 480 / 744], [train main loss -8.370154], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 481 / 744], [train main loss -8.374814], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 482 / 744], [train main loss -8.372088], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 483 / 744], [train main loss -8.372254], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 484 / 744], [train main loss -8.371388], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 485 / 744], [train main loss -8.387981], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 486 / 744], [train main loss -8.394112], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 487 / 744], [train main loss -8.398683], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 488 / 744], [train main loss -8.391211], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 489 / 744], [train main loss -8.396588], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 490 / 744], [train main loss -8.398387], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 491 / 744], [train main loss -8.393253], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 492 / 744], [train main loss -8.397274], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 493 / 744], [train main loss -8.393982], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 494 / 744], [train main loss -8.394587], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 495 / 744], [train main loss -8.388573], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 496 / 744], [train main loss -8.384425], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 497 / 744], [train main loss -8.378877], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 498 / 744], [train main loss -8.381522], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 499 / 744], [train main loss -8.380149], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 500 / 744], [train main loss -8.391697], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 501 / 744], [train main loss -8.399385], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 502 / 744], [train main loss -8.399919], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 503 / 744], [train main loss -8.393578], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 504 / 744], [train main loss -8.392917], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 505 / 744], [train main loss -8.387648], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 506 / 744], [train main loss -8.399574], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 507 / 744], [train main loss -8.403552], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 508 / 744], [train main loss -8.399383], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 509 / 744], [train main loss -8.407074], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 510 / 744], [train main loss -8.396318], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 511 / 744], [train main loss -8.391842], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 512 / 744], [train main loss -8.381551], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 513 / 744], [train main loss -8.382331], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 514 / 744], [train main loss -8.387232], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 515 / 744], [train main loss -8.395104], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 516 / 744], [train main loss -8.388921], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 517 / 744], [train main loss -8.390263], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 518 / 744], [train main loss -8.393257], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 519 / 744], [train main loss -8.390210], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 520 / 744], [train main loss -8.379877], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 521 / 744], [train main loss -8.386889], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 522 / 744], [train main loss -8.377838], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 523 / 744], [train main loss -8.375268], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 524 / 744], [train main loss -8.372233], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 525 / 744], [train main loss -8.371484], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 526 / 744], [train main loss -8.362994], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 527 / 744], [train main loss -8.365700], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 528 / 744], [train main loss -8.360629], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 529 / 744], [train main loss -8.366613], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 530 / 744], [train main loss -8.364253], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 531 / 744], [train main loss -8.361329], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 532 / 744], [train main loss -8.364638], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 533 / 744], [train main loss -8.358022], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 534 / 744], [train main loss -8.355148], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 535 / 744], [train main loss -8.362893], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 536 / 744], [train main loss -8.357206], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 537 / 744], [train main loss -8.350649], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 538 / 744], [train main loss -8.339348], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 539 / 744], [train main loss -8.339275], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 540 / 744], [train main loss -8.342702], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 541 / 744], [train main loss -8.334930], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 542 / 744], [train main loss -8.342197], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 543 / 744], [train main loss -8.335814], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 544 / 744], [train main loss -8.348634], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 545 / 744], [train main loss -8.349419], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 546 / 744], [train main loss -8.350900], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 547 / 744], [train main loss -8.351333], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 548 / 744], [train main loss -8.345302], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 549 / 744], [train main loss -8.359432], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 550 / 744], [train main loss -8.343946], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 551 / 744], [train main loss -8.346609], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 552 / 744], [train main loss -8.350588], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 553 / 744], [train main loss -8.351198], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 554 / 744], [train main loss -8.358327], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 555 / 744], [train main loss -8.353253], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 556 / 744], [train main loss -8.356544], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 557 / 744], [train main loss -8.350972], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 558 / 744], [train main loss -8.344911], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 559 / 744], [train main loss -8.345562], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 560 / 744], [train main loss -8.349258], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 561 / 744], [train main loss -8.349271], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 562 / 744], [train main loss -8.347349], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 563 / 744], [train main loss -8.352620], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 564 / 744], [train main loss -8.346104], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 565 / 744], [train main loss -8.343632], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 566 / 744], [train main loss -8.347213], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 567 / 744], [train main loss -8.356018], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 568 / 744], [train main loss -8.357786], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 569 / 744], [train main loss -8.358595], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 570 / 744], [train main loss -8.362891], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 571 / 744], [train main loss -8.375593], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 572 / 744], [train main loss -8.379671], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 573 / 744], [train main loss -8.378572], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 574 / 744], [train main loss -8.379755], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 575 / 744], [train main loss -8.380092], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 576 / 744], [train main loss -8.381772], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 577 / 744], [train main loss -8.373019], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 578 / 744], [train main loss -8.372577], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 579 / 744], [train main loss -8.373242], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 580 / 744], [train main loss -8.372734], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 581 / 744], [train main loss -8.375919], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 582 / 744], [train main loss -8.377927], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 583 / 744], [train main loss -8.386657], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 584 / 744], [train main loss -8.393007], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 585 / 744], [train main loss -8.398712], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 586 / 744], [train main loss -8.398416], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 587 / 744], [train main loss -8.401713], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 588 / 744], [train main loss -8.398570], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 589 / 744], [train main loss -8.395895], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 590 / 744], [train main loss -8.403050], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 591 / 744], [train main loss -8.401957], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 592 / 744], [train main loss -8.407410], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 593 / 744], [train main loss -8.408076], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 594 / 744], [train main loss -8.411502], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 595 / 744], [train main loss -8.420227], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 596 / 744], [train main loss -8.426083], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 597 / 744], [train main loss -8.420796], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 598 / 744], [train main loss -8.424862], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 599 / 744], [train main loss -8.415538], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 600 / 744], [train main loss -8.420584], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 601 / 744], [train main loss -8.421920], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 602 / 744], [train main loss -8.420594], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 603 / 744], [train main loss -8.429625], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 604 / 744], [train main loss -8.426056], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 605 / 744], [train main loss -8.415773], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 606 / 744], [train main loss -8.410670], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 607 / 744], [train main loss -8.408674], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 608 / 744], [train main loss -8.403858], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 609 / 744], [train main loss -8.404944], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 610 / 744], [train main loss -8.410165], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 611 / 744], [train main loss -8.421585], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 612 / 744], [train main loss -8.412950], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 613 / 744], [train main loss -8.405231], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 614 / 744], [train main loss -8.408589], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 615 / 744], [train main loss -8.401628], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 616 / 744], [train main loss -8.401182], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 617 / 744], [train main loss -8.402023], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 618 / 744], [train main loss -8.401311], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 619 / 744], [train main loss -8.399549], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 620 / 744], [train main loss -8.405484], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 621 / 744], [train main loss -8.404610], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 622 / 744], [train main loss -8.406530], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 623 / 744], [train main loss -8.408379], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 624 / 744], [train main loss -8.396328], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 625 / 744], [train main loss -8.402146], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 626 / 744], [train main loss -8.407802], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 627 / 744], [train main loss -8.406850], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 628 / 744], [train main loss -8.409474], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 629 / 744], [train main loss -8.410493], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 630 / 744], [train main loss -8.404068], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 631 / 744], [train main loss -8.400564], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 632 / 744], [train main loss -8.400034], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 633 / 744], [train main loss -8.401571], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 634 / 744], [train main loss -8.394536], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 635 / 744], [train main loss -8.398937], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 636 / 744], [train main loss -8.395753], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 637 / 744], [train main loss -8.389733], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 638 / 744], [train main loss -8.389703], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 639 / 744], [train main loss -8.398704], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 640 / 744], [train main loss -8.400706], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 641 / 744], [train main loss -8.399026], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 642 / 744], [train main loss -8.399695], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 643 / 744], [train main loss -8.400158], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 644 / 744], [train main loss -8.391443], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 645 / 744], [train main loss -8.388827], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 646 / 744], [train main loss -8.394416], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 647 / 744], [train main loss -8.390727], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 648 / 744], [train main loss -8.391833], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 649 / 744], [train main loss -8.401079], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 650 / 744], [train main loss -8.405601], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 651 / 744], [train main loss -8.397000], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 652 / 744], [train main loss -8.395140], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 653 / 744], [train main loss -8.386223], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 654 / 744], [train main loss -8.389620], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 655 / 744], [train main loss -8.397481], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 656 / 744], [train main loss -8.389072], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 657 / 744], [train main loss -8.390932], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 658 / 744], [train main loss -8.385149], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 659 / 744], [train main loss -8.384404], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 660 / 744], [train main loss -8.381549], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 661 / 744], [train main loss -8.378762], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 662 / 744], [train main loss -8.384341], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 663 / 744], [train main loss -8.390039], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 664 / 744], [train main loss -8.385448], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 665 / 744], [train main loss -8.389556], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 666 / 744], [train main loss -8.388191], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 667 / 744], [train main loss -8.387074], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 668 / 744], [train main loss -8.385583], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 669 / 744], [train main loss -8.380551], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 670 / 744], [train main loss -8.372147], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 671 / 744], [train main loss -8.367285], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 672 / 744], [train main loss -8.369256], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 673 / 744], [train main loss -8.367177], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 674 / 744], [train main loss -8.366494], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 675 / 744], [train main loss -8.357985], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 676 / 744], [train main loss -8.360751], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 677 / 744], [train main loss -8.356587], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 678 / 744], [train main loss -8.355655], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 679 / 744], [train main loss -8.365696], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 680 / 744], [train main loss -8.369500], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 681 / 744], [train main loss -8.373712], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 682 / 744], [train main loss -8.380572], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 683 / 744], [train main loss -8.380948], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 684 / 744], [train main loss -8.378636], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 685 / 744], [train main loss -8.382539], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 686 / 744], [train main loss -8.383284], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 687 / 744], [train main loss -8.382260], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 688 / 744], [train main loss -8.391203], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 689 / 744], [train main loss -8.397998], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 690 / 744], [train main loss -8.391579], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 691 / 744], [train main loss -8.392830], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 692 / 744], [train main loss -8.392561], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 693 / 744], [train main loss -8.389790], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 694 / 744], [train main loss -8.392294], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 695 / 744], [train main loss -8.394999], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 696 / 744], [train main loss -8.405116], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 697 / 744], [train main loss -8.399845], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 698 / 744], [train main loss -8.394843], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 699 / 744], [train main loss -8.391952], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 700 / 744], [train main loss -8.384533], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 701 / 744], [train main loss -8.388489], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 702 / 744], [train main loss -8.382932], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 703 / 744], [train main loss -8.383183], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 704 / 744], [train main loss -8.380686], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 705 / 744], [train main loss -8.379607], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 706 / 744], [train main loss -8.382429], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 707 / 744], [train main loss -8.387808], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 708 / 744], [train main loss -8.387363], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 709 / 744], [train main loss -8.390467], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 710 / 744], [train main loss -8.393849], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 711 / 744], [train main loss -8.385895], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 712 / 744], [train main loss -8.390095], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 713 / 744], [train main loss -8.395201], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 714 / 744], [train main loss -8.399453], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 715 / 744], [train main loss -8.403714], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 716 / 744], [train main loss -8.406250], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 717 / 744], [train main loss -8.407950], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 718 / 744], [train main loss -8.403267], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 719 / 744], [train main loss -8.403419], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 720 / 744], [train main loss -8.404477], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 721 / 744], [train main loss -8.403509], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 722 / 744], [train main loss -8.394554], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 723 / 744], [train main loss -8.391349], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 724 / 744], [train main loss -8.391249], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 725 / 744], [train main loss -8.401713], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 726 / 744], [train main loss -8.400212], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 727 / 744], [train main loss -8.404584], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 728 / 744], [train main loss -8.395931], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 729 / 744], [train main loss -8.401324], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 730 / 744], [train main loss -8.398207], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 731 / 744], [train main loss -8.395936], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 732 / 744], [train main loss -8.393291], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 733 / 744], [train main loss -8.385984], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 734 / 744], [train main loss -8.388324], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 735 / 744], [train main loss -8.380256], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 736 / 744], [train main loss -8.371529], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 737 / 744], [train main loss -8.380066], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 738 / 744], [train main loss -8.379742], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 739 / 744], [train main loss -8.378734], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 740 / 744], [train main loss -8.385138], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 741 / 744], [train main loss -8.392521], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 742 / 744], [train main loss -8.395783], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 743 / 744], [train main loss -8.394844], [lr 0.004663] [batchtime 1.14]
[epoch 6], [iter 744 / 744], [train main loss -8.396871], [lr 0.004663] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              97.95  37.19  0.01  0.01         0.99      0.99
   1  sidewalk          82.99   5.06  0.07  0.14         0.94      0.88
   2  building          92.71  21.15  0.04  0.04         0.96      0.96
   3  wall              62.35   0.52  0.42  0.19         0.71      0.84
   4  fence             65.99   0.65  0.26  0.25         0.79      0.80
   5  pole              69.14   1.14  0.30  0.15         0.77      0.87
   6  traffic light     75.88   0.16  0.21  0.11         0.83      0.90
   7  traffic sign      83.42   0.59  0.12  0.08         0.89      0.93
   8  vegetation        92.51  16.66  0.04  0.04         0.96      0.96
   9  terrain           52.31   0.46  0.80  0.11         0.56      0.90
  10  sky               91.00   3.32  0.01  0.09         0.99      0.92
  11  person            79.91   1.09  0.19  0.06         0.84      0.94
  12  rider             56.94   0.18  0.19  0.57         0.84      0.64
  13  car               95.75   6.40  0.02  0.03         0.98      0.97
  14  truck             85.91   0.28  0.08  0.09         0.93      0.92
  15  bus               81.42   0.36  0.08  0.15         0.93      0.87
  16  train             48.55   0.06  0.95  0.11         0.51      0.90
  17  motorcycle        56.80   0.06  0.27  0.49         0.79      0.67
  18  bicycle           79.14   0.64  0.10  0.16         0.91      0.86
Mean: 76.35
-----------------------------------------------------------------------------------------------------------
this : [epoch 6], [val loss 0.15210], [acc 0.95998], [acc_cls 0.84844], [mean_iu 0.76351], [fwavacc 0.92562]
best : [epoch 2], [val loss 0.15303], [acc 0.95799], [acc_cls 0.84888], [mean_iu 0.77525], [fwavacc 0.92257]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 7], [iter 1 / 744], [train main loss -13.832458], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 2 / 744], [train main loss -12.337438], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 3 / 744], [train main loss -11.806663], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 4 / 744], [train main loss -11.281382], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 5 / 744], [train main loss -11.489983], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 6 / 744], [train main loss -10.327529], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 7 / 744], [train main loss -10.090348], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 8 / 744], [train main loss -9.733148], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 9 / 744], [train main loss -9.849769], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 10 / 744], [train main loss -9.457855], [lr 0.004608] [batchtime 0]
[epoch 7], [iter 11 / 744], [train main loss -9.277196], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 12 / 744], [train main loss -8.429260], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 13 / 744], [train main loss -8.423824], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 14 / 744], [train main loss -8.237416], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 15 / 744], [train main loss -8.278944], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 16 / 744], [train main loss -8.806821], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 17 / 744], [train main loss -8.838852], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 18 / 744], [train main loss -8.982586], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 19 / 744], [train main loss -8.975009], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 20 / 744], [train main loss -8.711748], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 21 / 744], [train main loss -8.899518], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 22 / 744], [train main loss -8.989783], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 23 / 744], [train main loss -8.953695], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 24 / 744], [train main loss -8.919565], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 25 / 744], [train main loss -8.960479], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 26 / 744], [train main loss -9.056437], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 27 / 744], [train main loss -9.334363], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 28 / 744], [train main loss -9.368022], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 29 / 744], [train main loss -9.341444], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 30 / 744], [train main loss -9.115572], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 31 / 744], [train main loss -9.048183], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 32 / 744], [train main loss -8.954682], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 33 / 744], [train main loss -8.955589], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 34 / 744], [train main loss -8.885774], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 35 / 744], [train main loss -8.976632], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 36 / 744], [train main loss -9.072451], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 37 / 744], [train main loss -9.237774], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 38 / 744], [train main loss -9.199261], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 39 / 744], [train main loss -9.105298], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 40 / 744], [train main loss -9.021569], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 41 / 744], [train main loss -9.068826], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 42 / 744], [train main loss -9.106610], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 43 / 744], [train main loss -9.038156], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 44 / 744], [train main loss -9.073043], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 45 / 744], [train main loss -9.106898], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 46 / 744], [train main loss -8.968962], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 47 / 744], [train main loss -8.904956], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 48 / 744], [train main loss -8.830125], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 49 / 744], [train main loss -8.842319], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 50 / 744], [train main loss -8.878451], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 51 / 744], [train main loss -8.795458], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 52 / 744], [train main loss -8.776062], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 53 / 744], [train main loss -8.753684], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 54 / 744], [train main loss -8.739740], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 55 / 744], [train main loss -8.698483], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 56 / 744], [train main loss -8.689344], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 57 / 744], [train main loss -8.791503], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 58 / 744], [train main loss -8.837363], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 59 / 744], [train main loss -8.765795], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 60 / 744], [train main loss -8.805893], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 61 / 744], [train main loss -8.726136], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 62 / 744], [train main loss -8.679559], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 63 / 744], [train main loss -8.705655], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 64 / 744], [train main loss -8.717858], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 65 / 744], [train main loss -8.719676], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 66 / 744], [train main loss -8.701115], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 67 / 744], [train main loss -8.814439], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 68 / 744], [train main loss -8.837428], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 69 / 744], [train main loss -8.914414], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 70 / 744], [train main loss -8.968348], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 71 / 744], [train main loss -8.847189], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 72 / 744], [train main loss -8.845855], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 73 / 744], [train main loss -8.830840], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 74 / 744], [train main loss -8.827675], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 75 / 744], [train main loss -8.894388], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 76 / 744], [train main loss -8.931008], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 77 / 744], [train main loss -8.904343], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 78 / 744], [train main loss -8.996604], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 79 / 744], [train main loss -9.048840], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 80 / 744], [train main loss -9.035172], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 81 / 744], [train main loss -9.012694], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 82 / 744], [train main loss -9.075517], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 83 / 744], [train main loss -9.092859], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 84 / 744], [train main loss -9.077973], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 85 / 744], [train main loss -9.049688], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 86 / 744], [train main loss -9.114273], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 87 / 744], [train main loss -9.092371], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 88 / 744], [train main loss -9.078838], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 89 / 744], [train main loss -9.057888], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 90 / 744], [train main loss -9.061311], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 91 / 744], [train main loss -9.044219], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 92 / 744], [train main loss -9.042874], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 93 / 744], [train main loss -9.062242], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 94 / 744], [train main loss -9.033581], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 95 / 744], [train main loss -9.044877], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 96 / 744], [train main loss -9.037808], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 97 / 744], [train main loss -8.944843], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 98 / 744], [train main loss -8.956704], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 99 / 744], [train main loss -8.988107], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 100 / 744], [train main loss -8.984051], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 101 / 744], [train main loss -8.953844], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 102 / 744], [train main loss -8.992785], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 103 / 744], [train main loss -8.976631], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 104 / 744], [train main loss -8.949799], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 105 / 744], [train main loss -8.918503], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 106 / 744], [train main loss -8.867212], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 107 / 744], [train main loss -8.834130], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 108 / 744], [train main loss -8.869155], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 109 / 744], [train main loss -8.861065], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 110 / 744], [train main loss -8.850945], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 111 / 744], [train main loss -8.825177], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 112 / 744], [train main loss -8.782145], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 113 / 744], [train main loss -8.793289], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 114 / 744], [train main loss -8.774289], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 115 / 744], [train main loss -8.795269], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 116 / 744], [train main loss -8.820082], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 117 / 744], [train main loss -8.798015], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 118 / 744], [train main loss -8.810172], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 119 / 744], [train main loss -8.763504], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 120 / 744], [train main loss -8.758467], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 121 / 744], [train main loss -8.797454], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 122 / 744], [train main loss -8.781299], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 123 / 744], [train main loss -8.783845], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 124 / 744], [train main loss -8.756025], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 125 / 744], [train main loss -8.720288], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 126 / 744], [train main loss -8.735466], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 127 / 744], [train main loss -8.732006], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 128 / 744], [train main loss -8.731889], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 129 / 744], [train main loss -8.701407], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 130 / 744], [train main loss -8.701615], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 131 / 744], [train main loss -8.684727], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 132 / 744], [train main loss -8.745156], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 133 / 744], [train main loss -8.751589], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 134 / 744], [train main loss -8.748779], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 135 / 744], [train main loss -8.730454], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 136 / 744], [train main loss -8.731974], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 137 / 744], [train main loss -8.702350], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 138 / 744], [train main loss -8.663152], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 139 / 744], [train main loss -8.635322], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 140 / 744], [train main loss -8.633942], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 141 / 744], [train main loss -8.622556], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 142 / 744], [train main loss -8.656810], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 143 / 744], [train main loss -8.697578], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 144 / 744], [train main loss -8.748448], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 145 / 744], [train main loss -8.744926], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 146 / 744], [train main loss -8.753839], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 147 / 744], [train main loss -8.728300], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 148 / 744], [train main loss -8.748371], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 149 / 744], [train main loss -8.730893], [lr 0.004608] [batchtime 1.15]
[epoch 7], [iter 150 / 744], [train main loss -8.739962], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 151 / 744], [train main loss -8.744275], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 152 / 744], [train main loss -8.739781], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 153 / 744], [train main loss -8.752997], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 154 / 744], [train main loss -8.717484], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 155 / 744], [train main loss -8.726806], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 156 / 744], [train main loss -8.741368], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 157 / 744], [train main loss -8.739937], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 158 / 744], [train main loss -8.738825], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 159 / 744], [train main loss -8.741018], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 160 / 744], [train main loss -8.713966], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 161 / 744], [train main loss -8.697711], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 162 / 744], [train main loss -8.709238], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 163 / 744], [train main loss -8.727520], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 164 / 744], [train main loss -8.744107], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 165 / 744], [train main loss -8.732832], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 166 / 744], [train main loss -8.718301], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 167 / 744], [train main loss -8.690426], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 168 / 744], [train main loss -8.717019], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 169 / 744], [train main loss -8.705620], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 170 / 744], [train main loss -8.699650], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 171 / 744], [train main loss -8.715790], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 172 / 744], [train main loss -8.731606], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 173 / 744], [train main loss -8.703245], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 174 / 744], [train main loss -8.686414], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 175 / 744], [train main loss -8.684237], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 176 / 744], [train main loss -8.682659], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 177 / 744], [train main loss -8.667507], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 178 / 744], [train main loss -8.667611], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 179 / 744], [train main loss -8.691965], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 180 / 744], [train main loss -8.694601], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 181 / 744], [train main loss -8.703194], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 182 / 744], [train main loss -8.685103], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 183 / 744], [train main loss -8.710876], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 184 / 744], [train main loss -8.753652], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 185 / 744], [train main loss -8.727355], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 186 / 744], [train main loss -8.754684], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 187 / 744], [train main loss -8.737618], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 188 / 744], [train main loss -8.723258], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 189 / 744], [train main loss -8.732942], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 190 / 744], [train main loss -8.706183], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 191 / 744], [train main loss -8.707277], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 192 / 744], [train main loss -8.704589], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 193 / 744], [train main loss -8.726275], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 194 / 744], [train main loss -8.721731], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 195 / 744], [train main loss -8.727266], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 196 / 744], [train main loss -8.755089], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 197 / 744], [train main loss -8.774613], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 198 / 744], [train main loss -8.796077], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 199 / 744], [train main loss -8.787187], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 200 / 744], [train main loss -8.789103], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 201 / 744], [train main loss -8.787938], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 202 / 744], [train main loss -8.793216], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 203 / 744], [train main loss -8.792864], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 204 / 744], [train main loss -8.771953], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 205 / 744], [train main loss -8.796982], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 206 / 744], [train main loss -8.834935], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 207 / 744], [train main loss -8.821478], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 208 / 744], [train main loss -8.816699], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 209 / 744], [train main loss -8.795210], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 210 / 744], [train main loss -8.781361], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 211 / 744], [train main loss -8.807577], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 212 / 744], [train main loss -8.795221], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 213 / 744], [train main loss -8.768880], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 214 / 744], [train main loss -8.781114], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 215 / 744], [train main loss -8.781551], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 216 / 744], [train main loss -8.787564], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 217 / 744], [train main loss -8.790861], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 218 / 744], [train main loss -8.811069], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 219 / 744], [train main loss -8.806961], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 220 / 744], [train main loss -8.809773], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 221 / 744], [train main loss -8.807668], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 222 / 744], [train main loss -8.789719], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 223 / 744], [train main loss -8.787326], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 224 / 744], [train main loss -8.765645], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 225 / 744], [train main loss -8.751185], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 226 / 744], [train main loss -8.737287], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 227 / 744], [train main loss -8.721525], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 228 / 744], [train main loss -8.745297], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 229 / 744], [train main loss -8.727629], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 230 / 744], [train main loss -8.726934], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 231 / 744], [train main loss -8.738934], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 232 / 744], [train main loss -8.753785], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 233 / 744], [train main loss -8.727353], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 234 / 744], [train main loss -8.731903], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 235 / 744], [train main loss -8.725753], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 236 / 744], [train main loss -8.734447], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 237 / 744], [train main loss -8.716521], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 238 / 744], [train main loss -8.728283], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 239 / 744], [train main loss -8.722730], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 240 / 744], [train main loss -8.737019], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 241 / 744], [train main loss -8.726294], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 242 / 744], [train main loss -8.728761], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 243 / 744], [train main loss -8.723797], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 244 / 744], [train main loss -8.719402], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 245 / 744], [train main loss -8.741563], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 246 / 744], [train main loss -8.742505], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 247 / 744], [train main loss -8.745396], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 248 / 744], [train main loss -8.742212], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 249 / 744], [train main loss -8.756747], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 250 / 744], [train main loss -8.757562], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 251 / 744], [train main loss -8.749433], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 252 / 744], [train main loss -8.775880], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 253 / 744], [train main loss -8.775457], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 254 / 744], [train main loss -8.768758], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 255 / 744], [train main loss -8.772646], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 256 / 744], [train main loss -8.773111], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 257 / 744], [train main loss -8.762503], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 258 / 744], [train main loss -8.768451], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 259 / 744], [train main loss -8.792659], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 260 / 744], [train main loss -8.785025], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 261 / 744], [train main loss -8.782880], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 262 / 744], [train main loss -8.801685], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 263 / 744], [train main loss -8.786411], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 264 / 744], [train main loss -8.798348], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 265 / 744], [train main loss -8.813393], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 266 / 744], [train main loss -8.821169], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 267 / 744], [train main loss -8.829432], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 268 / 744], [train main loss -8.827251], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 269 / 744], [train main loss -8.825545], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 270 / 744], [train main loss -8.805878], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 271 / 744], [train main loss -8.789567], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 272 / 744], [train main loss -8.774495], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 273 / 744], [train main loss -8.779150], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 274 / 744], [train main loss -8.796593], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 275 / 744], [train main loss -8.821528], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 276 / 744], [train main loss -8.828315], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 277 / 744], [train main loss -8.814767], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 278 / 744], [train main loss -8.784348], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 279 / 744], [train main loss -8.793597], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 280 / 744], [train main loss -8.792330], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 281 / 744], [train main loss -8.787463], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 282 / 744], [train main loss -8.811844], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 283 / 744], [train main loss -8.811470], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 284 / 744], [train main loss -8.813091], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 285 / 744], [train main loss -8.822123], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 286 / 744], [train main loss -8.820697], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 287 / 744], [train main loss -8.792983], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 288 / 744], [train main loss -8.796811], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 289 / 744], [train main loss -8.789114], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 290 / 744], [train main loss -8.794011], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 291 / 744], [train main loss -8.802803], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 292 / 744], [train main loss -8.798345], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 293 / 744], [train main loss -8.812381], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 294 / 744], [train main loss -8.806702], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 295 / 744], [train main loss -8.809323], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 296 / 744], [train main loss -8.797397], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 297 / 744], [train main loss -8.815602], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 298 / 744], [train main loss -8.812900], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 299 / 744], [train main loss -8.809975], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 300 / 744], [train main loss -8.795456], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 301 / 744], [train main loss -8.816648], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 302 / 744], [train main loss -8.817466], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 303 / 744], [train main loss -8.814133], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 304 / 744], [train main loss -8.816142], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 305 / 744], [train main loss -8.812843], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 306 / 744], [train main loss -8.801953], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 307 / 744], [train main loss -8.796629], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 308 / 744], [train main loss -8.798754], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 309 / 744], [train main loss -8.817435], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 310 / 744], [train main loss -8.829952], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 311 / 744], [train main loss -8.823961], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 312 / 744], [train main loss -8.840468], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 313 / 744], [train main loss -8.834249], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 314 / 744], [train main loss -8.836953], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 315 / 744], [train main loss -8.844852], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 316 / 744], [train main loss -8.855878], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 317 / 744], [train main loss -8.858617], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 318 / 744], [train main loss -8.859441], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 319 / 744], [train main loss -8.866995], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 320 / 744], [train main loss -8.890442], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 321 / 744], [train main loss -8.895797], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 322 / 744], [train main loss -8.894269], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 323 / 744], [train main loss -8.886253], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 324 / 744], [train main loss -8.880047], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 325 / 744], [train main loss -8.885998], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 326 / 744], [train main loss -8.889044], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 327 / 744], [train main loss -8.881140], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 328 / 744], [train main loss -8.870067], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 329 / 744], [train main loss -8.865434], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 330 / 744], [train main loss -8.863079], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 331 / 744], [train main loss -8.851861], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 332 / 744], [train main loss -8.849167], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 333 / 744], [train main loss -8.855974], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 334 / 744], [train main loss -8.858711], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 335 / 744], [train main loss -8.860201], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 336 / 744], [train main loss -8.869260], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 337 / 744], [train main loss -8.869451], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 338 / 744], [train main loss -8.868431], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 339 / 744], [train main loss -8.877068], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 340 / 744], [train main loss -8.865890], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 341 / 744], [train main loss -8.861095], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 342 / 744], [train main loss -8.863839], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 343 / 744], [train main loss -8.862319], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 344 / 744], [train main loss -8.848687], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 345 / 744], [train main loss -8.840440], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 346 / 744], [train main loss -8.841494], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 347 / 744], [train main loss -8.832226], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 348 / 744], [train main loss -8.824737], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 349 / 744], [train main loss -8.825856], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 350 / 744], [train main loss -8.845709], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 351 / 744], [train main loss -8.858474], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 352 / 744], [train main loss -8.857421], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 353 / 744], [train main loss -8.849699], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 354 / 744], [train main loss -8.847417], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 355 / 744], [train main loss -8.876641], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 356 / 744], [train main loss -8.859351], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 357 / 744], [train main loss -8.855208], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 358 / 744], [train main loss -8.855781], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 359 / 744], [train main loss -8.860544], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 360 / 744], [train main loss -8.863864], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 361 / 744], [train main loss -8.863201], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 362 / 744], [train main loss -8.873571], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 363 / 744], [train main loss -8.882464], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 364 / 744], [train main loss -8.875890], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 365 / 744], [train main loss -8.891419], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 366 / 744], [train main loss -8.881564], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 367 / 744], [train main loss -8.878667], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 368 / 744], [train main loss -8.874219], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 369 / 744], [train main loss -8.868577], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 370 / 744], [train main loss -8.863008], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 371 / 744], [train main loss -8.863629], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 372 / 744], [train main loss -8.864441], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 373 / 744], [train main loss -8.866026], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 374 / 744], [train main loss -8.855862], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 375 / 744], [train main loss -8.853413], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 376 / 744], [train main loss -8.853474], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 377 / 744], [train main loss -8.867031], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 378 / 744], [train main loss -8.857742], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 379 / 744], [train main loss -8.853644], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 380 / 744], [train main loss -8.855989], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 381 / 744], [train main loss -8.846785], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 382 / 744], [train main loss -8.848864], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 383 / 744], [train main loss -8.854738], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 384 / 744], [train main loss -8.847559], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 385 / 744], [train main loss -8.832135], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 386 / 744], [train main loss -8.824977], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 387 / 744], [train main loss -8.823254], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 388 / 744], [train main loss -8.825369], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 389 / 744], [train main loss -8.826167], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 390 / 744], [train main loss -8.835302], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 391 / 744], [train main loss -8.832599], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 392 / 744], [train main loss -8.833117], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 393 / 744], [train main loss -8.825331], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 394 / 744], [train main loss -8.813263], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 395 / 744], [train main loss -8.813428], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 396 / 744], [train main loss -8.802485], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 397 / 744], [train main loss -8.784769], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 398 / 744], [train main loss -8.779504], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 399 / 744], [train main loss -8.800911], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 400 / 744], [train main loss -8.797389], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 401 / 744], [train main loss -8.792557], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 402 / 744], [train main loss -8.795188], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 403 / 744], [train main loss -8.803522], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 404 / 744], [train main loss -8.801623], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 405 / 744], [train main loss -8.807085], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 406 / 744], [train main loss -8.804587], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 407 / 744], [train main loss -8.797578], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 408 / 744], [train main loss -8.805781], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 409 / 744], [train main loss -8.798968], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 410 / 744], [train main loss -8.803441], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 411 / 744], [train main loss -8.804894], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 412 / 744], [train main loss -8.813090], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 413 / 744], [train main loss -8.795207], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 414 / 744], [train main loss -8.809692], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 415 / 744], [train main loss -8.792277], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 416 / 744], [train main loss -8.813766], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 417 / 744], [train main loss -8.818156], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 418 / 744], [train main loss -8.822511], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 419 / 744], [train main loss -8.831323], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 420 / 744], [train main loss -8.830722], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 421 / 744], [train main loss -8.827521], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 422 / 744], [train main loss -8.827381], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 423 / 744], [train main loss -8.840520], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 424 / 744], [train main loss -8.838401], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 425 / 744], [train main loss -8.835844], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 426 / 744], [train main loss -8.840525], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 427 / 744], [train main loss -8.837476], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 428 / 744], [train main loss -8.840962], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 429 / 744], [train main loss -8.834378], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 430 / 744], [train main loss -8.828522], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 431 / 744], [train main loss -8.821520], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 432 / 744], [train main loss -8.822155], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 433 / 744], [train main loss -8.832831], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 434 / 744], [train main loss -8.822383], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 435 / 744], [train main loss -8.829833], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 436 / 744], [train main loss -8.822653], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 437 / 744], [train main loss -8.829996], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 438 / 744], [train main loss -8.838297], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 439 / 744], [train main loss -8.845795], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 440 / 744], [train main loss -8.840852], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 441 / 744], [train main loss -8.854462], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 442 / 744], [train main loss -8.845786], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 443 / 744], [train main loss -8.841783], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 444 / 744], [train main loss -8.845926], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 445 / 744], [train main loss -8.842497], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 446 / 744], [train main loss -8.849177], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 447 / 744], [train main loss -8.840241], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 448 / 744], [train main loss -8.845718], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 449 / 744], [train main loss -8.834797], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 450 / 744], [train main loss -8.839577], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 451 / 744], [train main loss -8.838952], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 452 / 744], [train main loss -8.854423], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 453 / 744], [train main loss -8.854487], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 454 / 744], [train main loss -8.849235], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 455 / 744], [train main loss -8.847676], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 456 / 744], [train main loss -8.845581], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 457 / 744], [train main loss -8.849151], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 458 / 744], [train main loss -8.847058], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 459 / 744], [train main loss -8.842838], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 460 / 744], [train main loss -8.839680], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 461 / 744], [train main loss -8.836580], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 462 / 744], [train main loss -8.830756], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 463 / 744], [train main loss -8.829287], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 464 / 744], [train main loss -8.823628], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 465 / 744], [train main loss -8.824298], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 466 / 744], [train main loss -8.827382], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 467 / 744], [train main loss -8.840263], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 468 / 744], [train main loss -8.849848], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 469 / 744], [train main loss -8.841720], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 470 / 744], [train main loss -8.841457], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 471 / 744], [train main loss -8.845164], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 472 / 744], [train main loss -8.840216], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 473 / 744], [train main loss -8.843054], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 474 / 744], [train main loss -8.837612], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 475 / 744], [train main loss -8.843797], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 476 / 744], [train main loss -8.843113], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 477 / 744], [train main loss -8.837800], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 478 / 744], [train main loss -8.835895], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 479 / 744], [train main loss -8.838304], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 480 / 744], [train main loss -8.823849], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 481 / 744], [train main loss -8.817980], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 482 / 744], [train main loss -8.821651], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 483 / 744], [train main loss -8.817146], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 484 / 744], [train main loss -8.834607], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 485 / 744], [train main loss -8.834877], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 486 / 744], [train main loss -8.835904], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 487 / 744], [train main loss -8.831612], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 488 / 744], [train main loss -8.823208], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 489 / 744], [train main loss -8.815577], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 490 / 744], [train main loss -8.805996], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 491 / 744], [train main loss -8.787628], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 492 / 744], [train main loss -8.780599], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 493 / 744], [train main loss -8.784206], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 494 / 744], [train main loss -8.777412], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 495 / 744], [train main loss -8.762319], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 496 / 744], [train main loss -8.762423], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 497 / 744], [train main loss -8.754079], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 498 / 744], [train main loss -8.754178], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 499 / 744], [train main loss -8.753338], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 500 / 744], [train main loss -8.747637], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 501 / 744], [train main loss -8.743375], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 502 / 744], [train main loss -8.733770], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 503 / 744], [train main loss -8.734803], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 504 / 744], [train main loss -8.725201], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 505 / 744], [train main loss -8.727148], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 506 / 744], [train main loss -8.729436], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 507 / 744], [train main loss -8.736905], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 508 / 744], [train main loss -8.750159], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 509 / 744], [train main loss -8.750680], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 510 / 744], [train main loss -8.751023], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 511 / 744], [train main loss -8.750515], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 512 / 744], [train main loss -8.749278], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 513 / 744], [train main loss -8.753796], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 514 / 744], [train main loss -8.746463], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 515 / 744], [train main loss -8.737889], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 516 / 744], [train main loss -8.739157], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 517 / 744], [train main loss -8.738120], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 518 / 744], [train main loss -8.745825], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 519 / 744], [train main loss -8.750394], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 520 / 744], [train main loss -8.744301], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 521 / 744], [train main loss -8.751556], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 522 / 744], [train main loss -8.739415], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 523 / 744], [train main loss -8.742530], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 524 / 744], [train main loss -8.751251], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 525 / 744], [train main loss -8.754411], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 526 / 744], [train main loss -8.746118], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 527 / 744], [train main loss -8.740695], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 528 / 744], [train main loss -8.739282], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 529 / 744], [train main loss -8.740615], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 530 / 744], [train main loss -8.745820], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 531 / 744], [train main loss -8.746428], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 532 / 744], [train main loss -8.738647], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 533 / 744], [train main loss -8.737999], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 534 / 744], [train main loss -8.751573], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 535 / 744], [train main loss -8.750398], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 536 / 744], [train main loss -8.755756], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 537 / 744], [train main loss -8.757145], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 538 / 744], [train main loss -8.756230], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 539 / 744], [train main loss -8.753453], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 540 / 744], [train main loss -8.761072], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 541 / 744], [train main loss -8.759138], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 542 / 744], [train main loss -8.753731], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 543 / 744], [train main loss -8.748615], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 544 / 744], [train main loss -8.744640], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 545 / 744], [train main loss -8.747746], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 546 / 744], [train main loss -8.744131], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 547 / 744], [train main loss -8.757488], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 548 / 744], [train main loss -8.752395], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 549 / 744], [train main loss -8.747837], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 550 / 744], [train main loss -8.749236], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 551 / 744], [train main loss -8.742328], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 552 / 744], [train main loss -8.743201], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 553 / 744], [train main loss -8.743447], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 554 / 744], [train main loss -8.741129], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 555 / 744], [train main loss -8.732596], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 556 / 744], [train main loss -8.732616], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 557 / 744], [train main loss -8.740558], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 558 / 744], [train main loss -8.730824], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 559 / 744], [train main loss -8.721268], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 560 / 744], [train main loss -8.726386], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 561 / 744], [train main loss -8.731053], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 562 / 744], [train main loss -8.731234], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 563 / 744], [train main loss -8.731228], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 564 / 744], [train main loss -8.728977], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 565 / 744], [train main loss -8.729164], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 566 / 744], [train main loss -8.729037], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 567 / 744], [train main loss -8.723877], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 568 / 744], [train main loss -8.730694], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 569 / 744], [train main loss -8.727254], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 570 / 744], [train main loss -8.733593], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 571 / 744], [train main loss -8.737730], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 572 / 744], [train main loss -8.740588], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 573 / 744], [train main loss -8.740517], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 574 / 744], [train main loss -8.741914], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 575 / 744], [train main loss -8.734622], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 576 / 744], [train main loss -8.733987], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 577 / 744], [train main loss -8.734747], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 578 / 744], [train main loss -8.739059], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 579 / 744], [train main loss -8.744520], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 580 / 744], [train main loss -8.745266], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 581 / 744], [train main loss -8.735464], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 582 / 744], [train main loss -8.734538], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 583 / 744], [train main loss -8.734309], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 584 / 744], [train main loss -8.730663], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 585 / 744], [train main loss -8.729218], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 586 / 744], [train main loss -8.730972], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 587 / 744], [train main loss -8.725549], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 588 / 744], [train main loss -8.732063], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 589 / 744], [train main loss -8.727660], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 590 / 744], [train main loss -8.726022], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 591 / 744], [train main loss -8.718885], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 592 / 744], [train main loss -8.720859], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 593 / 744], [train main loss -8.717414], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 594 / 744], [train main loss -8.727228], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 595 / 744], [train main loss -8.727824], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 596 / 744], [train main loss -8.731979], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 597 / 744], [train main loss -8.735249], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 598 / 744], [train main loss -8.734924], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 599 / 744], [train main loss -8.732530], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 600 / 744], [train main loss -8.741800], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 601 / 744], [train main loss -8.744120], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 602 / 744], [train main loss -8.742205], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 603 / 744], [train main loss -8.745564], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 604 / 744], [train main loss -8.747478], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 605 / 744], [train main loss -8.754845], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 606 / 744], [train main loss -8.759835], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 607 / 744], [train main loss -8.760883], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 608 / 744], [train main loss -8.764251], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 609 / 744], [train main loss -8.762395], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 610 / 744], [train main loss -8.758497], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 611 / 744], [train main loss -8.763154], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 612 / 744], [train main loss -8.758711], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 613 / 744], [train main loss -8.756737], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 614 / 744], [train main loss -8.765862], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 615 / 744], [train main loss -8.762221], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 616 / 744], [train main loss -8.751551], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 617 / 744], [train main loss -8.747394], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 618 / 744], [train main loss -8.744970], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 619 / 744], [train main loss -8.742187], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 620 / 744], [train main loss -8.743417], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 621 / 744], [train main loss -8.737532], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 622 / 744], [train main loss -8.748627], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 623 / 744], [train main loss -8.754372], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 624 / 744], [train main loss -8.750872], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 625 / 744], [train main loss -8.748932], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 626 / 744], [train main loss -8.749604], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 627 / 744], [train main loss -8.746576], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 628 / 744], [train main loss -8.740444], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 629 / 744], [train main loss -8.731831], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 630 / 744], [train main loss -8.742996], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 631 / 744], [train main loss -8.739335], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 632 / 744], [train main loss -8.737352], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 633 / 744], [train main loss -8.734425], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 634 / 744], [train main loss -8.740548], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 635 / 744], [train main loss -8.746951], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 636 / 744], [train main loss -8.746058], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 637 / 744], [train main loss -8.744275], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 638 / 744], [train main loss -8.737367], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 639 / 744], [train main loss -8.738220], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 640 / 744], [train main loss -8.730964], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 641 / 744], [train main loss -8.725760], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 642 / 744], [train main loss -8.735663], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 643 / 744], [train main loss -8.729942], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 644 / 744], [train main loss -8.726756], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 645 / 744], [train main loss -8.728042], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 646 / 744], [train main loss -8.729811], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 647 / 744], [train main loss -8.726994], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 648 / 744], [train main loss -8.725959], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 649 / 744], [train main loss -8.734713], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 650 / 744], [train main loss -8.729260], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 651 / 744], [train main loss -8.728524], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 652 / 744], [train main loss -8.726380], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 653 / 744], [train main loss -8.723550], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 654 / 744], [train main loss -8.728506], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 655 / 744], [train main loss -8.730386], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 656 / 744], [train main loss -8.739014], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 657 / 744], [train main loss -8.736712], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 658 / 744], [train main loss -8.734696], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 659 / 744], [train main loss -8.729953], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 660 / 744], [train main loss -8.728340], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 661 / 744], [train main loss -8.735688], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 662 / 744], [train main loss -8.737394], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 663 / 744], [train main loss -8.733148], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 664 / 744], [train main loss -8.731659], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 665 / 744], [train main loss -8.730921], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 666 / 744], [train main loss -8.728422], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 667 / 744], [train main loss -8.726882], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 668 / 744], [train main loss -8.730293], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 669 / 744], [train main loss -8.736664], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 670 / 744], [train main loss -8.741400], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 671 / 744], [train main loss -8.743648], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 672 / 744], [train main loss -8.743646], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 673 / 744], [train main loss -8.746114], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 674 / 744], [train main loss -8.746651], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 675 / 744], [train main loss -8.753771], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 676 / 744], [train main loss -8.758558], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 677 / 744], [train main loss -8.763477], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 678 / 744], [train main loss -8.761564], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 679 / 744], [train main loss -8.765101], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 680 / 744], [train main loss -8.763476], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 681 / 744], [train main loss -8.774952], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 682 / 744], [train main loss -8.778204], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 683 / 744], [train main loss -8.777094], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 684 / 744], [train main loss -8.772367], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 685 / 744], [train main loss -8.766034], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 686 / 744], [train main loss -8.761455], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 687 / 744], [train main loss -8.756369], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 688 / 744], [train main loss -8.758902], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 689 / 744], [train main loss -8.753874], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 690 / 744], [train main loss -8.743360], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 691 / 744], [train main loss -8.747513], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 692 / 744], [train main loss -8.748389], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 693 / 744], [train main loss -8.751616], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 694 / 744], [train main loss -8.752877], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 695 / 744], [train main loss -8.760440], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 696 / 744], [train main loss -8.750522], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 697 / 744], [train main loss -8.745517], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 698 / 744], [train main loss -8.746305], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 699 / 744], [train main loss -8.748433], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 700 / 744], [train main loss -8.754763], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 701 / 744], [train main loss -8.761008], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 702 / 744], [train main loss -8.767491], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 703 / 744], [train main loss -8.763835], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 704 / 744], [train main loss -8.763970], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 705 / 744], [train main loss -8.756637], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 706 / 744], [train main loss -8.761176], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 707 / 744], [train main loss -8.771411], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 708 / 744], [train main loss -8.776481], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 709 / 744], [train main loss -8.778611], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 710 / 744], [train main loss -8.775437], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 711 / 744], [train main loss -8.774665], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 712 / 744], [train main loss -8.780814], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 713 / 744], [train main loss -8.779632], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 714 / 744], [train main loss -8.787825], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 715 / 744], [train main loss -8.793346], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 716 / 744], [train main loss -8.796997], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 717 / 744], [train main loss -8.794457], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 718 / 744], [train main loss -8.788940], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 719 / 744], [train main loss -8.789941], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 720 / 744], [train main loss -8.788107], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 721 / 744], [train main loss -8.793962], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 722 / 744], [train main loss -8.795446], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 723 / 744], [train main loss -8.789863], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 724 / 744], [train main loss -8.788984], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 725 / 744], [train main loss -8.790948], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 726 / 744], [train main loss -8.788765], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 727 / 744], [train main loss -8.795205], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 728 / 744], [train main loss -8.787100], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 729 / 744], [train main loss -8.783132], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 730 / 744], [train main loss -8.784933], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 731 / 744], [train main loss -8.788447], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 732 / 744], [train main loss -8.787185], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 733 / 744], [train main loss -8.777739], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 734 / 744], [train main loss -8.771602], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 735 / 744], [train main loss -8.762492], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 736 / 744], [train main loss -8.763173], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 737 / 744], [train main loss -8.770601], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 738 / 744], [train main loss -8.770353], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 739 / 744], [train main loss -8.764057], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 740 / 744], [train main loss -8.761222], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 741 / 744], [train main loss -8.765060], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 742 / 744], [train main loss -8.763892], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 743 / 744], [train main loss -8.765215], [lr 0.004608] [batchtime 1.14]
[epoch 7], [iter 744 / 744], [train main loss -8.762406], [lr 0.004608] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              98.38  37.26  0.01  0.01         0.99      0.99
   1  sidewalk          86.88   5.11  0.06  0.09         0.94      0.92
   2  building          92.98  21.21  0.03  0.04         0.97      0.96
   3  wall              59.39   0.56  0.31  0.38         0.76      0.73
   4  fence             59.17   0.54  0.52  0.17         0.66      0.86
   5  pole              71.68   1.22  0.21  0.18         0.82      0.85
   6  traffic light     77.44   0.17  0.15  0.14         0.87      0.88
   7  traffic sign      83.32   0.59  0.13  0.07         0.89      0.93
   8  vegetation        92.46  16.48  0.05  0.03         0.95      0.97
   9  terrain           61.26   0.71  0.17  0.47         0.86      0.68
  10  sky               94.77   3.31  0.01  0.04         0.99      0.96
  11  person            85.02   1.20  0.09  0.09         0.92      0.92
  12  rider             66.22   0.16  0.36  0.15         0.74      0.87
  13  car               95.86   6.38  0.02  0.02         0.98      0.98
  14  truck             79.89   0.26  0.14  0.11         0.88      0.90
  15  bus               80.87   0.37  0.04  0.20         0.96      0.83
  16  train             59.66   0.07  0.63  0.05         0.61      0.96
  17  motorcycle        58.62   0.07  0.12  0.59         0.90      0.63
  18  bicycle           79.48   0.65  0.09  0.17         0.92      0.85
Mean: 78.07
-----------------------------------------------------------------------------------------------------------
this : [epoch 7], [val loss 0.14374], [acc 0.96322], [acc_cls 0.87391], [mean_iu 0.78071], [fwavacc 0.93235]
best : [epoch 7], [val loss 0.14374], [acc 0.96322], [acc_cls 0.87391], [mean_iu 0.78071], [fwavacc 0.93235]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 8], [iter 1 / 744], [train main loss -6.250076], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 2 / 744], [train main loss -6.437961], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 3 / 744], [train main loss -4.745243], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 4 / 744], [train main loss -4.756481], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 5 / 744], [train main loss -5.777864], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 6 / 744], [train main loss -6.121045], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 7 / 744], [train main loss -6.084444], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 8 / 744], [train main loss -6.040705], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 9 / 744], [train main loss -6.131006], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 10 / 744], [train main loss -5.901070], [lr 0.004553] [batchtime 0]
[epoch 8], [iter 11 / 744], [train main loss -6.052228], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 12 / 744], [train main loss -6.226921], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 13 / 744], [train main loss -6.289633], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 14 / 744], [train main loss -6.577604], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 15 / 744], [train main loss -6.682364], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 16 / 744], [train main loss -6.832973], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 17 / 744], [train main loss -7.188811], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 18 / 744], [train main loss -7.427387], [lr 0.004553] [batchtime 1.13]
[epoch 8], [iter 19 / 744], [train main loss -7.524904], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 20 / 744], [train main loss -7.629518], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 21 / 744], [train main loss -7.630970], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 22 / 744], [train main loss -7.623300], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 23 / 744], [train main loss -7.561379], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 24 / 744], [train main loss -7.540956], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 25 / 744], [train main loss -7.569589], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 26 / 744], [train main loss -7.621677], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 27 / 744], [train main loss -7.741322], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 28 / 744], [train main loss -7.820026], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 29 / 744], [train main loss -7.722148], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 30 / 744], [train main loss -7.801116], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 31 / 744], [train main loss -7.886518], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 32 / 744], [train main loss -8.069795], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 33 / 744], [train main loss -8.030334], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 34 / 744], [train main loss -8.185350], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 35 / 744], [train main loss -8.221707], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 36 / 744], [train main loss -8.256828], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 37 / 744], [train main loss -8.164211], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 38 / 744], [train main loss -8.158053], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 39 / 744], [train main loss -8.090250], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 40 / 744], [train main loss -7.994751], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 41 / 744], [train main loss -7.934155], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 42 / 744], [train main loss -7.821435], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 43 / 744], [train main loss -7.862492], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 44 / 744], [train main loss -7.836832], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 45 / 744], [train main loss -7.821272], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 46 / 744], [train main loss -7.874787], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 47 / 744], [train main loss -7.884782], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 48 / 744], [train main loss -7.944686], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 49 / 744], [train main loss -8.084158], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 50 / 744], [train main loss -8.074294], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 51 / 744], [train main loss -8.044530], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 52 / 744], [train main loss -8.158964], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 53 / 744], [train main loss -8.142878], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 54 / 744], [train main loss -8.044235], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 55 / 744], [train main loss -8.096897], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 56 / 744], [train main loss -8.082068], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 57 / 744], [train main loss -8.087975], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 58 / 744], [train main loss -8.059006], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 59 / 744], [train main loss -8.082828], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 60 / 744], [train main loss -8.197792], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 61 / 744], [train main loss -8.221250], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 62 / 744], [train main loss -8.331853], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 63 / 744], [train main loss -8.328245], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 64 / 744], [train main loss -8.321439], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 65 / 744], [train main loss -8.365656], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 66 / 744], [train main loss -8.366715], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 67 / 744], [train main loss -8.335659], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 68 / 744], [train main loss -8.273546], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 69 / 744], [train main loss -8.313223], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 70 / 744], [train main loss -8.308184], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 71 / 744], [train main loss -8.404050], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 72 / 744], [train main loss -8.401639], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 73 / 744], [train main loss -8.371634], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 74 / 744], [train main loss -8.504024], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 75 / 744], [train main loss -8.522792], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 76 / 744], [train main loss -8.629135], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 77 / 744], [train main loss -8.581807], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 78 / 744], [train main loss -8.561569], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 79 / 744], [train main loss -8.541654], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 80 / 744], [train main loss -8.538314], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 81 / 744], [train main loss -8.483082], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 82 / 744], [train main loss -8.537369], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 83 / 744], [train main loss -8.549571], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 84 / 744], [train main loss -8.565436], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 85 / 744], [train main loss -8.611357], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 86 / 744], [train main loss -8.649803], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 87 / 744], [train main loss -8.652834], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 88 / 744], [train main loss -8.677355], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 89 / 744], [train main loss -8.659087], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 90 / 744], [train main loss -8.642580], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 91 / 744], [train main loss -8.602671], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 92 / 744], [train main loss -8.629430], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 93 / 744], [train main loss -8.600218], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 94 / 744], [train main loss -8.547339], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 95 / 744], [train main loss -8.564959], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 96 / 744], [train main loss -8.579583], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 97 / 744], [train main loss -8.577504], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 98 / 744], [train main loss -8.599825], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 99 / 744], [train main loss -8.552124], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 100 / 744], [train main loss -8.573803], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 101 / 744], [train main loss -8.540228], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 102 / 744], [train main loss -8.565491], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 103 / 744], [train main loss -8.576827], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 104 / 744], [train main loss -8.541142], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 105 / 744], [train main loss -8.555811], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 106 / 744], [train main loss -8.558092], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 107 / 744], [train main loss -8.535394], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 108 / 744], [train main loss -8.554706], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 109 / 744], [train main loss -8.518290], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 110 / 744], [train main loss -8.513781], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 111 / 744], [train main loss -8.497977], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 112 / 744], [train main loss -8.497610], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 113 / 744], [train main loss -8.480084], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 114 / 744], [train main loss -8.437838], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 115 / 744], [train main loss -8.466092], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 116 / 744], [train main loss -8.474651], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 117 / 744], [train main loss -8.489579], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 118 / 744], [train main loss -8.467027], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 119 / 744], [train main loss -8.486194], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 120 / 744], [train main loss -8.494962], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 121 / 744], [train main loss -8.463523], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 122 / 744], [train main loss -8.464245], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 123 / 744], [train main loss -8.451668], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 124 / 744], [train main loss -8.438642], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 125 / 744], [train main loss -8.465233], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 126 / 744], [train main loss -8.476340], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 127 / 744], [train main loss -8.490386], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 128 / 744], [train main loss -8.516461], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 129 / 744], [train main loss -8.523187], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 130 / 744], [train main loss -8.550770], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 131 / 744], [train main loss -8.559937], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 132 / 744], [train main loss -8.532465], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 133 / 744], [train main loss -8.515680], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 134 / 744], [train main loss -8.537947], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 135 / 744], [train main loss -8.530267], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 136 / 744], [train main loss -8.517865], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 137 / 744], [train main loss -8.495258], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 138 / 744], [train main loss -8.469722], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 139 / 744], [train main loss -8.424919], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 140 / 744], [train main loss -8.389835], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 141 / 744], [train main loss -8.365155], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 142 / 744], [train main loss -8.345393], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 143 / 744], [train main loss -8.387855], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 144 / 744], [train main loss -8.393481], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 145 / 744], [train main loss -8.398503], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 146 / 744], [train main loss -8.394924], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 147 / 744], [train main loss -8.402792], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 148 / 744], [train main loss -8.395835], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 149 / 744], [train main loss -8.428347], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 150 / 744], [train main loss -8.406139], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 151 / 744], [train main loss -8.430238], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 152 / 744], [train main loss -8.454181], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 153 / 744], [train main loss -8.461654], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 154 / 744], [train main loss -8.500544], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 155 / 744], [train main loss -8.493700], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 156 / 744], [train main loss -8.511299], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 157 / 744], [train main loss -8.505134], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 158 / 744], [train main loss -8.492843], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 159 / 744], [train main loss -8.494029], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 160 / 744], [train main loss -8.480114], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 161 / 744], [train main loss -8.471132], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 162 / 744], [train main loss -8.503011], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 163 / 744], [train main loss -8.526555], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 164 / 744], [train main loss -8.498775], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 165 / 744], [train main loss -8.550923], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 166 / 744], [train main loss -8.521983], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 167 / 744], [train main loss -8.477610], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 168 / 744], [train main loss -8.484037], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 169 / 744], [train main loss -8.478596], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 170 / 744], [train main loss -8.487679], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 171 / 744], [train main loss -8.546913], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 172 / 744], [train main loss -8.541103], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 173 / 744], [train main loss -8.550228], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 174 / 744], [train main loss -8.509408], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 175 / 744], [train main loss -8.527037], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 176 / 744], [train main loss -8.543380], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 177 / 744], [train main loss -8.540404], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 178 / 744], [train main loss -8.538814], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 179 / 744], [train main loss -8.543859], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 180 / 744], [train main loss -8.516020], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 181 / 744], [train main loss -8.517499], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 182 / 744], [train main loss -8.503714], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 183 / 744], [train main loss -8.521327], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 184 / 744], [train main loss -8.504201], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 185 / 744], [train main loss -8.508339], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 186 / 744], [train main loss -8.520888], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 187 / 744], [train main loss -8.521607], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 188 / 744], [train main loss -8.519987], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 189 / 744], [train main loss -8.514408], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 190 / 744], [train main loss -8.496072], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 191 / 744], [train main loss -8.502344], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 192 / 744], [train main loss -8.517969], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 193 / 744], [train main loss -8.512571], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 194 / 744], [train main loss -8.518543], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 195 / 744], [train main loss -8.490490], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 196 / 744], [train main loss -8.478934], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 197 / 744], [train main loss -8.479247], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 198 / 744], [train main loss -8.475569], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 199 / 744], [train main loss -8.478281], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 200 / 744], [train main loss -8.498474], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 201 / 744], [train main loss -8.494889], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 202 / 744], [train main loss -8.521775], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 203 / 744], [train main loss -8.487841], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 204 / 744], [train main loss -8.517347], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 205 / 744], [train main loss -8.524420], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 206 / 744], [train main loss -8.529565], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 207 / 744], [train main loss -8.504698], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 208 / 744], [train main loss -8.481935], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 209 / 744], [train main loss -8.482518], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 210 / 744], [train main loss -8.451865], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 211 / 744], [train main loss -8.439723], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 212 / 744], [train main loss -8.453537], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 213 / 744], [train main loss -8.464721], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 214 / 744], [train main loss -8.483212], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 215 / 744], [train main loss -8.489680], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 216 / 744], [train main loss -8.479460], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 217 / 744], [train main loss -8.480955], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 218 / 744], [train main loss -8.518322], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 219 / 744], [train main loss -8.551409], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 220 / 744], [train main loss -8.532032], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 221 / 744], [train main loss -8.558969], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 222 / 744], [train main loss -8.551700], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 223 / 744], [train main loss -8.555260], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 224 / 744], [train main loss -8.567540], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 225 / 744], [train main loss -8.543191], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 226 / 744], [train main loss -8.537100], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 227 / 744], [train main loss -8.540271], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 228 / 744], [train main loss -8.568471], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 229 / 744], [train main loss -8.567423], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 230 / 744], [train main loss -8.590781], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 231 / 744], [train main loss -8.583765], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 232 / 744], [train main loss -8.597166], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 233 / 744], [train main loss -8.602034], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 234 / 744], [train main loss -8.623005], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 235 / 744], [train main loss -8.613099], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 236 / 744], [train main loss -8.604325], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 237 / 744], [train main loss -8.599765], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 238 / 744], [train main loss -8.594949], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 239 / 744], [train main loss -8.584617], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 240 / 744], [train main loss -8.588986], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 241 / 744], [train main loss -8.557684], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 242 / 744], [train main loss -8.563612], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 243 / 744], [train main loss -8.577633], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 244 / 744], [train main loss -8.576459], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 245 / 744], [train main loss -8.568246], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 246 / 744], [train main loss -8.550747], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 247 / 744], [train main loss -8.567741], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 248 / 744], [train main loss -8.573621], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 249 / 744], [train main loss -8.569377], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 250 / 744], [train main loss -8.550510], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 251 / 744], [train main loss -8.556838], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 252 / 744], [train main loss -8.543491], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 253 / 744], [train main loss -8.540767], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 254 / 744], [train main loss -8.524718], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 255 / 744], [train main loss -8.524451], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 256 / 744], [train main loss -8.539109], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 257 / 744], [train main loss -8.536120], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 258 / 744], [train main loss -8.530283], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 259 / 744], [train main loss -8.519834], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 260 / 744], [train main loss -8.524175], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 261 / 744], [train main loss -8.508113], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 262 / 744], [train main loss -8.533345], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 263 / 744], [train main loss -8.526020], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 264 / 744], [train main loss -8.538533], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 265 / 744], [train main loss -8.512692], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 266 / 744], [train main loss -8.513723], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 267 / 744], [train main loss -8.490027], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 268 / 744], [train main loss -8.480908], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 269 / 744], [train main loss -8.492372], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 270 / 744], [train main loss -8.464938], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 271 / 744], [train main loss -8.469482], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 272 / 744], [train main loss -8.477602], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 273 / 744], [train main loss -8.443753], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 274 / 744], [train main loss -8.459174], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 275 / 744], [train main loss -8.432182], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 276 / 744], [train main loss -8.421307], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 277 / 744], [train main loss -8.422809], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 278 / 744], [train main loss -8.409387], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 279 / 744], [train main loss -8.418956], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 280 / 744], [train main loss -8.430650], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 281 / 744], [train main loss -8.447390], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 282 / 744], [train main loss -8.466175], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 283 / 744], [train main loss -8.468195], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 284 / 744], [train main loss -8.471983], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 285 / 744], [train main loss -8.477156], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 286 / 744], [train main loss -8.497903], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 287 / 744], [train main loss -8.498196], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 288 / 744], [train main loss -8.509959], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 289 / 744], [train main loss -8.490197], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 290 / 744], [train main loss -8.484504], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 291 / 744], [train main loss -8.487329], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 292 / 744], [train main loss -8.475288], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 293 / 744], [train main loss -8.477013], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 294 / 744], [train main loss -8.495113], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 295 / 744], [train main loss -8.493647], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 296 / 744], [train main loss -8.500071], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 297 / 744], [train main loss -8.507861], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 298 / 744], [train main loss -8.509754], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 299 / 744], [train main loss -8.519697], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 300 / 744], [train main loss -8.534372], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 301 / 744], [train main loss -8.531023], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 302 / 744], [train main loss -8.529923], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 303 / 744], [train main loss -8.513400], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 304 / 744], [train main loss -8.505880], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 305 / 744], [train main loss -8.504255], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 306 / 744], [train main loss -8.500607], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 307 / 744], [train main loss -8.522199], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 308 / 744], [train main loss -8.524484], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 309 / 744], [train main loss -8.526608], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 310 / 744], [train main loss -8.525687], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 311 / 744], [train main loss -8.519024], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 312 / 744], [train main loss -8.537874], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 313 / 744], [train main loss -8.545141], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 314 / 744], [train main loss -8.548216], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 315 / 744], [train main loss -8.564032], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 316 / 744], [train main loss -8.569596], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 317 / 744], [train main loss -8.569371], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 318 / 744], [train main loss -8.561680], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 319 / 744], [train main loss -8.551173], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 320 / 744], [train main loss -8.542268], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 321 / 744], [train main loss -8.535010], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 322 / 744], [train main loss -8.529073], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 323 / 744], [train main loss -8.507528], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 324 / 744], [train main loss -8.525939], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 325 / 744], [train main loss -8.549671], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 326 / 744], [train main loss -8.556859], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 327 / 744], [train main loss -8.544091], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 328 / 744], [train main loss -8.561879], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 329 / 744], [train main loss -8.566881], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 330 / 744], [train main loss -8.565063], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 331 / 744], [train main loss -8.546723], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 332 / 744], [train main loss -8.554438], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 333 / 744], [train main loss -8.558201], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 334 / 744], [train main loss -8.550437], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 335 / 744], [train main loss -8.552415], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 336 / 744], [train main loss -8.572663], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 337 / 744], [train main loss -8.592354], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 338 / 744], [train main loss -8.575856], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 339 / 744], [train main loss -8.580045], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 340 / 744], [train main loss -8.558216], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 341 / 744], [train main loss -8.551317], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 342 / 744], [train main loss -8.544094], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 343 / 744], [train main loss -8.551913], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 344 / 744], [train main loss -8.551817], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 345 / 744], [train main loss -8.567757], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 346 / 744], [train main loss -8.561801], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 347 / 744], [train main loss -8.572524], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 348 / 744], [train main loss -8.560633], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 349 / 744], [train main loss -8.553242], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 350 / 744], [train main loss -8.545800], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 351 / 744], [train main loss -8.546561], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 352 / 744], [train main loss -8.552893], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 353 / 744], [train main loss -8.556462], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 354 / 744], [train main loss -8.560672], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 355 / 744], [train main loss -8.562166], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 356 / 744], [train main loss -8.569345], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 357 / 744], [train main loss -8.578697], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 358 / 744], [train main loss -8.591337], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 359 / 744], [train main loss -8.574971], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 360 / 744], [train main loss -8.577206], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 361 / 744], [train main loss -8.602387], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 362 / 744], [train main loss -8.609414], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 363 / 744], [train main loss -8.631065], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 364 / 744], [train main loss -8.631086], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 365 / 744], [train main loss -8.614380], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 366 / 744], [train main loss -8.620799], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 367 / 744], [train main loss -8.617258], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 368 / 744], [train main loss -8.602958], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 369 / 744], [train main loss -8.599186], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 370 / 744], [train main loss -8.602991], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 371 / 744], [train main loss -8.602724], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 372 / 744], [train main loss -8.612189], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 373 / 744], [train main loss -8.616177], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 374 / 744], [train main loss -8.618273], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 375 / 744], [train main loss -8.624340], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 376 / 744], [train main loss -8.620468], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 377 / 744], [train main loss -8.619900], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 378 / 744], [train main loss -8.627384], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 379 / 744], [train main loss -8.634083], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 380 / 744], [train main loss -8.616941], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 381 / 744], [train main loss -8.616031], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 382 / 744], [train main loss -8.619688], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 383 / 744], [train main loss -8.615753], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 384 / 744], [train main loss -8.616313], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 385 / 744], [train main loss -8.617616], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 386 / 744], [train main loss -8.620940], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 387 / 744], [train main loss -8.626559], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 388 / 744], [train main loss -8.630936], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 389 / 744], [train main loss -8.628847], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 390 / 744], [train main loss -8.635943], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 391 / 744], [train main loss -8.632391], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 392 / 744], [train main loss -8.628103], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 393 / 744], [train main loss -8.636675], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 394 / 744], [train main loss -8.632601], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 395 / 744], [train main loss -8.635656], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 396 / 744], [train main loss -8.636046], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 397 / 744], [train main loss -8.635335], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 398 / 744], [train main loss -8.628439], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 399 / 744], [train main loss -8.616843], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 400 / 744], [train main loss -8.623308], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 401 / 744], [train main loss -8.622741], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 402 / 744], [train main loss -8.647811], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 403 / 744], [train main loss -8.655965], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 404 / 744], [train main loss -8.654385], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 405 / 744], [train main loss -8.645944], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 406 / 744], [train main loss -8.638932], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 407 / 744], [train main loss -8.632556], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 408 / 744], [train main loss -8.639801], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 409 / 744], [train main loss -8.647141], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 410 / 744], [train main loss -8.632574], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 411 / 744], [train main loss -8.619380], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 412 / 744], [train main loss -8.627366], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 413 / 744], [train main loss -8.630206], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 414 / 744], [train main loss -8.648999], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 415 / 744], [train main loss -8.653639], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 416 / 744], [train main loss -8.646931], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 417 / 744], [train main loss -8.652682], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 418 / 744], [train main loss -8.647557], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 419 / 744], [train main loss -8.672077], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 420 / 744], [train main loss -8.666930], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 421 / 744], [train main loss -8.658416], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 422 / 744], [train main loss -8.650571], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 423 / 744], [train main loss -8.645455], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 424 / 744], [train main loss -8.650893], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 425 / 744], [train main loss -8.647160], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 426 / 744], [train main loss -8.643714], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 427 / 744], [train main loss -8.637721], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 428 / 744], [train main loss -8.639285], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 429 / 744], [train main loss -8.636316], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 430 / 744], [train main loss -8.636749], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 431 / 744], [train main loss -8.637836], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 432 / 744], [train main loss -8.640909], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 433 / 744], [train main loss -8.638668], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 434 / 744], [train main loss -8.643157], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 435 / 744], [train main loss -8.632508], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 436 / 744], [train main loss -8.635229], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 437 / 744], [train main loss -8.634757], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 438 / 744], [train main loss -8.645428], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 439 / 744], [train main loss -8.645766], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 440 / 744], [train main loss -8.642521], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 441 / 744], [train main loss -8.633212], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 442 / 744], [train main loss -8.637462], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 443 / 744], [train main loss -8.630578], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 444 / 744], [train main loss -8.622685], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 445 / 744], [train main loss -8.625847], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 446 / 744], [train main loss -8.632030], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 447 / 744], [train main loss -8.634942], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 448 / 744], [train main loss -8.637557], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 449 / 744], [train main loss -8.629030], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 450 / 744], [train main loss -8.629684], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 451 / 744], [train main loss -8.630951], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 452 / 744], [train main loss -8.635862], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 453 / 744], [train main loss -8.647711], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 454 / 744], [train main loss -8.649724], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 455 / 744], [train main loss -8.642661], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 456 / 744], [train main loss -8.645985], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 457 / 744], [train main loss -8.642984], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 458 / 744], [train main loss -8.642498], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 459 / 744], [train main loss -8.639329], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 460 / 744], [train main loss -8.631687], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 461 / 744], [train main loss -8.628111], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 462 / 744], [train main loss -8.624413], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 463 / 744], [train main loss -8.622591], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 464 / 744], [train main loss -8.618300], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 465 / 744], [train main loss -8.624932], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 466 / 744], [train main loss -8.634237], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 467 / 744], [train main loss -8.640822], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 468 / 744], [train main loss -8.639682], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 469 / 744], [train main loss -8.637625], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 470 / 744], [train main loss -8.640680], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 471 / 744], [train main loss -8.631091], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 472 / 744], [train main loss -8.638562], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 473 / 744], [train main loss -8.645501], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 474 / 744], [train main loss -8.650693], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 475 / 744], [train main loss -8.649875], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 476 / 744], [train main loss -8.640098], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 477 / 744], [train main loss -8.644228], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 478 / 744], [train main loss -8.638663], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 479 / 744], [train main loss -8.636481], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 480 / 744], [train main loss -8.632422], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 481 / 744], [train main loss -8.630199], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 482 / 744], [train main loss -8.623245], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 483 / 744], [train main loss -8.621684], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 484 / 744], [train main loss -8.613993], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 485 / 744], [train main loss -8.615300], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 486 / 744], [train main loss -8.615904], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 487 / 744], [train main loss -8.597130], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 488 / 744], [train main loss -8.594322], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 489 / 744], [train main loss -8.604158], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 490 / 744], [train main loss -8.604398], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 491 / 744], [train main loss -8.614415], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 492 / 744], [train main loss -8.616326], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 493 / 744], [train main loss -8.607408], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 494 / 744], [train main loss -8.609836], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 495 / 744], [train main loss -8.613807], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 496 / 744], [train main loss -8.615844], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 497 / 744], [train main loss -8.632020], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 498 / 744], [train main loss -8.639796], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 499 / 744], [train main loss -8.631105], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 500 / 744], [train main loss -8.628662], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 501 / 744], [train main loss -8.633002], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 502 / 744], [train main loss -8.638939], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 503 / 744], [train main loss -8.630921], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 504 / 744], [train main loss -8.635377], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 505 / 744], [train main loss -8.637184], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 506 / 744], [train main loss -8.645043], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 507 / 744], [train main loss -8.649227], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 508 / 744], [train main loss -8.664069], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 509 / 744], [train main loss -8.661583], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 510 / 744], [train main loss -8.651441], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 511 / 744], [train main loss -8.647320], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 512 / 744], [train main loss -8.654967], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 513 / 744], [train main loss -8.655454], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 514 / 744], [train main loss -8.660548], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 515 / 744], [train main loss -8.660879], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 516 / 744], [train main loss -8.656032], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 517 / 744], [train main loss -8.664386], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 518 / 744], [train main loss -8.658894], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 519 / 744], [train main loss -8.665400], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 520 / 744], [train main loss -8.663293], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 521 / 744], [train main loss -8.662893], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 522 / 744], [train main loss -8.662456], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 523 / 744], [train main loss -8.662617], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 524 / 744], [train main loss -8.671943], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 525 / 744], [train main loss -8.678974], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 526 / 744], [train main loss -8.672688], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 527 / 744], [train main loss -8.682390], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 528 / 744], [train main loss -8.676519], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 529 / 744], [train main loss -8.671606], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 530 / 744], [train main loss -8.660575], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 531 / 744], [train main loss -8.654925], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 532 / 744], [train main loss -8.665495], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 533 / 744], [train main loss -8.645808], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 534 / 744], [train main loss -8.659254], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 535 / 744], [train main loss -8.670313], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 536 / 744], [train main loss -8.667047], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 537 / 744], [train main loss -8.669578], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 538 / 744], [train main loss -8.659734], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 539 / 744], [train main loss -8.662709], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 540 / 744], [train main loss -8.660545], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 541 / 744], [train main loss -8.658838], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 542 / 744], [train main loss -8.652616], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 543 / 744], [train main loss -8.654921], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 544 / 744], [train main loss -8.646343], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 545 / 744], [train main loss -8.649804], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 546 / 744], [train main loss -8.650349], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 547 / 744], [train main loss -8.644327], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 548 / 744], [train main loss -8.637735], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 549 / 744], [train main loss -8.638431], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 550 / 744], [train main loss -8.629024], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 551 / 744], [train main loss -8.632411], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 552 / 744], [train main loss -8.630968], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 553 / 744], [train main loss -8.628524], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 554 / 744], [train main loss -8.634050], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 555 / 744], [train main loss -8.625491], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 556 / 744], [train main loss -8.628488], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 557 / 744], [train main loss -8.623223], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 558 / 744], [train main loss -8.623784], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 559 / 744], [train main loss -8.625244], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 560 / 744], [train main loss -8.622715], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 561 / 744], [train main loss -8.621519], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 562 / 744], [train main loss -8.624896], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 563 / 744], [train main loss -8.622669], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 564 / 744], [train main loss -8.629867], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 565 / 744], [train main loss -8.625007], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 566 / 744], [train main loss -8.618363], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 567 / 744], [train main loss -8.614884], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 568 / 744], [train main loss -8.612035], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 569 / 744], [train main loss -8.611875], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 570 / 744], [train main loss -8.603660], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 571 / 744], [train main loss -8.608680], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 572 / 744], [train main loss -8.613997], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 573 / 744], [train main loss -8.599510], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 574 / 744], [train main loss -8.598809], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 575 / 744], [train main loss -8.596552], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 576 / 744], [train main loss -8.591816], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 577 / 744], [train main loss -8.593134], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 578 / 744], [train main loss -8.597568], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 579 / 744], [train main loss -8.584903], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 580 / 744], [train main loss -8.591482], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 581 / 744], [train main loss -8.587980], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 582 / 744], [train main loss -8.590758], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 583 / 744], [train main loss -8.587603], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 584 / 744], [train main loss -8.587281], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 585 / 744], [train main loss -8.585144], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 586 / 744], [train main loss -8.579542], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 587 / 744], [train main loss -8.585543], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 588 / 744], [train main loss -8.577176], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 589 / 744], [train main loss -8.582441], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 590 / 744], [train main loss -8.577906], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 591 / 744], [train main loss -8.573785], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 592 / 744], [train main loss -8.568552], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 593 / 744], [train main loss -8.568995], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 594 / 744], [train main loss -8.578603], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 595 / 744], [train main loss -8.573739], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 596 / 744], [train main loss -8.568743], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 597 / 744], [train main loss -8.568601], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 598 / 744], [train main loss -8.564115], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 599 / 744], [train main loss -8.564212], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 600 / 744], [train main loss -8.562753], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 601 / 744], [train main loss -8.557742], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 602 / 744], [train main loss -8.559800], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 603 / 744], [train main loss -8.561150], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 604 / 744], [train main loss -8.569134], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 605 / 744], [train main loss -8.571338], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 606 / 744], [train main loss -8.574108], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 607 / 744], [train main loss -8.567946], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 608 / 744], [train main loss -8.564873], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 609 / 744], [train main loss -8.578874], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 610 / 744], [train main loss -8.567415], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 611 / 744], [train main loss -8.568536], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 612 / 744], [train main loss -8.561079], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 613 / 744], [train main loss -8.551036], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 614 / 744], [train main loss -8.555169], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 615 / 744], [train main loss -8.556871], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 616 / 744], [train main loss -8.560172], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 617 / 744], [train main loss -8.563174], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 618 / 744], [train main loss -8.567248], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 619 / 744], [train main loss -8.576302], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 620 / 744], [train main loss -8.584002], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 621 / 744], [train main loss -8.581870], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 622 / 744], [train main loss -8.588769], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 623 / 744], [train main loss -8.588493], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 624 / 744], [train main loss -8.596403], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 625 / 744], [train main loss -8.594338], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 626 / 744], [train main loss -8.597584], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 627 / 744], [train main loss -8.597875], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 628 / 744], [train main loss -8.599346], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 629 / 744], [train main loss -8.597181], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 630 / 744], [train main loss -8.600377], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 631 / 744], [train main loss -8.608418], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 632 / 744], [train main loss -8.604757], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 633 / 744], [train main loss -8.607272], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 634 / 744], [train main loss -8.613632], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 635 / 744], [train main loss -8.610442], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 636 / 744], [train main loss -8.604069], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 637 / 744], [train main loss -8.606542], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 638 / 744], [train main loss -8.610718], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 639 / 744], [train main loss -8.610778], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 640 / 744], [train main loss -8.612881], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 641 / 744], [train main loss -8.609500], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 642 / 744], [train main loss -8.604860], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 643 / 744], [train main loss -8.603779], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 644 / 744], [train main loss -8.605922], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 645 / 744], [train main loss -8.612428], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 646 / 744], [train main loss -8.610865], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 647 / 744], [train main loss -8.612124], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 648 / 744], [train main loss -8.602258], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 649 / 744], [train main loss -8.611984], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 650 / 744], [train main loss -8.610538], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 651 / 744], [train main loss -8.609607], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 652 / 744], [train main loss -8.613201], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 653 / 744], [train main loss -8.616257], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 654 / 744], [train main loss -8.615405], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 655 / 744], [train main loss -8.624831], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 656 / 744], [train main loss -8.619676], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 657 / 744], [train main loss -8.618606], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 658 / 744], [train main loss -8.613785], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 659 / 744], [train main loss -8.615689], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 660 / 744], [train main loss -8.616092], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 661 / 744], [train main loss -8.609264], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 662 / 744], [train main loss -8.608137], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 663 / 744], [train main loss -8.605004], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 664 / 744], [train main loss -8.600653], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 665 / 744], [train main loss -8.610136], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 666 / 744], [train main loss -8.611828], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 667 / 744], [train main loss -8.611334], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 668 / 744], [train main loss -8.617231], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 669 / 744], [train main loss -8.613463], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 670 / 744], [train main loss -8.618848], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 671 / 744], [train main loss -8.616016], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 672 / 744], [train main loss -8.619326], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 673 / 744], [train main loss -8.615763], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 674 / 744], [train main loss -8.610494], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 675 / 744], [train main loss -8.606050], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 676 / 744], [train main loss -8.611604], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 677 / 744], [train main loss -8.613814], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 678 / 744], [train main loss -8.622417], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 679 / 744], [train main loss -8.628649], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 680 / 744], [train main loss -8.625274], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 681 / 744], [train main loss -8.621171], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 682 / 744], [train main loss -8.621455], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 683 / 744], [train main loss -8.626190], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 684 / 744], [train main loss -8.617125], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 685 / 744], [train main loss -8.617986], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 686 / 744], [train main loss -8.624606], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 687 / 744], [train main loss -8.624540], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 688 / 744], [train main loss -8.625763], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 689 / 744], [train main loss -8.623576], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 690 / 744], [train main loss -8.623660], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 691 / 744], [train main loss -8.642387], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 692 / 744], [train main loss -8.641269], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 693 / 744], [train main loss -8.636626], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 694 / 744], [train main loss -8.639843], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 695 / 744], [train main loss -8.647141], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 696 / 744], [train main loss -8.645144], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 697 / 744], [train main loss -8.640132], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 698 / 744], [train main loss -8.643695], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 699 / 744], [train main loss -8.645839], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 700 / 744], [train main loss -8.643403], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 701 / 744], [train main loss -8.640368], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 702 / 744], [train main loss -8.643684], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 703 / 744], [train main loss -8.642510], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 704 / 744], [train main loss -8.640378], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 705 / 744], [train main loss -8.644897], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 706 / 744], [train main loss -8.649274], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 707 / 744], [train main loss -8.646541], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 708 / 744], [train main loss -8.649628], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 709 / 744], [train main loss -8.652192], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 710 / 744], [train main loss -8.656261], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 711 / 744], [train main loss -8.655502], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 712 / 744], [train main loss -8.659213], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 713 / 744], [train main loss -8.653222], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 714 / 744], [train main loss -8.648359], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 715 / 744], [train main loss -8.653662], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 716 / 744], [train main loss -8.655266], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 717 / 744], [train main loss -8.656765], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 718 / 744], [train main loss -8.658131], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 719 / 744], [train main loss -8.656340], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 720 / 744], [train main loss -8.663867], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 721 / 744], [train main loss -8.665562], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 722 / 744], [train main loss -8.668032], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 723 / 744], [train main loss -8.661339], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 724 / 744], [train main loss -8.663376], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 725 / 744], [train main loss -8.664952], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 726 / 744], [train main loss -8.663464], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 727 / 744], [train main loss -8.662171], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 728 / 744], [train main loss -8.660248], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 729 / 744], [train main loss -8.655304], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 730 / 744], [train main loss -8.658034], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 731 / 744], [train main loss -8.660053], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 732 / 744], [train main loss -8.663917], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 733 / 744], [train main loss -8.676586], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 734 / 744], [train main loss -8.682099], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 735 / 744], [train main loss -8.685241], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 736 / 744], [train main loss -8.683897], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 737 / 744], [train main loss -8.687092], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 738 / 744], [train main loss -8.688347], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 739 / 744], [train main loss -8.683196], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 740 / 744], [train main loss -8.682826], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 741 / 744], [train main loss -8.681606], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 742 / 744], [train main loss -8.677158], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 743 / 744], [train main loss -8.681400], [lr 0.004553] [batchtime 1.14]
[epoch 8], [iter 744 / 744], [train main loss -8.681954], [lr 0.004553] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              96.05  36.27  0.04  0.00         0.96      1.00
   1  sidewalk          74.68   5.21  0.04  0.30         0.96      0.77
   2  building          92.98  21.23  0.03  0.04         0.97      0.96
   3  wall              66.27   0.54  0.36  0.15         0.73      0.87
   4  fence             66.38   0.61  0.34  0.17         0.75      0.86
   5  pole              70.48   1.19  0.24  0.18         0.80      0.85
   6  traffic light     76.25   0.17  0.16  0.16         0.86      0.87
   7  traffic sign      82.03   0.58  0.15  0.07         0.87      0.93
   8  vegetation        92.54  16.57  0.05  0.04         0.96      0.97
   9  terrain           57.57   0.59  0.40  0.34         0.72      0.75
  10  sky               94.18   3.31  0.01  0.05         0.99      0.95
  11  person            84.81   1.18  0.10  0.08         0.91      0.92
  12  rider             69.56   0.18  0.20  0.23         0.83      0.81
  13  car               94.17   6.30  0.03  0.03         0.97      0.97
  14  truck             69.63   0.28  0.07  0.37         0.94      0.73
  15  bus               76.07   0.30  0.29  0.02         0.77      0.98
  16  train             56.96   0.10  0.11  0.65         0.90      0.61
  17  motorcycle        47.27   0.07  0.16  0.95         0.86      0.51
  18  bicycle           79.44   0.64  0.11  0.15         0.90      0.87
Mean: 76.17
-----------------------------------------------------------------------------------------------------------
this : [epoch 8], [val loss 0.16506], [acc 0.95339], [acc_cls 0.87703], [mean_iu 0.76175], [fwavacc 0.91575]
best : [epoch 7], [val loss 0.14374], [acc 0.96322], [acc_cls 0.87391], [mean_iu 0.78071], [fwavacc 0.93235]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 9], [iter 1 / 744], [train main loss -5.754900], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 2 / 744], [train main loss -10.881440], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 3 / 744], [train main loss -10.205180], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 4 / 744], [train main loss -8.379222], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 5 / 744], [train main loss -8.005438], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 6 / 744], [train main loss -7.985759], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 7 / 744], [train main loss -7.811732], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 8 / 744], [train main loss -8.219025], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 9 / 744], [train main loss -8.241746], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 10 / 744], [train main loss -8.122237], [lr 0.004499] [batchtime 0]
[epoch 9], [iter 11 / 744], [train main loss -7.634184], [lr 0.004499] [batchtime 1.13]
[epoch 9], [iter 12 / 744], [train main loss -7.597255], [lr 0.004499] [batchtime 1.13]
[epoch 9], [iter 13 / 744], [train main loss -7.712800], [lr 0.004499] [batchtime 1.13]
[epoch 9], [iter 14 / 744], [train main loss -7.805391], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 15 / 744], [train main loss -8.040478], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 16 / 744], [train main loss -8.186233], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 17 / 744], [train main loss -8.158416], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 18 / 744], [train main loss -8.225443], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 19 / 744], [train main loss -8.185890], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 20 / 744], [train main loss -8.081117], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 21 / 744], [train main loss -8.093293], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 22 / 744], [train main loss -8.291899], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 23 / 744], [train main loss -8.016569], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 24 / 744], [train main loss -7.781014], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 25 / 744], [train main loss -7.826903], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 26 / 744], [train main loss -7.687816], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 27 / 744], [train main loss -7.642360], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 28 / 744], [train main loss -7.576774], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 29 / 744], [train main loss -7.641042], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 30 / 744], [train main loss -7.666232], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 31 / 744], [train main loss -7.641107], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 32 / 744], [train main loss -7.771887], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 33 / 744], [train main loss -7.758422], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 34 / 744], [train main loss -7.690511], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 35 / 744], [train main loss -7.624210], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 36 / 744], [train main loss -7.555627], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 37 / 744], [train main loss -7.509285], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 38 / 744], [train main loss -7.478652], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 39 / 744], [train main loss -7.466828], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 40 / 744], [train main loss -7.392703], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 41 / 744], [train main loss -7.391614], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 42 / 744], [train main loss -7.448414], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 43 / 744], [train main loss -7.454323], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 44 / 744], [train main loss -7.399282], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 45 / 744], [train main loss -7.456797], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 46 / 744], [train main loss -7.464837], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 47 / 744], [train main loss -7.541674], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 48 / 744], [train main loss -7.549563], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 49 / 744], [train main loss -7.519033], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 50 / 744], [train main loss -7.528095], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 51 / 744], [train main loss -7.534527], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 52 / 744], [train main loss -7.557298], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 53 / 744], [train main loss -7.658518], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 54 / 744], [train main loss -7.642120], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 55 / 744], [train main loss -7.788583], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 56 / 744], [train main loss -7.783610], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 57 / 744], [train main loss -7.789362], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 58 / 744], [train main loss -7.873652], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 59 / 744], [train main loss -7.933431], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 60 / 744], [train main loss -7.957326], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 61 / 744], [train main loss -7.947611], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 62 / 744], [train main loss -7.952503], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 63 / 744], [train main loss -7.936017], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 64 / 744], [train main loss -7.892963], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 65 / 744], [train main loss -7.945592], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 66 / 744], [train main loss -7.827645], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 67 / 744], [train main loss -7.740663], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 68 / 744], [train main loss -7.774906], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 69 / 744], [train main loss -7.735520], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 70 / 744], [train main loss -7.756087], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 71 / 744], [train main loss -7.751889], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 72 / 744], [train main loss -7.854315], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 73 / 744], [train main loss -7.861460], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 74 / 744], [train main loss -7.844180], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 75 / 744], [train main loss -7.850524], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 76 / 744], [train main loss -7.829517], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 77 / 744], [train main loss -7.795033], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 78 / 744], [train main loss -7.790295], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 79 / 744], [train main loss -7.797528], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 80 / 744], [train main loss -7.866107], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 81 / 744], [train main loss -7.902922], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 82 / 744], [train main loss -7.893029], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 83 / 744], [train main loss -7.891628], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 84 / 744], [train main loss -7.904775], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 85 / 744], [train main loss -7.874121], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 86 / 744], [train main loss -7.940277], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 87 / 744], [train main loss -7.957310], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 88 / 744], [train main loss -7.954729], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 89 / 744], [train main loss -7.942500], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 90 / 744], [train main loss -7.979490], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 91 / 744], [train main loss -7.942801], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 92 / 744], [train main loss -7.923015], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 93 / 744], [train main loss -7.875303], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 94 / 744], [train main loss -7.958209], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 95 / 744], [train main loss -7.994786], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 96 / 744], [train main loss -7.982320], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 97 / 744], [train main loss -8.026730], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 98 / 744], [train main loss -7.989392], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 99 / 744], [train main loss -8.031662], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 100 / 744], [train main loss -8.104911], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 101 / 744], [train main loss -8.122875], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 102 / 744], [train main loss -8.107120], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 103 / 744], [train main loss -8.160220], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 104 / 744], [train main loss -8.156992], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 105 / 744], [train main loss -8.136011], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 106 / 744], [train main loss -8.097557], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 107 / 744], [train main loss -8.097967], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 108 / 744], [train main loss -8.120880], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 109 / 744], [train main loss -8.089744], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 110 / 744], [train main loss -8.088768], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 111 / 744], [train main loss -8.098424], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 112 / 744], [train main loss -8.054235], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 113 / 744], [train main loss -8.068450], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 114 / 744], [train main loss -8.115503], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 115 / 744], [train main loss -8.120172], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 116 / 744], [train main loss -8.100238], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 117 / 744], [train main loss -8.044520], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 118 / 744], [train main loss -8.064365], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 119 / 744], [train main loss -8.037971], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 120 / 744], [train main loss -8.063738], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 121 / 744], [train main loss -8.058439], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 122 / 744], [train main loss -8.023025], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 123 / 744], [train main loss -7.969136], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 124 / 744], [train main loss -8.005957], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 125 / 744], [train main loss -8.029662], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 126 / 744], [train main loss -8.034354], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 127 / 744], [train main loss -8.024210], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 128 / 744], [train main loss -8.062506], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 129 / 744], [train main loss -8.046208], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 130 / 744], [train main loss -8.041431], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 131 / 744], [train main loss -8.068563], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 132 / 744], [train main loss -8.080053], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 133 / 744], [train main loss -8.068598], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 134 / 744], [train main loss -8.079685], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 135 / 744], [train main loss -8.082850], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 136 / 744], [train main loss -8.079188], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 137 / 744], [train main loss -8.062200], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 138 / 744], [train main loss -8.087423], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 139 / 744], [train main loss -8.097168], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 140 / 744], [train main loss -8.110428], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 141 / 744], [train main loss -8.097647], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 142 / 744], [train main loss -8.065425], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 143 / 744], [train main loss -8.051094], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 144 / 744], [train main loss -8.020345], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 145 / 744], [train main loss -8.012697], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 146 / 744], [train main loss -7.997828], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 147 / 744], [train main loss -7.998838], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 148 / 744], [train main loss -7.996595], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 149 / 744], [train main loss -8.009812], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 150 / 744], [train main loss -8.041278], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 151 / 744], [train main loss -8.068788], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 152 / 744], [train main loss -8.051159], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 153 / 744], [train main loss -8.052864], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 154 / 744], [train main loss -8.051575], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 155 / 744], [train main loss -8.077693], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 156 / 744], [train main loss -8.087240], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 157 / 744], [train main loss -8.102656], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 158 / 744], [train main loss -8.101151], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 159 / 744], [train main loss -8.086208], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 160 / 744], [train main loss -8.093594], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 161 / 744], [train main loss -8.081534], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 162 / 744], [train main loss -8.097059], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 163 / 744], [train main loss -8.073846], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 164 / 744], [train main loss -8.075213], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 165 / 744], [train main loss -8.066287], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 166 / 744], [train main loss -8.078411], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 167 / 744], [train main loss -8.071759], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 168 / 744], [train main loss -8.067162], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 169 / 744], [train main loss -8.055102], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 170 / 744], [train main loss -8.031780], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 171 / 744], [train main loss -8.021162], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 172 / 744], [train main loss -8.002658], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 173 / 744], [train main loss -8.046381], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 174 / 744], [train main loss -8.046937], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 175 / 744], [train main loss -8.041321], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 176 / 744], [train main loss -8.024836], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 177 / 744], [train main loss -8.048371], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 178 / 744], [train main loss -8.036696], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 179 / 744], [train main loss -8.053896], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 180 / 744], [train main loss -8.040450], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 181 / 744], [train main loss -8.029482], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 182 / 744], [train main loss -7.995065], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 183 / 744], [train main loss -8.019694], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 184 / 744], [train main loss -8.050799], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 185 / 744], [train main loss -8.071783], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 186 / 744], [train main loss -8.079151], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 187 / 744], [train main loss -8.096929], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 188 / 744], [train main loss -8.115109], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 189 / 744], [train main loss -8.121692], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 190 / 744], [train main loss -8.118089], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 191 / 744], [train main loss -8.122529], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 192 / 744], [train main loss -8.106684], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 193 / 744], [train main loss -8.104375], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 194 / 744], [train main loss -8.094056], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 195 / 744], [train main loss -8.101270], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 196 / 744], [train main loss -8.091974], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 197 / 744], [train main loss -8.103962], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 198 / 744], [train main loss -8.114838], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 199 / 744], [train main loss -8.115575], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 200 / 744], [train main loss -8.107469], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 201 / 744], [train main loss -8.104341], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 202 / 744], [train main loss -8.098224], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 203 / 744], [train main loss -8.098909], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 204 / 744], [train main loss -8.105644], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 205 / 744], [train main loss -8.100276], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 206 / 744], [train main loss -8.101906], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 207 / 744], [train main loss -8.111097], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 208 / 744], [train main loss -8.077736], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 209 / 744], [train main loss -8.068952], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 210 / 744], [train main loss -8.052408], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 211 / 744], [train main loss -8.040792], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 212 / 744], [train main loss -8.016214], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 213 / 744], [train main loss -8.040177], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 214 / 744], [train main loss -8.039193], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 215 / 744], [train main loss -8.044032], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 216 / 744], [train main loss -8.059402], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 217 / 744], [train main loss -8.062626], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 218 / 744], [train main loss -8.074667], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 219 / 744], [train main loss -8.062042], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 220 / 744], [train main loss -8.052845], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 221 / 744], [train main loss -8.052514], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 222 / 744], [train main loss -8.050951], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 223 / 744], [train main loss -8.046366], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 224 / 744], [train main loss -8.027680], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 225 / 744], [train main loss -8.018337], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 226 / 744], [train main loss -8.020145], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 227 / 744], [train main loss -8.003737], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 228 / 744], [train main loss -8.024179], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 229 / 744], [train main loss -8.066580], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 230 / 744], [train main loss -8.054641], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 231 / 744], [train main loss -8.074556], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 232 / 744], [train main loss -8.088351], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 233 / 744], [train main loss -8.099339], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 234 / 744], [train main loss -8.095297], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 235 / 744], [train main loss -8.133318], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 236 / 744], [train main loss -8.131605], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 237 / 744], [train main loss -8.154167], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 238 / 744], [train main loss -8.177461], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 239 / 744], [train main loss -8.178490], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 240 / 744], [train main loss -8.183415], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 241 / 744], [train main loss -8.167142], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 242 / 744], [train main loss -8.172008], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 243 / 744], [train main loss -8.201172], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 244 / 744], [train main loss -8.195396], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 245 / 744], [train main loss -8.199645], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 246 / 744], [train main loss -8.198390], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 247 / 744], [train main loss -8.212186], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 248 / 744], [train main loss -8.234687], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 249 / 744], [train main loss -8.242264], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 250 / 744], [train main loss -8.230307], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 251 / 744], [train main loss -8.233143], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 252 / 744], [train main loss -8.216791], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 253 / 744], [train main loss -8.195051], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 254 / 744], [train main loss -8.231418], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 255 / 744], [train main loss -8.237818], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 256 / 744], [train main loss -8.219410], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 257 / 744], [train main loss -8.202218], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 258 / 744], [train main loss -8.187096], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 259 / 744], [train main loss -8.208420], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 260 / 744], [train main loss -8.222431], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 261 / 744], [train main loss -8.232598], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 262 / 744], [train main loss -8.231356], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 263 / 744], [train main loss -8.231309], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 264 / 744], [train main loss -8.243699], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 265 / 744], [train main loss -8.250389], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 266 / 744], [train main loss -8.273291], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 267 / 744], [train main loss -8.282471], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 268 / 744], [train main loss -8.281542], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 269 / 744], [train main loss -8.284877], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 270 / 744], [train main loss -8.275285], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 271 / 744], [train main loss -8.275842], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 272 / 744], [train main loss -8.257806], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 273 / 744], [train main loss -8.265342], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 274 / 744], [train main loss -8.270902], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 275 / 744], [train main loss -8.263167], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 276 / 744], [train main loss -8.258924], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 277 / 744], [train main loss -8.267312], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 278 / 744], [train main loss -8.269356], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 279 / 744], [train main loss -8.267163], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 280 / 744], [train main loss -8.244894], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 281 / 744], [train main loss -8.231469], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 282 / 744], [train main loss -8.222845], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 283 / 744], [train main loss -8.249066], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 284 / 744], [train main loss -8.262244], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 285 / 744], [train main loss -8.265494], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 286 / 744], [train main loss -8.275260], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 287 / 744], [train main loss -8.271342], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 288 / 744], [train main loss -8.260602], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 289 / 744], [train main loss -8.272261], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 290 / 744], [train main loss -8.267666], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 291 / 744], [train main loss -8.291333], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 292 / 744], [train main loss -8.293988], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 293 / 744], [train main loss -8.293824], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 294 / 744], [train main loss -8.299798], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 295 / 744], [train main loss -8.310965], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 296 / 744], [train main loss -8.315516], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 297 / 744], [train main loss -8.329262], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 298 / 744], [train main loss -8.325224], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 299 / 744], [train main loss -8.335715], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 300 / 744], [train main loss -8.350736], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 301 / 744], [train main loss -8.350762], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 302 / 744], [train main loss -8.344369], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 303 / 744], [train main loss -8.367522], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 304 / 744], [train main loss -8.369792], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 305 / 744], [train main loss -8.372664], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 306 / 744], [train main loss -8.366556], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 307 / 744], [train main loss -8.376756], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 308 / 744], [train main loss -8.371292], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 309 / 744], [train main loss -8.375221], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 310 / 744], [train main loss -8.369650], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 311 / 744], [train main loss -8.366221], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 312 / 744], [train main loss -8.370545], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 313 / 744], [train main loss -8.378354], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 314 / 744], [train main loss -8.352343], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 315 / 744], [train main loss -8.348281], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 316 / 744], [train main loss -8.346415], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 317 / 744], [train main loss -8.359661], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 318 / 744], [train main loss -8.361886], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 319 / 744], [train main loss -8.347596], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 320 / 744], [train main loss -8.346956], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 321 / 744], [train main loss -8.366113], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 322 / 744], [train main loss -8.348704], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 323 / 744], [train main loss -8.370346], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 324 / 744], [train main loss -8.368326], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 325 / 744], [train main loss -8.364582], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 326 / 744], [train main loss -8.373614], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 327 / 744], [train main loss -8.371549], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 328 / 744], [train main loss -8.378216], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 329 / 744], [train main loss -8.374140], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 330 / 744], [train main loss -8.365731], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 331 / 744], [train main loss -8.385440], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 332 / 744], [train main loss -8.386661], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 333 / 744], [train main loss -8.386604], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 334 / 744], [train main loss -8.400208], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 335 / 744], [train main loss -8.397003], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 336 / 744], [train main loss -8.398864], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 337 / 744], [train main loss -8.385562], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 338 / 744], [train main loss -8.382354], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 339 / 744], [train main loss -8.372217], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 340 / 744], [train main loss -8.370176], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 341 / 744], [train main loss -8.364849], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 342 / 744], [train main loss -8.362482], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 343 / 744], [train main loss -8.359351], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 344 / 744], [train main loss -8.345115], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 345 / 744], [train main loss -8.342039], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 346 / 744], [train main loss -8.353720], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 347 / 744], [train main loss -8.343498], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 348 / 744], [train main loss -8.353239], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 349 / 744], [train main loss -8.340891], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 350 / 744], [train main loss -8.328213], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 351 / 744], [train main loss -8.340774], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 352 / 744], [train main loss -8.346305], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 353 / 744], [train main loss -8.342673], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 354 / 744], [train main loss -8.343307], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 355 / 744], [train main loss -8.334058], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 356 / 744], [train main loss -8.325233], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 357 / 744], [train main loss -8.331491], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 358 / 744], [train main loss -8.317333], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 359 / 744], [train main loss -8.318410], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 360 / 744], [train main loss -8.298419], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 361 / 744], [train main loss -8.300482], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 362 / 744], [train main loss -8.304692], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 363 / 744], [train main loss -8.310399], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 364 / 744], [train main loss -8.311648], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 365 / 744], [train main loss -8.309573], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 366 / 744], [train main loss -8.298444], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 367 / 744], [train main loss -8.297245], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 368 / 744], [train main loss -8.291933], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 369 / 744], [train main loss -8.301554], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 370 / 744], [train main loss -8.301086], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 371 / 744], [train main loss -8.295714], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 372 / 744], [train main loss -8.303338], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 373 / 744], [train main loss -8.299127], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 374 / 744], [train main loss -8.305268], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 375 / 744], [train main loss -8.315062], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 376 / 744], [train main loss -8.302047], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 377 / 744], [train main loss -8.298395], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 378 / 744], [train main loss -8.291148], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 379 / 744], [train main loss -8.282725], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 380 / 744], [train main loss -8.266978], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 381 / 744], [train main loss -8.268425], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 382 / 744], [train main loss -8.273448], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 383 / 744], [train main loss -8.275885], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 384 / 744], [train main loss -8.285946], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 385 / 744], [train main loss -8.278056], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 386 / 744], [train main loss -8.277513], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 387 / 744], [train main loss -8.286202], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 388 / 744], [train main loss -8.279605], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 389 / 744], [train main loss -8.280179], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 390 / 744], [train main loss -8.287281], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 391 / 744], [train main loss -8.275956], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 392 / 744], [train main loss -8.270940], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 393 / 744], [train main loss -8.269249], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 394 / 744], [train main loss -8.253471], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 395 / 744], [train main loss -8.254745], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 396 / 744], [train main loss -8.272289], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 397 / 744], [train main loss -8.277120], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 398 / 744], [train main loss -8.287803], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 399 / 744], [train main loss -8.294890], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 400 / 744], [train main loss -8.303641], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 401 / 744], [train main loss -8.308596], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 402 / 744], [train main loss -8.300771], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 403 / 744], [train main loss -8.302909], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 404 / 744], [train main loss -8.302163], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 405 / 744], [train main loss -8.297139], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 406 / 744], [train main loss -8.306859], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 407 / 744], [train main loss -8.300975], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 408 / 744], [train main loss -8.301266], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 409 / 744], [train main loss -8.305401], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 410 / 744], [train main loss -8.302941], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 411 / 744], [train main loss -8.315871], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 412 / 744], [train main loss -8.320402], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 413 / 744], [train main loss -8.317465], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 414 / 744], [train main loss -8.309376], [lr 0.004499] [batchtime 1.14]
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0

[epoch 9], [iter 415 / 744], [train main loss -8.325185], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 416 / 744], [train main loss -8.323592], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 417 / 744], [train main loss -8.334121], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 418 / 744], [train main loss -8.330153], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 419 / 744], [train main loss -8.340226], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 420 / 744], [train main loss -8.357308], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 421 / 744], [train main loss -8.360000], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 422 / 744], [train main loss -8.356344], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 423 / 744], [train main loss -8.348712], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 424 / 744], [train main loss -8.353404], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 425 / 744], [train main loss -8.352338], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 426 / 744], [train main loss -8.351329], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 427 / 744], [train main loss -8.350698], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 428 / 744], [train main loss -8.349857], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 429 / 744], [train main loss -8.349276], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 430 / 744], [train main loss -8.347316], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 431 / 744], [train main loss -8.342669], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 432 / 744], [train main loss -8.348712], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 433 / 744], [train main loss -8.344104], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 434 / 744], [train main loss -8.353207], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 435 / 744], [train main loss -8.359617], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 436 / 744], [train main loss -8.355443], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 437 / 744], [train main loss -8.363388], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 438 / 744], [train main loss -8.369788], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 439 / 744], [train main loss -8.357131], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 440 / 744], [train main loss -8.355416], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 441 / 744], [train main loss -8.338523], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 442 / 744], [train main loss -8.343799], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 443 / 744], [train main loss -8.360473], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 444 / 744], [train main loss -8.376799], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 445 / 744], [train main loss -8.387549], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 446 / 744], [train main loss -8.389038], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 447 / 744], [train main loss -8.387509], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 448 / 744], [train main loss -8.374420], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 449 / 744], [train main loss -8.383606], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 450 / 744], [train main loss -8.378566], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 451 / 744], [train main loss -8.374221], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 452 / 744], [train main loss -8.372010], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 453 / 744], [train main loss -8.381632], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 454 / 744], [train main loss -8.378849], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 455 / 744], [train main loss -8.388290], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 456 / 744], [train main loss -8.380986], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 457 / 744], [train main loss -8.386214], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 458 / 744], [train main loss -8.386362], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 459 / 744], [train main loss -8.378692], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 460 / 744], [train main loss -8.390193], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 461 / 744], [train main loss -8.408079], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 462 / 744], [train main loss -8.411504], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 463 / 744], [train main loss -8.423629], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 464 / 744], [train main loss -8.420159], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 465 / 744], [train main loss -8.429036], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 466 / 744], [train main loss -8.423664], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 467 / 744], [train main loss -8.424606], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 468 / 744], [train main loss -8.431092], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 469 / 744], [train main loss -8.420451], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 470 / 744], [train main loss -8.421484], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 471 / 744], [train main loss -8.416622], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 472 / 744], [train main loss -8.412621], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 473 / 744], [train main loss -8.422397], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 474 / 744], [train main loss -8.426425], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 475 / 744], [train main loss -8.430916], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 476 / 744], [train main loss -8.421442], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 477 / 744], [train main loss -8.419413], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 478 / 744], [train main loss -8.419222], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 479 / 744], [train main loss -8.414970], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 480 / 744], [train main loss -8.437646], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 481 / 744], [train main loss -8.438777], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 482 / 744], [train main loss -8.453547], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 483 / 744], [train main loss -8.445138], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 484 / 744], [train main loss -8.444069], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 485 / 744], [train main loss -8.445826], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 486 / 744], [train main loss -8.444356], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 487 / 744], [train main loss -8.445496], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 488 / 744], [train main loss -8.442978], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 489 / 744], [train main loss -8.451230], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 490 / 744], [train main loss -8.450926], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 491 / 744], [train main loss -8.445282], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 492 / 744], [train main loss -8.436099], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 493 / 744], [train main loss -8.438166], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 494 / 744], [train main loss -8.450288], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 495 / 744], [train main loss -8.446890], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 496 / 744], [train main loss -8.448490], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 497 / 744], [train main loss -8.455272], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 498 / 744], [train main loss -8.456696], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 499 / 744], [train main loss -8.446282], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 500 / 744], [train main loss -8.441865], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 501 / 744], [train main loss -8.435466], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 502 / 744], [train main loss -8.430031], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 503 / 744], [train main loss -8.437786], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 504 / 744], [train main loss -8.438458], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 505 / 744], [train main loss -8.438141], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 506 / 744], [train main loss -8.432058], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 507 / 744], [train main loss -8.434173], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 508 / 744], [train main loss -8.430379], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 509 / 744], [train main loss -8.425130], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 510 / 744], [train main loss -8.429278], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 511 / 744], [train main loss -8.426608], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 512 / 744], [train main loss -8.419603], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 513 / 744], [train main loss -8.416518], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 514 / 744], [train main loss -8.423602], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 515 / 744], [train main loss -8.426602], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 516 / 744], [train main loss -8.432614], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 517 / 744], [train main loss -8.423846], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 518 / 744], [train main loss -8.427419], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 519 / 744], [train main loss -8.416300], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 520 / 744], [train main loss -8.420091], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 521 / 744], [train main loss -8.412841], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 522 / 744], [train main loss -8.405468], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 523 / 744], [train main loss -8.405052], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 524 / 744], [train main loss -8.407400], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 525 / 744], [train main loss -8.412695], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 526 / 744], [train main loss -8.409896], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 527 / 744], [train main loss -8.412792], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 528 / 744], [train main loss -8.412468], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 529 / 744], [train main loss -8.407280], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 530 / 744], [train main loss -8.399540], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 531 / 744], [train main loss -8.395627], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 532 / 744], [train main loss -8.387546], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 533 / 744], [train main loss -8.389859], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 534 / 744], [train main loss -8.383670], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 535 / 744], [train main loss -8.386156], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 536 / 744], [train main loss -8.388441], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 537 / 744], [train main loss -8.397386], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 538 / 744], [train main loss -8.399027], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 539 / 744], [train main loss -8.394514], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 540 / 744], [train main loss -8.387121], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 541 / 744], [train main loss -8.378034], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 542 / 744], [train main loss -8.390455], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 543 / 744], [train main loss -8.381910], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 544 / 744], [train main loss -8.382043], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 545 / 744], [train main loss -8.368979], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 546 / 744], [train main loss -8.374904], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 547 / 744], [train main loss -8.371447], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 548 / 744], [train main loss -8.360660], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 549 / 744], [train main loss -8.366937], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 550 / 744], [train main loss -8.359977], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 551 / 744], [train main loss -8.365168], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 552 / 744], [train main loss -8.371626], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 553 / 744], [train main loss -8.381183], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 554 / 744], [train main loss -8.390167], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 555 / 744], [train main loss -8.379094], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 556 / 744], [train main loss -8.375908], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 557 / 744], [train main loss -8.378013], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 558 / 744], [train main loss -8.379227], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 559 / 744], [train main loss -8.384894], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 560 / 744], [train main loss -8.392151], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 561 / 744], [train main loss -8.394174], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 562 / 744], [train main loss -8.389288], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 563 / 744], [train main loss -8.393999], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 564 / 744], [train main loss -8.394579], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 565 / 744], [train main loss -8.397015], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 566 / 744], [train main loss -8.394554], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 567 / 744], [train main loss -8.383391], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 568 / 744], [train main loss -8.376398], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 569 / 744], [train main loss -8.384091], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 570 / 744], [train main loss -8.388265], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 571 / 744], [train main loss -8.393685], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 572 / 744], [train main loss -8.391501], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 573 / 744], [train main loss -8.396254], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 574 / 744], [train main loss -8.403527], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 575 / 744], [train main loss -8.401519], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 576 / 744], [train main loss -8.397995], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 577 / 744], [train main loss -8.398696], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 578 / 744], [train main loss -8.393742], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 579 / 744], [train main loss -8.405253], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 580 / 744], [train main loss -8.405242], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 581 / 744], [train main loss -8.406034], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 582 / 744], [train main loss -8.407350], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 583 / 744], [train main loss -8.413879], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 584 / 744], [train main loss -8.406984], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 585 / 744], [train main loss -8.403521], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 586 / 744], [train main loss -8.408439], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 587 / 744], [train main loss -8.410070], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 588 / 744], [train main loss -8.414567], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 589 / 744], [train main loss -8.418563], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 590 / 744], [train main loss -8.425261], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 591 / 744], [train main loss -8.430334], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 592 / 744], [train main loss -8.436178], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 593 / 744], [train main loss -8.436480], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 594 / 744], [train main loss -8.444245], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 595 / 744], [train main loss -8.457427], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 596 / 744], [train main loss -8.460489], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 597 / 744], [train main loss -8.457975], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 598 / 744], [train main loss -8.454617], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 599 / 744], [train main loss -8.453594], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 600 / 744], [train main loss -8.447062], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 601 / 744], [train main loss -8.448299], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 602 / 744], [train main loss -8.447644], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 603 / 744], [train main loss -8.455055], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 604 / 744], [train main loss -8.444539], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 605 / 744], [train main loss -8.440037], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 606 / 744], [train main loss -8.442992], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 607 / 744], [train main loss -8.448872], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 608 / 744], [train main loss -8.457362], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 609 / 744], [train main loss -8.464381], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 610 / 744], [train main loss -8.460452], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 611 / 744], [train main loss -8.458535], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 612 / 744], [train main loss -8.457881], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 613 / 744], [train main loss -8.456374], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 614 / 744], [train main loss -8.459423], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 615 / 744], [train main loss -8.449082], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 616 / 744], [train main loss -8.453841], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 617 / 744], [train main loss -8.454182], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 618 / 744], [train main loss -8.453851], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 619 / 744], [train main loss -8.464994], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 620 / 744], [train main loss -8.456458], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 621 / 744], [train main loss -8.456112], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 622 / 744], [train main loss -8.451738], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 623 / 744], [train main loss -8.453187], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 624 / 744], [train main loss -8.449078], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 625 / 744], [train main loss -8.452710], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 626 / 744], [train main loss -8.447300], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 627 / 744], [train main loss -8.452514], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 628 / 744], [train main loss -8.463200], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 629 / 744], [train main loss -8.461406], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 630 / 744], [train main loss -8.463141], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 631 / 744], [train main loss -8.464588], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 632 / 744], [train main loss -8.459236], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 633 / 744], [train main loss -8.461980], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 634 / 744], [train main loss -8.455730], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 635 / 744], [train main loss -8.464535], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 636 / 744], [train main loss -8.462894], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 637 / 744], [train main loss -8.460143], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 638 / 744], [train main loss -8.455575], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 639 / 744], [train main loss -8.461169], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 640 / 744], [train main loss -8.459690], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 641 / 744], [train main loss -8.467024], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 642 / 744], [train main loss -8.467151], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 643 / 744], [train main loss -8.464012], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 644 / 744], [train main loss -8.462755], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 645 / 744], [train main loss -8.460101], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 646 / 744], [train main loss -8.458392], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 647 / 744], [train main loss -8.464104], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 648 / 744], [train main loss -8.460749], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 649 / 744], [train main loss -8.464017], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 650 / 744], [train main loss -8.463516], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 651 / 744], [train main loss -8.467887], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 652 / 744], [train main loss -8.463019], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 653 / 744], [train main loss -8.457589], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 654 / 744], [train main loss -8.453365], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 655 / 744], [train main loss -8.450885], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 656 / 744], [train main loss -8.448408], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 657 / 744], [train main loss -8.440953], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 658 / 744], [train main loss -8.438064], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 659 / 744], [train main loss -8.443963], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 660 / 744], [train main loss -8.453962], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 661 / 744], [train main loss -8.464119], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 662 / 744], [train main loss -8.463206], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 663 / 744], [train main loss -8.459988], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 664 / 744], [train main loss -8.458572], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 665 / 744], [train main loss -8.462715], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 666 / 744], [train main loss -8.469541], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 667 / 744], [train main loss -8.474745], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 668 / 744], [train main loss -8.470124], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 669 / 744], [train main loss -8.467977], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 670 / 744], [train main loss -8.466237], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 671 / 744], [train main loss -8.465450], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 672 / 744], [train main loss -8.466917], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 673 / 744], [train main loss -8.468151], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 674 / 744], [train main loss -8.470237], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 675 / 744], [train main loss -8.474084], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 676 / 744], [train main loss -8.466848], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 677 / 744], [train main loss -8.470024], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 678 / 744], [train main loss -8.468519], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 679 / 744], [train main loss -8.463529], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 680 / 744], [train main loss -8.470695], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 681 / 744], [train main loss -8.462896], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 682 / 744], [train main loss -8.457213], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 683 / 744], [train main loss -8.454448], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 684 / 744], [train main loss -8.465397], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 685 / 744], [train main loss -8.462255], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 686 / 744], [train main loss -8.463893], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 687 / 744], [train main loss -8.455944], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 688 / 744], [train main loss -8.448868], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 689 / 744], [train main loss -8.444646], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 690 / 744], [train main loss -8.445812], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 691 / 744], [train main loss -8.450187], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 692 / 744], [train main loss -8.457277], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 693 / 744], [train main loss -8.447719], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 694 / 744], [train main loss -8.449835], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 695 / 744], [train main loss -8.457500], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 696 / 744], [train main loss -8.460021], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 697 / 744], [train main loss -8.454126], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 698 / 744], [train main loss -8.456146], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 699 / 744], [train main loss -8.450545], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 700 / 744], [train main loss -8.461979], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 701 / 744], [train main loss -8.458977], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 702 / 744], [train main loss -8.463802], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 703 / 744], [train main loss -8.466520], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 704 / 744], [train main loss -8.469221], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 705 / 744], [train main loss -8.470044], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 706 / 744], [train main loss -8.471666], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 707 / 744], [train main loss -8.474834], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 708 / 744], [train main loss -8.469930], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 709 / 744], [train main loss -8.473111], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 710 / 744], [train main loss -8.465156], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 711 / 744], [train main loss -8.458995], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 712 / 744], [train main loss -8.466844], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 713 / 744], [train main loss -8.462157], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 714 / 744], [train main loss -8.461224], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 715 / 744], [train main loss -8.453961], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 716 / 744], [train main loss -8.443394], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 717 / 744], [train main loss -8.438279], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 718 / 744], [train main loss -8.442809], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 719 / 744], [train main loss -8.444159], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 720 / 744], [train main loss -8.442122], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 721 / 744], [train main loss -8.439231], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 722 / 744], [train main loss -8.440265], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 723 / 744], [train main loss -8.431457], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 724 / 744], [train main loss -8.429047], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 725 / 744], [train main loss -8.428488], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 726 / 744], [train main loss -8.432433], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 727 / 744], [train main loss -8.438088], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 728 / 744], [train main loss -8.443809], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 729 / 744], [train main loss -8.441812], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 730 / 744], [train main loss -8.434876], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 731 / 744], [train main loss -8.437975], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 732 / 744], [train main loss -8.442036], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 733 / 744], [train main loss -8.441572], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 734 / 744], [train main loss -8.440749], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 735 / 744], [train main loss -8.442566], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 736 / 744], [train main loss -8.443148], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 737 / 744], [train main loss -8.443210], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 738 / 744], [train main loss -8.435903], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 739 / 744], [train main loss -8.431868], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 740 / 744], [train main loss -8.436134], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 741 / 744], [train main loss -8.439142], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 742 / 744], [train main loss -8.439645], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 743 / 744], [train main loss -8.437095], [lr 0.004499] [batchtime 1.14]
[epoch 9], [iter 744 / 744], [train main loss -8.440590], [lr 0.004499] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              98.08  37.13  0.01  0.01         0.99      0.99
   1  sidewalk          85.41   5.08  0.06  0.11         0.94      0.90
   2  building          93.31  21.29  0.03  0.04         0.97      0.96
   3  wall              62.10   0.58  0.27  0.34         0.79      0.74
   4  fence             64.87   0.67  0.22  0.32         0.82      0.76
   5  pole              70.60   1.15  0.28  0.13         0.78      0.88
   6  traffic light     76.75   0.17  0.15  0.15         0.87      0.87
   7  traffic sign      82.32   0.59  0.13  0.09         0.89      0.92
   8  vegetation        92.55  16.58  0.04  0.04         0.96      0.97
   9  terrain           56.85   0.52  0.58  0.17         0.63      0.85
  10  sky               95.37   3.30  0.02  0.03         0.98      0.97
  11  person            84.05   1.21  0.08  0.11         0.93      0.90
  12  rider             63.06   0.16  0.37  0.21         0.73      0.82
  13  car               92.27   6.20  0.05  0.03         0.95      0.97
  14  truck             52.72   0.29  0.04  0.86         0.96      0.54
  15  bus               77.91   0.35  0.12  0.17         0.89      0.86
  16  train             75.15   0.10  0.08  0.25         0.93      0.80
  17  motorcycle        59.04   0.05  0.59  0.11         0.63      0.90
  18  bicycle           78.44   0.65  0.09  0.18         0.92      0.84
Mean: 76.89
-----------------------------------------------------------------------------------------------------------
this : [epoch 9], [val loss 0.16392], [acc 0.96081], [acc_cls 0.87109], [mean_iu 0.76887], [fwavacc 0.92820]
best : [epoch 7], [val loss 0.14374], [acc 0.96322], [acc_cls 0.87391], [mean_iu 0.78071], [fwavacc 0.93235]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 10], [iter 1 / 744], [train main loss -14.882043], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 2 / 744], [train main loss -11.299132], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 3 / 744], [train main loss -9.513013], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 4 / 744], [train main loss -9.224894], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 5 / 744], [train main loss -8.835078], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 6 / 744], [train main loss -8.361924], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 7 / 744], [train main loss -8.608940], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 8 / 744], [train main loss -8.250324], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 9 / 744], [train main loss -8.421157], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 10 / 744], [train main loss -8.213590], [lr 0.004445] [batchtime 0]
[epoch 10], [iter 11 / 744], [train main loss -8.291614], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 12 / 744], [train main loss -8.449264], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 13 / 744], [train main loss -8.668855], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 14 / 744], [train main loss -8.675040], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 15 / 744], [train main loss -8.869416], [lr 0.004445] [batchtime 1.15]
[epoch 10], [iter 16 / 744], [train main loss -9.082510], [lr 0.004445] [batchtime 1.15]
[epoch 10], [iter 17 / 744], [train main loss -9.174003], [lr 0.004445] [batchtime 1.15]
[epoch 10], [iter 18 / 744], [train main loss -8.885992], [lr 0.004445] [batchtime 1.15]
[epoch 10], [iter 19 / 744], [train main loss -8.988785], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 20 / 744], [train main loss -9.224337], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 21 / 744], [train main loss -8.988091], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 22 / 744], [train main loss -8.972162], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 23 / 744], [train main loss -8.847181], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 24 / 744], [train main loss -8.845763], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 25 / 744], [train main loss -8.909238], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 26 / 744], [train main loss -8.904145], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 27 / 744], [train main loss -8.898247], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 28 / 744], [train main loss -9.142525], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 29 / 744], [train main loss -9.026714], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 30 / 744], [train main loss -9.093131], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 31 / 744], [train main loss -8.945328], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 32 / 744], [train main loss -8.782105], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 33 / 744], [train main loss -8.815435], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 34 / 744], [train main loss -8.941225], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 35 / 744], [train main loss -8.832128], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 36 / 744], [train main loss -8.821327], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 37 / 744], [train main loss -8.838207], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 38 / 744], [train main loss -8.840213], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 39 / 744], [train main loss -8.859484], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 40 / 744], [train main loss -8.899419], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 41 / 744], [train main loss -9.047497], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 42 / 744], [train main loss -8.979813], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 43 / 744], [train main loss -8.908162], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 44 / 744], [train main loss -8.842422], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 45 / 744], [train main loss -8.838698], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 46 / 744], [train main loss -8.828134], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 47 / 744], [train main loss -8.800962], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 48 / 744], [train main loss -8.865607], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 49 / 744], [train main loss -8.971011], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 50 / 744], [train main loss -8.939409], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 51 / 744], [train main loss -8.921557], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 52 / 744], [train main loss -8.890085], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 53 / 744], [train main loss -8.867669], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 54 / 744], [train main loss -8.985127], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 55 / 744], [train main loss -8.954386], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 56 / 744], [train main loss -8.881411], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 57 / 744], [train main loss -8.838554], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 58 / 744], [train main loss -8.900180], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 59 / 744], [train main loss -8.843604], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 60 / 744], [train main loss -8.806172], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 61 / 744], [train main loss -8.800853], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 62 / 744], [train main loss -8.820122], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 63 / 744], [train main loss -8.878942], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 64 / 744], [train main loss -8.901510], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 65 / 744], [train main loss -8.854815], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 66 / 744], [train main loss -8.921580], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 67 / 744], [train main loss -8.996137], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 68 / 744], [train main loss -9.056883], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 69 / 744], [train main loss -8.999707], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 70 / 744], [train main loss -8.920296], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 71 / 744], [train main loss -8.871597], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 72 / 744], [train main loss -8.834461], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 73 / 744], [train main loss -8.890332], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 74 / 744], [train main loss -8.818064], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 75 / 744], [train main loss -8.828211], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 76 / 744], [train main loss -8.836540], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 77 / 744], [train main loss -8.860540], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 78 / 744], [train main loss -8.827000], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 79 / 744], [train main loss -8.783612], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 80 / 744], [train main loss -8.775885], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 81 / 744], [train main loss -8.866119], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 82 / 744], [train main loss -8.872538], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 83 / 744], [train main loss -8.864832], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 84 / 744], [train main loss -8.842303], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 85 / 744], [train main loss -8.837491], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 86 / 744], [train main loss -8.843756], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 87 / 744], [train main loss -8.808081], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 88 / 744], [train main loss -8.845995], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 89 / 744], [train main loss -8.809700], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 90 / 744], [train main loss -8.806052], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 91 / 744], [train main loss -8.829949], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 92 / 744], [train main loss -8.818055], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 93 / 744], [train main loss -8.841998], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 94 / 744], [train main loss -8.780166], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 95 / 744], [train main loss -8.728677], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 96 / 744], [train main loss -8.643919], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 97 / 744], [train main loss -8.737054], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 98 / 744], [train main loss -8.733036], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 99 / 744], [train main loss -8.717540], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 100 / 744], [train main loss -8.799453], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 101 / 744], [train main loss -8.820505], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 102 / 744], [train main loss -8.802033], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 103 / 744], [train main loss -8.751052], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 104 / 744], [train main loss -8.735716], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 105 / 744], [train main loss -8.771197], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 106 / 744], [train main loss -8.770243], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 107 / 744], [train main loss -8.764568], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 108 / 744], [train main loss -8.773242], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 109 / 744], [train main loss -8.757916], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 110 / 744], [train main loss -8.749768], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 111 / 744], [train main loss -8.750449], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 112 / 744], [train main loss -8.714651], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 113 / 744], [train main loss -8.732763], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 114 / 744], [train main loss -8.668928], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 115 / 744], [train main loss -8.721432], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 116 / 744], [train main loss -8.686792], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 117 / 744], [train main loss -8.681929], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 118 / 744], [train main loss -8.703902], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 119 / 744], [train main loss -8.701576], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 120 / 744], [train main loss -8.672329], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 121 / 744], [train main loss -8.727057], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 122 / 744], [train main loss -8.738203], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 123 / 744], [train main loss -8.754294], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 124 / 744], [train main loss -8.805173], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 125 / 744], [train main loss -8.758087], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 126 / 744], [train main loss -8.748076], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 127 / 744], [train main loss -8.734929], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 128 / 744], [train main loss -8.715021], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 129 / 744], [train main loss -8.740555], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 130 / 744], [train main loss -8.689462], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 131 / 744], [train main loss -8.662285], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 132 / 744], [train main loss -8.694814], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 133 / 744], [train main loss -8.676456], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 134 / 744], [train main loss -8.664245], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 135 / 744], [train main loss -8.677081], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 136 / 744], [train main loss -8.676489], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 137 / 744], [train main loss -8.666249], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 138 / 744], [train main loss -8.708047], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 139 / 744], [train main loss -8.726936], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 140 / 744], [train main loss -8.693408], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 141 / 744], [train main loss -8.691177], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 142 / 744], [train main loss -8.674884], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 143 / 744], [train main loss -8.707043], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 144 / 744], [train main loss -8.692482], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 145 / 744], [train main loss -8.642831], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 146 / 744], [train main loss -8.639510], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 147 / 744], [train main loss -8.682136], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 148 / 744], [train main loss -8.684904], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 149 / 744], [train main loss -8.677681], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 150 / 744], [train main loss -8.681670], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 151 / 744], [train main loss -8.711193], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 152 / 744], [train main loss -8.692702], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 153 / 744], [train main loss -8.746523], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 154 / 744], [train main loss -8.737231], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 155 / 744], [train main loss -8.720671], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 156 / 744], [train main loss -8.719680], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 157 / 744], [train main loss -8.711388], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 158 / 744], [train main loss -8.716462], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 159 / 744], [train main loss -8.715967], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 160 / 744], [train main loss -8.700744], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 161 / 744], [train main loss -8.704925], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 162 / 744], [train main loss -8.682473], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 163 / 744], [train main loss -8.655574], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 164 / 744], [train main loss -8.653053], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 165 / 744], [train main loss -8.632645], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 166 / 744], [train main loss -8.645810], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 167 / 744], [train main loss -8.637073], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 168 / 744], [train main loss -8.630464], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 169 / 744], [train main loss -8.616770], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 170 / 744], [train main loss -8.612062], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 171 / 744], [train main loss -8.626419], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 172 / 744], [train main loss -8.601263], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 173 / 744], [train main loss -8.616949], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 174 / 744], [train main loss -8.616095], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 175 / 744], [train main loss -8.631986], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 176 / 744], [train main loss -8.633928], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 177 / 744], [train main loss -8.663651], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 178 / 744], [train main loss -8.656393], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 179 / 744], [train main loss -8.629146], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 180 / 744], [train main loss -8.662462], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 181 / 744], [train main loss -8.641972], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 182 / 744], [train main loss -8.682858], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 183 / 744], [train main loss -8.671659], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 184 / 744], [train main loss -8.659565], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 185 / 744], [train main loss -8.644217], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 186 / 744], [train main loss -8.607947], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 187 / 744], [train main loss -8.606715], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 188 / 744], [train main loss -8.599486], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 189 / 744], [train main loss -8.609076], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 190 / 744], [train main loss -8.591987], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 191 / 744], [train main loss -8.579762], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 192 / 744], [train main loss -8.584518], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 193 / 744], [train main loss -8.594610], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 194 / 744], [train main loss -8.596232], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 195 / 744], [train main loss -8.568837], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 196 / 744], [train main loss -8.562007], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 197 / 744], [train main loss -8.583836], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 198 / 744], [train main loss -8.594909], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 199 / 744], [train main loss -8.592550], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 200 / 744], [train main loss -8.559526], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 201 / 744], [train main loss -8.600569], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 202 / 744], [train main loss -8.609241], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 203 / 744], [train main loss -8.643459], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 204 / 744], [train main loss -8.633281], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 205 / 744], [train main loss -8.656950], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 206 / 744], [train main loss -8.672207], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 207 / 744], [train main loss -8.665341], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 208 / 744], [train main loss -8.671357], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 209 / 744], [train main loss -8.685760], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 210 / 744], [train main loss -8.677697], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 211 / 744], [train main loss -8.663315], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 212 / 744], [train main loss -8.663096], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 213 / 744], [train main loss -8.669176], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 214 / 744], [train main loss -8.679289], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 215 / 744], [train main loss -8.678309], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 216 / 744], [train main loss -8.707215], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 217 / 744], [train main loss -8.714057], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 218 / 744], [train main loss -8.743302], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 219 / 744], [train main loss -8.746573], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 220 / 744], [train main loss -8.724082], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 221 / 744], [train main loss -8.697186], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 222 / 744], [train main loss -8.713151], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 223 / 744], [train main loss -8.719393], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 224 / 744], [train main loss -8.696028], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 225 / 744], [train main loss -8.693886], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 226 / 744], [train main loss -8.700496], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 227 / 744], [train main loss -8.691042], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 228 / 744], [train main loss -8.694171], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 229 / 744], [train main loss -8.685212], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 230 / 744], [train main loss -8.713005], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 231 / 744], [train main loss -8.730946], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 232 / 744], [train main loss -8.708027], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 233 / 744], [train main loss -8.713671], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 234 / 744], [train main loss -8.695913], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 235 / 744], [train main loss -8.713818], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 236 / 744], [train main loss -8.721750], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 237 / 744], [train main loss -8.724792], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 238 / 744], [train main loss -8.719955], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 239 / 744], [train main loss -8.724564], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 240 / 744], [train main loss -8.735810], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 241 / 744], [train main loss -8.713298], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 242 / 744], [train main loss -8.715546], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 243 / 744], [train main loss -8.698128], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 244 / 744], [train main loss -8.706778], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 245 / 744], [train main loss -8.696246], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 246 / 744], [train main loss -8.695165], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 247 / 744], [train main loss -8.726463], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 248 / 744], [train main loss -8.724821], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 249 / 744], [train main loss -8.706125], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 250 / 744], [train main loss -8.702048], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 251 / 744], [train main loss -8.735075], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 252 / 744], [train main loss -8.742127], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 253 / 744], [train main loss -8.764921], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 254 / 744], [train main loss -8.755086], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 255 / 744], [train main loss -8.735440], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 256 / 744], [train main loss -8.728879], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 257 / 744], [train main loss -8.737744], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 258 / 744], [train main loss -8.753207], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 259 / 744], [train main loss -8.759704], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 260 / 744], [train main loss -8.751716], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 261 / 744], [train main loss -8.748167], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 262 / 744], [train main loss -8.751519], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 263 / 744], [train main loss -8.729207], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 264 / 744], [train main loss -8.715191], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 265 / 744], [train main loss -8.742818], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 266 / 744], [train main loss -8.751755], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 267 / 744], [train main loss -8.770648], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 268 / 744], [train main loss -8.769315], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 269 / 744], [train main loss -8.768325], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 270 / 744], [train main loss -8.762799], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 271 / 744], [train main loss -8.768679], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 272 / 744], [train main loss -8.775873], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 273 / 744], [train main loss -8.758154], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 274 / 744], [train main loss -8.747548], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 275 / 744], [train main loss -8.754384], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 276 / 744], [train main loss -8.763241], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 277 / 744], [train main loss -8.763826], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 278 / 744], [train main loss -8.762727], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 279 / 744], [train main loss -8.773680], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 280 / 744], [train main loss -8.782226], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 281 / 744], [train main loss -8.765865], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 282 / 744], [train main loss -8.771263], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 283 / 744], [train main loss -8.779262], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 284 / 744], [train main loss -8.766597], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 285 / 744], [train main loss -8.758640], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 286 / 744], [train main loss -8.766903], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 287 / 744], [train main loss -8.748475], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 288 / 744], [train main loss -8.743405], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 289 / 744], [train main loss -8.739483], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 290 / 744], [train main loss -8.759320], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 291 / 744], [train main loss -8.782559], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 292 / 744], [train main loss -8.792500], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 293 / 744], [train main loss -8.782232], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 294 / 744], [train main loss -8.794166], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 295 / 744], [train main loss -8.798208], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 296 / 744], [train main loss -8.798292], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 297 / 744], [train main loss -8.803779], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 298 / 744], [train main loss -8.819486], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 299 / 744], [train main loss -8.812101], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 300 / 744], [train main loss -8.808479], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 301 / 744], [train main loss -8.805460], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 302 / 744], [train main loss -8.785671], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 303 / 744], [train main loss -8.797926], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 304 / 744], [train main loss -8.814816], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 305 / 744], [train main loss -8.793502], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 306 / 744], [train main loss -8.812125], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 307 / 744], [train main loss -8.807968], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 308 / 744], [train main loss -8.804640], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 309 / 744], [train main loss -8.814444], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 310 / 744], [train main loss -8.837785], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 311 / 744], [train main loss -8.841422], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 312 / 744], [train main loss -8.830171], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 313 / 744], [train main loss -8.818297], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 314 / 744], [train main loss -8.820782], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 315 / 744], [train main loss -8.823666], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 316 / 744], [train main loss -8.811857], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 317 / 744], [train main loss -8.812360], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 318 / 744], [train main loss -8.811669], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 319 / 744], [train main loss -8.810241], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 320 / 744], [train main loss -8.822158], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 321 / 744], [train main loss -8.840942], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 322 / 744], [train main loss -8.849995], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 323 / 744], [train main loss -8.860633], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 324 / 744], [train main loss -8.860098], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 325 / 744], [train main loss -8.850668], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 326 / 744], [train main loss -8.858392], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 327 / 744], [train main loss -8.850799], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 328 / 744], [train main loss -8.840965], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 329 / 744], [train main loss -8.841763], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 330 / 744], [train main loss -8.832964], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 331 / 744], [train main loss -8.828782], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 332 / 744], [train main loss -8.838021], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 333 / 744], [train main loss -8.841402], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 334 / 744], [train main loss -8.868136], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 335 / 744], [train main loss -8.878672], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 336 / 744], [train main loss -8.870672], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 337 / 744], [train main loss -8.876513], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 338 / 744], [train main loss -8.892126], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 339 / 744], [train main loss -8.889087], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 340 / 744], [train main loss -8.882855], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 341 / 744], [train main loss -8.862109], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 342 / 744], [train main loss -8.856655], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 343 / 744], [train main loss -8.862679], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 344 / 744], [train main loss -8.859801], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 345 / 744], [train main loss -8.846592], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 346 / 744], [train main loss -8.842045], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 347 / 744], [train main loss -8.839410], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 348 / 744], [train main loss -8.851643], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 349 / 744], [train main loss -8.847043], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 350 / 744], [train main loss -8.838083], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 351 / 744], [train main loss -8.845377], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 352 / 744], [train main loss -8.848790], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 353 / 744], [train main loss -8.854808], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 354 / 744], [train main loss -8.861970], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 355 / 744], [train main loss -8.852579], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 356 / 744], [train main loss -8.849932], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 357 / 744], [train main loss -8.839903], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 358 / 744], [train main loss -8.833628], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 359 / 744], [train main loss -8.832531], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 360 / 744], [train main loss -8.844332], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 361 / 744], [train main loss -8.846017], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 362 / 744], [train main loss -8.863451], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 363 / 744], [train main loss -8.862484], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 364 / 744], [train main loss -8.866757], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 365 / 744], [train main loss -8.863172], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 366 / 744], [train main loss -8.872364], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 367 / 744], [train main loss -8.880977], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 368 / 744], [train main loss -8.875263], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 369 / 744], [train main loss -8.885577], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 370 / 744], [train main loss -8.889802], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 371 / 744], [train main loss -8.899662], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 372 / 744], [train main loss -8.889267], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 373 / 744], [train main loss -8.890173], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 374 / 744], [train main loss -8.901374], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 375 / 744], [train main loss -8.897603], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 376 / 744], [train main loss -8.887225], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 377 / 744], [train main loss -8.885805], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 378 / 744], [train main loss -8.890024], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 379 / 744], [train main loss -8.887299], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 380 / 744], [train main loss -8.874684], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 381 / 744], [train main loss -8.858215], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 382 / 744], [train main loss -8.867900], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 383 / 744], [train main loss -8.859655], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 384 / 744], [train main loss -8.857859], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 385 / 744], [train main loss -8.853202], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 386 / 744], [train main loss -8.856033], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 387 / 744], [train main loss -8.866045], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 388 / 744], [train main loss -8.861970], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 389 / 744], [train main loss -8.859351], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 390 / 744], [train main loss -8.858601], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 391 / 744], [train main loss -8.849801], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 392 / 744], [train main loss -8.850560], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 393 / 744], [train main loss -8.838043], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 394 / 744], [train main loss -8.847515], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 395 / 744], [train main loss -8.844656], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 396 / 744], [train main loss -8.848574], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 397 / 744], [train main loss -8.834907], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 398 / 744], [train main loss -8.830237], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 399 / 744], [train main loss -8.810891], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 400 / 744], [train main loss -8.816143], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 401 / 744], [train main loss -8.816675], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 402 / 744], [train main loss -8.813993], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 403 / 744], [train main loss -8.820192], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 404 / 744], [train main loss -8.836493], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 405 / 744], [train main loss -8.840686], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 406 / 744], [train main loss -8.847999], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 407 / 744], [train main loss -8.835780], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 408 / 744], [train main loss -8.840950], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 409 / 744], [train main loss -8.847212], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 410 / 744], [train main loss -8.860187], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 411 / 744], [train main loss -8.874473], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 412 / 744], [train main loss -8.881469], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 413 / 744], [train main loss -8.881830], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 414 / 744], [train main loss -8.868161], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 415 / 744], [train main loss -8.866686], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 416 / 744], [train main loss -8.858321], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 417 / 744], [train main loss -8.852723], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 418 / 744], [train main loss -8.860905], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 419 / 744], [train main loss -8.867349], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 420 / 744], [train main loss -8.873882], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 421 / 744], [train main loss -8.878514], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 422 / 744], [train main loss -8.898098], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 423 / 744], [train main loss -8.890889], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 424 / 744], [train main loss -8.900684], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 425 / 744], [train main loss -8.896431], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 426 / 744], [train main loss -8.890716], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 427 / 744], [train main loss -8.876510], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 428 / 744], [train main loss -8.868918], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 429 / 744], [train main loss -8.856149], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 430 / 744], [train main loss -8.857127], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 431 / 744], [train main loss -8.849706], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 432 / 744], [train main loss -8.860804], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 433 / 744], [train main loss -8.856128], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 434 / 744], [train main loss -8.858701], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 435 / 744], [train main loss -8.853237], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 436 / 744], [train main loss -8.864727], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 437 / 744], [train main loss -8.862275], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 438 / 744], [train main loss -8.873155], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 439 / 744], [train main loss -8.871381], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 440 / 744], [train main loss -8.873947], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 441 / 744], [train main loss -8.866558], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 442 / 744], [train main loss -8.855923], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 443 / 744], [train main loss -8.864639], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 444 / 744], [train main loss -8.862480], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 445 / 744], [train main loss -8.867173], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 446 / 744], [train main loss -8.869589], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 447 / 744], [train main loss -8.861842], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 448 / 744], [train main loss -8.863764], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 449 / 744], [train main loss -8.858407], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 450 / 744], [train main loss -8.854382], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 451 / 744], [train main loss -8.855211], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 452 / 744], [train main loss -8.851072], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 453 / 744], [train main loss -8.857549], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 454 / 744], [train main loss -8.854418], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 455 / 744], [train main loss -8.848999], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 456 / 744], [train main loss -8.857050], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 457 / 744], [train main loss -8.842951], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 458 / 744], [train main loss -8.830897], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 459 / 744], [train main loss -8.838847], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 460 / 744], [train main loss -8.838143], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 461 / 744], [train main loss -8.838577], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 462 / 744], [train main loss -8.843767], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 463 / 744], [train main loss -8.859854], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 464 / 744], [train main loss -8.865084], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 465 / 744], [train main loss -8.867375], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 466 / 744], [train main loss -8.866548], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 467 / 744], [train main loss -8.863243], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 468 / 744], [train main loss -8.850540], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 469 / 744], [train main loss -8.850260], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 470 / 744], [train main loss -8.848359], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 471 / 744], [train main loss -8.844108], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 472 / 744], [train main loss -8.844209], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 473 / 744], [train main loss -8.844161], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 474 / 744], [train main loss -8.836888], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 475 / 744], [train main loss -8.831901], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 476 / 744], [train main loss -8.847348], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 477 / 744], [train main loss -8.843333], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 478 / 744], [train main loss -8.839618], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 479 / 744], [train main loss -8.846110], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 480 / 744], [train main loss -8.851205], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 481 / 744], [train main loss -8.852371], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 482 / 744], [train main loss -8.845193], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 483 / 744], [train main loss -8.842120], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 484 / 744], [train main loss -8.847187], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 485 / 744], [train main loss -8.842803], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 486 / 744], [train main loss -8.851154], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 487 / 744], [train main loss -8.854664], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 488 / 744], [train main loss -8.859294], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 489 / 744], [train main loss -8.857621], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 490 / 744], [train main loss -8.859252], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 491 / 744], [train main loss -8.853102], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 492 / 744], [train main loss -8.863483], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 493 / 744], [train main loss -8.863269], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 494 / 744], [train main loss -8.858673], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 495 / 744], [train main loss -8.847652], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 496 / 744], [train main loss -8.847272], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 497 / 744], [train main loss -8.847173], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 498 / 744], [train main loss -8.850201], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 499 / 744], [train main loss -8.841475], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 500 / 744], [train main loss -8.833508], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 501 / 744], [train main loss -8.833931], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 502 / 744], [train main loss -8.838221], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 503 / 744], [train main loss -8.849916], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 504 / 744], [train main loss -8.861931], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 505 / 744], [train main loss -8.862790], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 506 / 744], [train main loss -8.864413], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 507 / 744], [train main loss -8.870429], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 508 / 744], [train main loss -8.867542], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 509 / 744], [train main loss -8.862768], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 510 / 744], [train main loss -8.860325], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 511 / 744], [train main loss -8.862353], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 512 / 744], [train main loss -8.854143], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 513 / 744], [train main loss -8.856747], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 514 / 744], [train main loss -8.856588], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 515 / 744], [train main loss -8.866194], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 516 / 744], [train main loss -8.859400], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 517 / 744], [train main loss -8.860077], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 518 / 744], [train main loss -8.867451], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 519 / 744], [train main loss -8.872351], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 520 / 744], [train main loss -8.873589], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 521 / 744], [train main loss -8.878684], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 522 / 744], [train main loss -8.873815], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 523 / 744], [train main loss -8.866489], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 524 / 744], [train main loss -8.885340], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 525 / 744], [train main loss -8.884600], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 526 / 744], [train main loss -8.876147], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 527 / 744], [train main loss -8.868971], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 528 / 744], [train main loss -8.875679], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 529 / 744], [train main loss -8.876016], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 530 / 744], [train main loss -8.872205], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 531 / 744], [train main loss -8.874446], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 532 / 744], [train main loss -8.874579], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 533 / 744], [train main loss -8.878419], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 534 / 744], [train main loss -8.866601], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 535 / 744], [train main loss -8.873364], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 536 / 744], [train main loss -8.872320], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 537 / 744], [train main loss -8.866461], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 538 / 744], [train main loss -8.857477], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 539 / 744], [train main loss -8.852851], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 540 / 744], [train main loss -8.844304], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 541 / 744], [train main loss -8.844733], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 542 / 744], [train main loss -8.841858], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 543 / 744], [train main loss -8.842126], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 544 / 744], [train main loss -8.838028], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 545 / 744], [train main loss -8.836811], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 546 / 744], [train main loss -8.836436], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 547 / 744], [train main loss -8.820979], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 548 / 744], [train main loss -8.809715], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 549 / 744], [train main loss -8.812109], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 550 / 744], [train main loss -8.810742], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 551 / 744], [train main loss -8.809687], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 552 / 744], [train main loss -8.804349], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 553 / 744], [train main loss -8.809456], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 554 / 744], [train main loss -8.811240], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 555 / 744], [train main loss -8.805901], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 556 / 744], [train main loss -8.802679], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 557 / 744], [train main loss -8.806496], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 558 / 744], [train main loss -8.806741], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 559 / 744], [train main loss -8.808074], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 560 / 744], [train main loss -8.808211], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 561 / 744], [train main loss -8.802127], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 562 / 744], [train main loss -8.794272], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 563 / 744], [train main loss -8.788860], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 564 / 744], [train main loss -8.792269], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 565 / 744], [train main loss -8.793541], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 566 / 744], [train main loss -8.796095], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 567 / 744], [train main loss -8.788713], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 568 / 744], [train main loss -8.778394], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 569 / 744], [train main loss -8.784622], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 570 / 744], [train main loss -8.786972], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 571 / 744], [train main loss -8.787559], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 572 / 744], [train main loss -8.782308], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 573 / 744], [train main loss -8.782734], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 574 / 744], [train main loss -8.777829], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 575 / 744], [train main loss -8.786516], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 576 / 744], [train main loss -8.780543], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 577 / 744], [train main loss -8.789735], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 578 / 744], [train main loss -8.804525], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 579 / 744], [train main loss -8.815993], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 580 / 744], [train main loss -8.812178], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 581 / 744], [train main loss -8.813369], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 582 / 744], [train main loss -8.801379], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 583 / 744], [train main loss -8.809120], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 584 / 744], [train main loss -8.806991], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 585 / 744], [train main loss -8.812518], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 586 / 744], [train main loss -8.814713], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 587 / 744], [train main loss -8.820517], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 588 / 744], [train main loss -8.810714], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 589 / 744], [train main loss -8.823167], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 590 / 744], [train main loss -8.820619], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 591 / 744], [train main loss -8.823232], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 592 / 744], [train main loss -8.822947], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 593 / 744], [train main loss -8.817288], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 594 / 744], [train main loss -8.819150], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 595 / 744], [train main loss -8.825350], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 596 / 744], [train main loss -8.840727], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 597 / 744], [train main loss -8.844295], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 598 / 744], [train main loss -8.843038], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 599 / 744], [train main loss -8.840372], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 600 / 744], [train main loss -8.833956], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 601 / 744], [train main loss -8.833688], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 602 / 744], [train main loss -8.820992], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 603 / 744], [train main loss -8.818100], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 604 / 744], [train main loss -8.812462], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 605 / 744], [train main loss -8.815452], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 606 / 744], [train main loss -8.809590], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 607 / 744], [train main loss -8.806079], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 608 / 744], [train main loss -8.806484], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 609 / 744], [train main loss -8.801443], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 610 / 744], [train main loss -8.793626], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 611 / 744], [train main loss -8.797918], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 612 / 744], [train main loss -8.801789], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 613 / 744], [train main loss -8.789590], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 614 / 744], [train main loss -8.786155], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 615 / 744], [train main loss -8.791707], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 616 / 744], [train main loss -8.789311], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 617 / 744], [train main loss -8.797590], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 618 / 744], [train main loss -8.794586], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 619 / 744], [train main loss -8.809599], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 620 / 744], [train main loss -8.808594], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 621 / 744], [train main loss -8.813680], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 622 / 744], [train main loss -8.815829], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 623 / 744], [train main loss -8.812016], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 624 / 744], [train main loss -8.807409], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 625 / 744], [train main loss -8.811940], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 626 / 744], [train main loss -8.817357], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 627 / 744], [train main loss -8.811100], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 628 / 744], [train main loss -8.824685], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 629 / 744], [train main loss -8.819582], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 630 / 744], [train main loss -8.823665], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 631 / 744], [train main loss -8.825384], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 632 / 744], [train main loss -8.827907], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 633 / 744], [train main loss -8.825382], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 634 / 744], [train main loss -8.835749], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 635 / 744], [train main loss -8.827386], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 636 / 744], [train main loss -8.824278], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 637 / 744], [train main loss -8.821611], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 638 / 744], [train main loss -8.821788], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 639 / 744], [train main loss -8.821294], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 640 / 744], [train main loss -8.817558], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 641 / 744], [train main loss -8.817565], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 642 / 744], [train main loss -8.816554], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 643 / 744], [train main loss -8.830845], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 644 / 744], [train main loss -8.829693], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 645 / 744], [train main loss -8.828879], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 646 / 744], [train main loss -8.825657], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 647 / 744], [train main loss -8.815530], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 648 / 744], [train main loss -8.819792], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 649 / 744], [train main loss -8.827003], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 650 / 744], [train main loss -8.821335], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 651 / 744], [train main loss -8.822976], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 652 / 744], [train main loss -8.823276], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 653 / 744], [train main loss -8.833284], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 654 / 744], [train main loss -8.827766], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 655 / 744], [train main loss -8.822386], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 656 / 744], [train main loss -8.817608], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 657 / 744], [train main loss -8.811653], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 658 / 744], [train main loss -8.802183], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 659 / 744], [train main loss -8.809813], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 660 / 744], [train main loss -8.811389], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 661 / 744], [train main loss -8.810725], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 662 / 744], [train main loss -8.817762], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 663 / 744], [train main loss -8.823898], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 664 / 744], [train main loss -8.821677], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 665 / 744], [train main loss -8.819567], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 666 / 744], [train main loss -8.817721], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 667 / 744], [train main loss -8.816122], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 668 / 744], [train main loss -8.816137], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 669 / 744], [train main loss -8.826083], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 670 / 744], [train main loss -8.823133], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 671 / 744], [train main loss -8.814570], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 672 / 744], [train main loss -8.819344], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 673 / 744], [train main loss -8.819211], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 674 / 744], [train main loss -8.816808], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 675 / 744], [train main loss -8.824621], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 676 / 744], [train main loss -8.827447], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 677 / 744], [train main loss -8.842285], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 678 / 744], [train main loss -8.844234], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 679 / 744], [train main loss -8.852397], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 680 / 744], [train main loss -8.849959], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 681 / 744], [train main loss -8.847429], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 682 / 744], [train main loss -8.844202], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 683 / 744], [train main loss -8.834454], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 684 / 744], [train main loss -8.831108], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 685 / 744], [train main loss -8.834631], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 686 / 744], [train main loss -8.833119], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 687 / 744], [train main loss -8.834408], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 688 / 744], [train main loss -8.834687], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 689 / 744], [train main loss -8.833795], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 690 / 744], [train main loss -8.833611], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 691 / 744], [train main loss -8.836681], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 692 / 744], [train main loss -8.845274], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 693 / 744], [train main loss -8.846950], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 694 / 744], [train main loss -8.845567], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 695 / 744], [train main loss -8.842251], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 696 / 744], [train main loss -8.840320], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 697 / 744], [train main loss -8.838179], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 698 / 744], [train main loss -8.838313], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 699 / 744], [train main loss -8.838001], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 700 / 744], [train main loss -8.837703], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 701 / 744], [train main loss -8.833850], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 702 / 744], [train main loss -8.831749], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 703 / 744], [train main loss -8.830582], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 704 / 744], [train main loss -8.837255], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 705 / 744], [train main loss -8.834239], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 706 / 744], [train main loss -8.831986], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 707 / 744], [train main loss -8.828939], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 708 / 744], [train main loss -8.827406], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 709 / 744], [train main loss -8.833035], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 710 / 744], [train main loss -8.842705], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 711 / 744], [train main loss -8.842608], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 712 / 744], [train main loss -8.841818], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 713 / 744], [train main loss -8.839691], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 714 / 744], [train main loss -8.837907], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 715 / 744], [train main loss -8.843093], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 716 / 744], [train main loss -8.837920], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 717 / 744], [train main loss -8.834251], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 718 / 744], [train main loss -8.834781], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 719 / 744], [train main loss -8.831350], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 720 / 744], [train main loss -8.833199], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 721 / 744], [train main loss -8.836455], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 722 / 744], [train main loss -8.823062], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 723 / 744], [train main loss -8.814361], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 724 / 744], [train main loss -8.817765], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 725 / 744], [train main loss -8.823625], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 726 / 744], [train main loss -8.821787], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 727 / 744], [train main loss -8.819842], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 728 / 744], [train main loss -8.823567], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 729 / 744], [train main loss -8.820103], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 730 / 744], [train main loss -8.815980], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 731 / 744], [train main loss -8.815012], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 732 / 744], [train main loss -8.813721], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 733 / 744], [train main loss -8.815768], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 734 / 744], [train main loss -8.810478], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 735 / 744], [train main loss -8.819678], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 736 / 744], [train main loss -8.814908], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 737 / 744], [train main loss -8.811813], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 738 / 744], [train main loss -8.806813], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 739 / 744], [train main loss -8.805234], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 740 / 744], [train main loss -8.812055], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 741 / 744], [train main loss -8.810860], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 742 / 744], [train main loss -8.814538], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 743 / 744], [train main loss -8.812637], [lr 0.004445] [batchtime 1.14]
[epoch 10], [iter 744 / 744], [train main loss -8.821867], [lr 0.004445] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              98.23  37.25  0.01  0.01         0.99      0.99
   1  sidewalk          86.46   5.04  0.07  0.08         0.93      0.92
   2  building          93.17  21.25  0.03  0.04         0.97      0.96
   3  wall              64.20   0.53  0.39  0.16         0.72      0.86
   4  fence             64.72   0.66  0.24  0.31         0.81      0.77
   5  pole              71.08   1.17  0.26  0.14         0.79      0.88
   6  traffic light     76.25   0.17  0.19  0.12         0.84      0.89
   7  traffic sign      82.62   0.59  0.12  0.09         0.89      0.92
   8  vegetation        92.99  16.71  0.04  0.04         0.96      0.96
   9  terrain           64.92   0.65  0.29  0.25         0.78      0.80
  10  sky               93.89   3.31  0.01  0.05         0.99      0.95
  11  person            85.06   1.21  0.07  0.10         0.93      0.91
  12  rider             70.09   0.18  0.17  0.25         0.85      0.80
  13  car               95.78   6.37  0.02  0.02         0.98      0.98
  14  truck             77.68   0.25  0.19  0.10         0.84      0.91
  15  bus               77.97   0.35  0.11  0.17         0.90      0.86
  16  train             26.11   0.03  2.83  0.00         0.26      1.00
  17  motorcycle        69.00   0.06  0.27  0.18         0.79      0.85
  18  bicycle           80.39   0.65  0.09  0.15         0.92      0.87
Mean: 77.40
-----------------------------------------------------------------------------------------------------------
this : [epoch 10], [val loss 0.14401], [acc 0.96418], [acc_cls 0.84878], [mean_iu 0.77401], [fwavacc 0.93316]
best : [epoch 7], [val loss 0.14374], [acc 0.96322], [acc_cls 0.87391], [mean_iu 0.78071], [fwavacc 0.93235]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 11], [iter 1 / 744], [train main loss -13.930734], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 2 / 744], [train main loss -12.735019], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 3 / 744], [train main loss -12.122761], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 4 / 744], [train main loss -12.170985], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 5 / 744], [train main loss -11.545917], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 6 / 744], [train main loss -11.494743], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 7 / 744], [train main loss -11.039599], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 8 / 744], [train main loss -10.837607], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 9 / 744], [train main loss -10.572444], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 10 / 744], [train main loss -10.471090], [lr 0.004391] [batchtime 0]
[epoch 11], [iter 11 / 744], [train main loss -10.036151], [lr 0.004391] [batchtime 1.13]
[epoch 11], [iter 12 / 744], [train main loss -9.957876], [lr 0.004391] [batchtime 1.13]
[epoch 11], [iter 13 / 744], [train main loss -9.926523], [lr 0.004391] [batchtime 1.16]
[epoch 11], [iter 14 / 744], [train main loss -9.572987], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 15 / 744], [train main loss -9.519704], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 16 / 744], [train main loss -9.307450], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 17 / 744], [train main loss -9.361722], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 18 / 744], [train main loss -9.408034], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 19 / 744], [train main loss -9.521765], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 20 / 744], [train main loss -9.494214], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 21 / 744], [train main loss -9.567843], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 22 / 744], [train main loss -9.607615], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 23 / 744], [train main loss -9.608993], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 24 / 744], [train main loss -9.593769], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 25 / 744], [train main loss -9.717374], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 26 / 744], [train main loss -9.651399], [lr 0.004391] [batchtime 1.15]
[epoch 11], [iter 27 / 744], [train main loss -9.370558], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 28 / 744], [train main loss -9.499094], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 29 / 744], [train main loss -9.327529], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 30 / 744], [train main loss -9.257481], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 31 / 744], [train main loss -9.141338], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 32 / 744], [train main loss -9.060760], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 33 / 744], [train main loss -9.161147], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 34 / 744], [train main loss -9.208383], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 35 / 744], [train main loss -9.222501], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 36 / 744], [train main loss -8.981109], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 37 / 744], [train main loss -9.074864], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 38 / 744], [train main loss -9.074877], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 39 / 744], [train main loss -9.076135], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 40 / 744], [train main loss -9.094112], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 41 / 744], [train main loss -9.103575], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 42 / 744], [train main loss -9.091358], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 43 / 744], [train main loss -9.013036], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 44 / 744], [train main loss -8.977334], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 45 / 744], [train main loss -8.947423], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 46 / 744], [train main loss -9.049876], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 47 / 744], [train main loss -9.051237], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 48 / 744], [train main loss -8.970849], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 49 / 744], [train main loss -8.954289], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 50 / 744], [train main loss -9.000209], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 51 / 744], [train main loss -8.913281], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 52 / 744], [train main loss -8.969778], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 53 / 744], [train main loss -9.012978], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 54 / 744], [train main loss -9.105161], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 55 / 744], [train main loss -9.151205], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 56 / 744], [train main loss -9.125693], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 57 / 744], [train main loss -9.059378], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 58 / 744], [train main loss -9.023224], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 59 / 744], [train main loss -9.018736], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 60 / 744], [train main loss -9.046474], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 61 / 744], [train main loss -8.956924], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 62 / 744], [train main loss -8.958002], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 63 / 744], [train main loss -8.940048], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 64 / 744], [train main loss -8.876862], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 65 / 744], [train main loss -8.865070], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 66 / 744], [train main loss -8.776590], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 67 / 744], [train main loss -8.788717], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 68 / 744], [train main loss -8.745183], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 69 / 744], [train main loss -8.700885], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 70 / 744], [train main loss -8.684845], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 71 / 744], [train main loss -8.654303], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 72 / 744], [train main loss -8.603086], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 73 / 744], [train main loss -8.646881], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 74 / 744], [train main loss -8.597442], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 75 / 744], [train main loss -8.601465], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 76 / 744], [train main loss -8.665382], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 77 / 744], [train main loss -8.609608], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 78 / 744], [train main loss -8.663518], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 79 / 744], [train main loss -8.627421], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 80 / 744], [train main loss -8.566742], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 81 / 744], [train main loss -8.537528], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 82 / 744], [train main loss -8.549267], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 83 / 744], [train main loss -8.557513], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 84 / 744], [train main loss -8.578748], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 85 / 744], [train main loss -8.610445], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 86 / 744], [train main loss -8.590968], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 87 / 744], [train main loss -8.535938], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 88 / 744], [train main loss -8.586180], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 89 / 744], [train main loss -8.568146], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 90 / 744], [train main loss -8.543706], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 91 / 744], [train main loss -8.570988], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 92 / 744], [train main loss -8.604718], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 93 / 744], [train main loss -8.584986], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 94 / 744], [train main loss -8.549929], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 95 / 744], [train main loss -8.533595], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 96 / 744], [train main loss -8.551197], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 97 / 744], [train main loss -8.550285], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 98 / 744], [train main loss -8.615497], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 99 / 744], [train main loss -8.639713], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 100 / 744], [train main loss -8.587303], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 101 / 744], [train main loss -8.567545], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 102 / 744], [train main loss -8.581362], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 103 / 744], [train main loss -8.581474], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 104 / 744], [train main loss -8.581977], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 105 / 744], [train main loss -8.531929], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 106 / 744], [train main loss -8.523405], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 107 / 744], [train main loss -8.520037], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 108 / 744], [train main loss -8.536510], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 109 / 744], [train main loss -8.595297], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 110 / 744], [train main loss -8.593299], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 111 / 744], [train main loss -8.587795], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 112 / 744], [train main loss -8.612870], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 113 / 744], [train main loss -8.616904], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 114 / 744], [train main loss -8.661788], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 115 / 744], [train main loss -8.648693], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 116 / 744], [train main loss -8.663071], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 117 / 744], [train main loss -8.683286], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 118 / 744], [train main loss -8.653622], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 119 / 744], [train main loss -8.626813], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 120 / 744], [train main loss -8.636588], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 121 / 744], [train main loss -8.655544], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 122 / 744], [train main loss -8.655004], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 123 / 744], [train main loss -8.682907], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 124 / 744], [train main loss -8.731414], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 125 / 744], [train main loss -8.721499], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 126 / 744], [train main loss -8.745205], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 127 / 744], [train main loss -8.731437], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 128 / 744], [train main loss -8.711922], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 129 / 744], [train main loss -8.718053], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 130 / 744], [train main loss -8.693791], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 131 / 744], [train main loss -8.652977], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 132 / 744], [train main loss -8.652076], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 133 / 744], [train main loss -8.615631], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 134 / 744], [train main loss -8.638000], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 135 / 744], [train main loss -8.679555], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 136 / 744], [train main loss -8.665455], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 137 / 744], [train main loss -8.665108], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 138 / 744], [train main loss -8.658656], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 139 / 744], [train main loss -8.692303], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 140 / 744], [train main loss -8.703442], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 141 / 744], [train main loss -8.739334], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 142 / 744], [train main loss -8.723863], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 143 / 744], [train main loss -8.708316], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 144 / 744], [train main loss -8.670931], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 145 / 744], [train main loss -8.674107], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 146 / 744], [train main loss -8.672974], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 147 / 744], [train main loss -8.670631], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 148 / 744], [train main loss -8.706762], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 149 / 744], [train main loss -8.720121], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 150 / 744], [train main loss -8.724543], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 151 / 744], [train main loss -8.691748], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 152 / 744], [train main loss -8.683109], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 153 / 744], [train main loss -8.660334], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 154 / 744], [train main loss -8.647692], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 155 / 744], [train main loss -8.612492], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 156 / 744], [train main loss -8.618993], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 157 / 744], [train main loss -8.611198], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 158 / 744], [train main loss -8.589448], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 159 / 744], [train main loss -8.611175], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 160 / 744], [train main loss -8.662467], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 161 / 744], [train main loss -8.656368], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 162 / 744], [train main loss -8.662477], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 163 / 744], [train main loss -8.701775], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 164 / 744], [train main loss -8.709637], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 165 / 744], [train main loss -8.685755], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 166 / 744], [train main loss -8.680342], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 167 / 744], [train main loss -8.684224], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 168 / 744], [train main loss -8.669624], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 169 / 744], [train main loss -8.691058], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 170 / 744], [train main loss -8.720268], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 171 / 744], [train main loss -8.725018], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 172 / 744], [train main loss -8.695677], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 173 / 744], [train main loss -8.662474], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 174 / 744], [train main loss -8.688100], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 175 / 744], [train main loss -8.706425], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 176 / 744], [train main loss -8.687081], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 177 / 744], [train main loss -8.687187], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 178 / 744], [train main loss -8.681589], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 179 / 744], [train main loss -8.649851], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 180 / 744], [train main loss -8.690789], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 181 / 744], [train main loss -8.713070], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 182 / 744], [train main loss -8.729473], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 183 / 744], [train main loss -8.709694], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 184 / 744], [train main loss -8.705075], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 185 / 744], [train main loss -8.699643], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 186 / 744], [train main loss -8.723130], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 187 / 744], [train main loss -8.768184], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 188 / 744], [train main loss -8.777710], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 189 / 744], [train main loss -8.778510], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 190 / 744], [train main loss -8.752389], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 191 / 744], [train main loss -8.754270], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 192 / 744], [train main loss -8.756467], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 193 / 744], [train main loss -8.737406], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 194 / 744], [train main loss -8.731944], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 195 / 744], [train main loss -8.750897], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 196 / 744], [train main loss -8.773581], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 197 / 744], [train main loss -8.747063], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 198 / 744], [train main loss -8.717799], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 199 / 744], [train main loss -8.698930], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 200 / 744], [train main loss -8.687965], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 201 / 744], [train main loss -8.698972], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 202 / 744], [train main loss -8.715914], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 203 / 744], [train main loss -8.729225], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 204 / 744], [train main loss -8.696088], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 205 / 744], [train main loss -8.670442], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 206 / 744], [train main loss -8.690091], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 207 / 744], [train main loss -8.696629], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 208 / 744], [train main loss -8.682506], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 209 / 744], [train main loss -8.687556], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 210 / 744], [train main loss -8.690603], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 211 / 744], [train main loss -8.710638], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 212 / 744], [train main loss -8.700245], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 213 / 744], [train main loss -8.693494], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 214 / 744], [train main loss -8.701098], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 215 / 744], [train main loss -8.711503], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 216 / 744], [train main loss -8.722982], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 217 / 744], [train main loss -8.725657], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 218 / 744], [train main loss -8.659056], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 219 / 744], [train main loss -8.654147], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 220 / 744], [train main loss -8.670406], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 221 / 744], [train main loss -8.680190], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 222 / 744], [train main loss -8.688326], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 223 / 744], [train main loss -8.674874], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 224 / 744], [train main loss -8.702870], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 225 / 744], [train main loss -8.683793], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 226 / 744], [train main loss -8.681733], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 227 / 744], [train main loss -8.684675], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 228 / 744], [train main loss -8.698114], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 229 / 744], [train main loss -8.713831], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 230 / 744], [train main loss -8.696501], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 231 / 744], [train main loss -8.702428], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 232 / 744], [train main loss -8.698795], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 233 / 744], [train main loss -8.697488], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 234 / 744], [train main loss -8.678721], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 235 / 744], [train main loss -8.665065], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 236 / 744], [train main loss -8.659880], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 237 / 744], [train main loss -8.696945], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 238 / 744], [train main loss -8.688706], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 239 / 744], [train main loss -8.701329], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 240 / 744], [train main loss -8.694702], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 241 / 744], [train main loss -8.705917], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 242 / 744], [train main loss -8.730334], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 243 / 744], [train main loss -8.730105], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 244 / 744], [train main loss -8.744174], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 245 / 744], [train main loss -8.734910], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 246 / 744], [train main loss -8.730821], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 247 / 744], [train main loss -8.714741], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 248 / 744], [train main loss -8.706016], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 249 / 744], [train main loss -8.713841], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 250 / 744], [train main loss -8.717389], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 251 / 744], [train main loss -8.706497], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 252 / 744], [train main loss -8.689918], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 253 / 744], [train main loss -8.697163], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 254 / 744], [train main loss -8.679425], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 255 / 744], [train main loss -8.694502], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 256 / 744], [train main loss -8.708908], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 257 / 744], [train main loss -8.719604], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 258 / 744], [train main loss -8.730454], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 259 / 744], [train main loss -8.726404], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 260 / 744], [train main loss -8.745795], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 261 / 744], [train main loss -8.785751], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 262 / 744], [train main loss -8.822510], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 263 / 744], [train main loss -8.812285], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 264 / 744], [train main loss -8.800921], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 265 / 744], [train main loss -8.790624], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 266 / 744], [train main loss -8.798409], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 267 / 744], [train main loss -8.818646], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 268 / 744], [train main loss -8.819804], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 269 / 744], [train main loss -8.822680], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 270 / 744], [train main loss -8.804046], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 271 / 744], [train main loss -8.803533], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 272 / 744], [train main loss -8.803967], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 273 / 744], [train main loss -8.793930], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 274 / 744], [train main loss -8.801058], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 275 / 744], [train main loss -8.810969], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 276 / 744], [train main loss -8.817391], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 277 / 744], [train main loss -8.803063], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 278 / 744], [train main loss -8.819055], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 279 / 744], [train main loss -8.819581], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 280 / 744], [train main loss -8.820800], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 281 / 744], [train main loss -8.811708], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 282 / 744], [train main loss -8.792035], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 283 / 744], [train main loss -8.786363], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 284 / 744], [train main loss -8.781364], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 285 / 744], [train main loss -8.782807], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 286 / 744], [train main loss -8.778363], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 287 / 744], [train main loss -8.783499], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 288 / 744], [train main loss -8.775365], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 289 / 744], [train main loss -8.798459], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 290 / 744], [train main loss -8.798802], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 291 / 744], [train main loss -8.785964], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 292 / 744], [train main loss -8.764976], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 293 / 744], [train main loss -8.776265], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 294 / 744], [train main loss -8.777129], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 295 / 744], [train main loss -8.758877], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 296 / 744], [train main loss -8.770856], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 297 / 744], [train main loss -8.770745], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 298 / 744], [train main loss -8.772027], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 299 / 744], [train main loss -8.765500], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 300 / 744], [train main loss -8.776207], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 301 / 744], [train main loss -8.780180], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 302 / 744], [train main loss -8.780656], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 303 / 744], [train main loss -8.783028], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 304 / 744], [train main loss -8.776437], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 305 / 744], [train main loss -8.772807], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 306 / 744], [train main loss -8.763186], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 307 / 744], [train main loss -8.767969], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 308 / 744], [train main loss -8.780824], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 309 / 744], [train main loss -8.766685], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 310 / 744], [train main loss -8.764165], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 311 / 744], [train main loss -8.745380], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 312 / 744], [train main loss -8.742573], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 313 / 744], [train main loss -8.734656], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 314 / 744], [train main loss -8.753675], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 315 / 744], [train main loss -8.757528], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 316 / 744], [train main loss -8.736750], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 317 / 744], [train main loss -8.731692], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 318 / 744], [train main loss -8.733019], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 319 / 744], [train main loss -8.734298], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 320 / 744], [train main loss -8.744667], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 321 / 744], [train main loss -8.737852], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 322 / 744], [train main loss -8.757321], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 323 / 744], [train main loss -8.761802], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 324 / 744], [train main loss -8.748834], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 325 / 744], [train main loss -8.723892], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 326 / 744], [train main loss -8.738677], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 327 / 744], [train main loss -8.752311], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 328 / 744], [train main loss -8.749545], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 329 / 744], [train main loss -8.759850], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 330 / 744], [train main loss -8.768513], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 331 / 744], [train main loss -8.757420], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 332 / 744], [train main loss -8.749522], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 333 / 744], [train main loss -8.761502], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 334 / 744], [train main loss -8.768293], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 335 / 744], [train main loss -8.778857], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 336 / 744], [train main loss -8.767170], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 337 / 744], [train main loss -8.767101], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 338 / 744], [train main loss -8.782671], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 339 / 744], [train main loss -8.770383], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 340 / 744], [train main loss -8.767828], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 341 / 744], [train main loss -8.768309], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 342 / 744], [train main loss -8.762312], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 343 / 744], [train main loss -8.751898], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 344 / 744], [train main loss -8.735233], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 345 / 744], [train main loss -8.731806], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 346 / 744], [train main loss -8.727722], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 347 / 744], [train main loss -8.731835], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 348 / 744], [train main loss -8.737700], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 349 / 744], [train main loss -8.729045], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 350 / 744], [train main loss -8.715668], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 351 / 744], [train main loss -8.698276], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 352 / 744], [train main loss -8.699799], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 353 / 744], [train main loss -8.705290], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 354 / 744], [train main loss -8.701802], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 355 / 744], [train main loss -8.710987], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 356 / 744], [train main loss -8.708498], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 357 / 744], [train main loss -8.726831], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 358 / 744], [train main loss -8.709453], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 359 / 744], [train main loss -8.712626], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 360 / 744], [train main loss -8.692531], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 361 / 744], [train main loss -8.704981], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 362 / 744], [train main loss -8.693510], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 363 / 744], [train main loss -8.686442], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 364 / 744], [train main loss -8.687253], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 365 / 744], [train main loss -8.707337], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 366 / 744], [train main loss -8.707237], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 367 / 744], [train main loss -8.718058], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 368 / 744], [train main loss -8.708722], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 369 / 744], [train main loss -8.688493], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 370 / 744], [train main loss -8.693991], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 371 / 744], [train main loss -8.682983], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 372 / 744], [train main loss -8.690929], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 373 / 744], [train main loss -8.680208], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 374 / 744], [train main loss -8.688992], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 375 / 744], [train main loss -8.674459], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 376 / 744], [train main loss -8.661183], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 377 / 744], [train main loss -8.657894], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 378 / 744], [train main loss -8.652652], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 379 / 744], [train main loss -8.663940], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 380 / 744], [train main loss -8.651085], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 381 / 744], [train main loss -8.646386], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 382 / 744], [train main loss -8.642054], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 383 / 744], [train main loss -8.656116], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 384 / 744], [train main loss -8.669892], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 385 / 744], [train main loss -8.690359], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 386 / 744], [train main loss -8.704319], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 387 / 744], [train main loss -8.718372], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 388 / 744], [train main loss -8.715727], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 389 / 744], [train main loss -8.730098], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 390 / 744], [train main loss -8.740855], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 391 / 744], [train main loss -8.740800], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 392 / 744], [train main loss -8.745558], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 393 / 744], [train main loss -8.747452], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 394 / 744], [train main loss -8.733598], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 395 / 744], [train main loss -8.725331], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 396 / 744], [train main loss -8.713346], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 397 / 744], [train main loss -8.704817], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 398 / 744], [train main loss -8.726465], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 399 / 744], [train main loss -8.715214], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 400 / 744], [train main loss -8.701111], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 401 / 744], [train main loss -8.696638], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 402 / 744], [train main loss -8.688247], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 403 / 744], [train main loss -8.699900], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 404 / 744], [train main loss -8.712908], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 405 / 744], [train main loss -8.718711], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 406 / 744], [train main loss -8.728942], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 407 / 744], [train main loss -8.722687], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 408 / 744], [train main loss -8.730454], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 409 / 744], [train main loss -8.742970], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 410 / 744], [train main loss -8.745072], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 411 / 744], [train main loss -8.735471], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 412 / 744], [train main loss -8.742751], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 413 / 744], [train main loss -8.730762], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 414 / 744], [train main loss -8.727347], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 415 / 744], [train main loss -8.733242], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 416 / 744], [train main loss -8.735660], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 417 / 744], [train main loss -8.734673], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 418 / 744], [train main loss -8.740216], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 419 / 744], [train main loss -8.727341], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 420 / 744], [train main loss -8.727584], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 421 / 744], [train main loss -8.721769], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 422 / 744], [train main loss -8.726045], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 423 / 744], [train main loss -8.737783], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 424 / 744], [train main loss -8.746321], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 425 / 744], [train main loss -8.739313], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 426 / 744], [train main loss -8.741606], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 427 / 744], [train main loss -8.748080], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 428 / 744], [train main loss -8.733678], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 429 / 744], [train main loss -8.741167], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 430 / 744], [train main loss -8.749574], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 431 / 744], [train main loss -8.748937], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 432 / 744], [train main loss -8.737738], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 433 / 744], [train main loss -8.747368], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 434 / 744], [train main loss -8.741338], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 435 / 744], [train main loss -8.729057], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 436 / 744], [train main loss -8.734044], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 437 / 744], [train main loss -8.734477], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 438 / 744], [train main loss -8.723347], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 439 / 744], [train main loss -8.728126], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 440 / 744], [train main loss -8.735468], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 441 / 744], [train main loss -8.736331], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 442 / 744], [train main loss -8.736115], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 443 / 744], [train main loss -8.735204], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 444 / 744], [train main loss -8.733243], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 445 / 744], [train main loss -8.738632], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 446 / 744], [train main loss -8.741323], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 447 / 744], [train main loss -8.742346], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 448 / 744], [train main loss -8.745489], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 449 / 744], [train main loss -8.748759], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 450 / 744], [train main loss -8.757595], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 451 / 744], [train main loss -8.759646], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 452 / 744], [train main loss -8.750655], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 453 / 744], [train main loss -8.737237], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 454 / 744], [train main loss -8.741272], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 455 / 744], [train main loss -8.739278], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 456 / 744], [train main loss -8.740769], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 457 / 744], [train main loss -8.743768], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 458 / 744], [train main loss -8.735882], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 459 / 744], [train main loss -8.732499], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 460 / 744], [train main loss -8.735621], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 461 / 744], [train main loss -8.730865], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 462 / 744], [train main loss -8.723101], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 463 / 744], [train main loss -8.724549], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 464 / 744], [train main loss -8.731312], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 465 / 744], [train main loss -8.732973], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 466 / 744], [train main loss -8.733129], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 467 / 744], [train main loss -8.728045], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 468 / 744], [train main loss -8.727003], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 469 / 744], [train main loss -8.715753], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 470 / 744], [train main loss -8.710844], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 471 / 744], [train main loss -8.708547], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 472 / 744], [train main loss -8.703049], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 473 / 744], [train main loss -8.702747], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 474 / 744], [train main loss -8.705034], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 475 / 744], [train main loss -8.709403], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 476 / 744], [train main loss -8.710538], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 477 / 744], [train main loss -8.706711], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 478 / 744], [train main loss -8.693462], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 479 / 744], [train main loss -8.694422], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 480 / 744], [train main loss -8.696493], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 481 / 744], [train main loss -8.697544], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 482 / 744], [train main loss -8.698833], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 483 / 744], [train main loss -8.694345], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 484 / 744], [train main loss -8.684802], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 485 / 744], [train main loss -8.668134], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 486 / 744], [train main loss -8.673222], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 487 / 744], [train main loss -8.671710], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 488 / 744], [train main loss -8.659722], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 489 / 744], [train main loss -8.663106], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 490 / 744], [train main loss -8.666183], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 491 / 744], [train main loss -8.679728], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 492 / 744], [train main loss -8.679576], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 493 / 744], [train main loss -8.688296], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 494 / 744], [train main loss -8.704229], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 495 / 744], [train main loss -8.710851], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 496 / 744], [train main loss -8.709293], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 497 / 744], [train main loss -8.711358], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 498 / 744], [train main loss -8.711356], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 499 / 744], [train main loss -8.722512], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 500 / 744], [train main loss -8.722238], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 501 / 744], [train main loss -8.734142], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 502 / 744], [train main loss -8.728210], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 503 / 744], [train main loss -8.720220], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 504 / 744], [train main loss -8.719080], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 505 / 744], [train main loss -8.706708], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 506 / 744], [train main loss -8.713405], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 507 / 744], [train main loss -8.716829], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 508 / 744], [train main loss -8.717623], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 509 / 744], [train main loss -8.712518], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 510 / 744], [train main loss -8.717743], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 511 / 744], [train main loss -8.726196], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 512 / 744], [train main loss -8.732695], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 513 / 744], [train main loss -8.735159], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 514 / 744], [train main loss -8.735796], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 515 / 744], [train main loss -8.730762], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 516 / 744], [train main loss -8.738404], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 517 / 744], [train main loss -8.746889], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 518 / 744], [train main loss -8.738498], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 519 / 744], [train main loss -8.744871], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 520 / 744], [train main loss -8.751516], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 521 / 744], [train main loss -8.750703], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 522 / 744], [train main loss -8.753908], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 523 / 744], [train main loss -8.752902], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 524 / 744], [train main loss -8.751395], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 525 / 744], [train main loss -8.754224], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 526 / 744], [train main loss -8.753736], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 527 / 744], [train main loss -8.749154], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 528 / 744], [train main loss -8.758233], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 529 / 744], [train main loss -8.761760], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 530 / 744], [train main loss -8.756118], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 531 / 744], [train main loss -8.768428], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 532 / 744], [train main loss -8.761193], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 533 / 744], [train main loss -8.755676], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 534 / 744], [train main loss -8.753903], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 535 / 744], [train main loss -8.749945], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 536 / 744], [train main loss -8.750292], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 537 / 744], [train main loss -8.746151], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 538 / 744], [train main loss -8.750847], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 539 / 744], [train main loss -8.749858], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 540 / 744], [train main loss -8.739439], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 541 / 744], [train main loss -8.739305], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 542 / 744], [train main loss -8.754683], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 543 / 744], [train main loss -8.751298], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 544 / 744], [train main loss -8.750504], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 545 / 744], [train main loss -8.752678], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 546 / 744], [train main loss -8.751292], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 547 / 744], [train main loss -8.753257], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 548 / 744], [train main loss -8.749521], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 549 / 744], [train main loss -8.754264], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 550 / 744], [train main loss -8.753205], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 551 / 744], [train main loss -8.749854], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 552 / 744], [train main loss -8.746085], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 553 / 744], [train main loss -8.738227], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 554 / 744], [train main loss -8.736008], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 555 / 744], [train main loss -8.736723], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 556 / 744], [train main loss -8.732233], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 557 / 744], [train main loss -8.730295], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 558 / 744], [train main loss -8.722753], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 559 / 744], [train main loss -8.720314], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 560 / 744], [train main loss -8.717899], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 561 / 744], [train main loss -8.721083], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 562 / 744], [train main loss -8.723235], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 563 / 744], [train main loss -8.731805], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 564 / 744], [train main loss -8.732900], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 565 / 744], [train main loss -8.732165], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 566 / 744], [train main loss -8.725641], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 567 / 744], [train main loss -8.725356], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 568 / 744], [train main loss -8.725463], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 569 / 744], [train main loss -8.723876], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 570 / 744], [train main loss -8.722458], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 571 / 744], [train main loss -8.724448], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 572 / 744], [train main loss -8.737463], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 573 / 744], [train main loss -8.730009], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 574 / 744], [train main loss -8.729874], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 575 / 744], [train main loss -8.734589], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 576 / 744], [train main loss -8.736785], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 577 / 744], [train main loss -8.729607], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 578 / 744], [train main loss -8.723417], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 579 / 744], [train main loss -8.731192], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 580 / 744], [train main loss -8.733620], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 581 / 744], [train main loss -8.733509], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 582 / 744], [train main loss -8.744168], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 583 / 744], [train main loss -8.737712], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 584 / 744], [train main loss -8.732548], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 585 / 744], [train main loss -8.737117], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 586 / 744], [train main loss -8.728160], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 587 / 744], [train main loss -8.729594], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 588 / 744], [train main loss -8.723845], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 589 / 744], [train main loss -8.732290], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 590 / 744], [train main loss -8.728181], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 591 / 744], [train main loss -8.728121], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 592 / 744], [train main loss -8.733111], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 593 / 744], [train main loss -8.733053], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 594 / 744], [train main loss -8.734060], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 595 / 744], [train main loss -8.741904], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 596 / 744], [train main loss -8.741850], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 597 / 744], [train main loss -8.747942], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 598 / 744], [train main loss -8.744812], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 599 / 744], [train main loss -8.736858], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 600 / 744], [train main loss -8.742278], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 601 / 744], [train main loss -8.732862], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 602 / 744], [train main loss -8.734568], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 603 / 744], [train main loss -8.733643], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 604 / 744], [train main loss -8.733660], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 605 / 744], [train main loss -8.745262], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 606 / 744], [train main loss -8.735881], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 607 / 744], [train main loss -8.737342], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 608 / 744], [train main loss -8.754422], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 609 / 744], [train main loss -8.756499], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 610 / 744], [train main loss -8.747698], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 611 / 744], [train main loss -8.743022], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 612 / 744], [train main loss -8.744731], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 613 / 744], [train main loss -8.737067], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 614 / 744], [train main loss -8.728337], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 615 / 744], [train main loss -8.737045], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 616 / 744], [train main loss -8.748066], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 617 / 744], [train main loss -8.753159], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 618 / 744], [train main loss -8.751179], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 619 / 744], [train main loss -8.755494], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 620 / 744], [train main loss -8.758874], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 621 / 744], [train main loss -8.760072], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 622 / 744], [train main loss -8.763019], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 623 / 744], [train main loss -8.766816], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 624 / 744], [train main loss -8.769126], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 625 / 744], [train main loss -8.771032], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 626 / 744], [train main loss -8.764337], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 627 / 744], [train main loss -8.766994], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 628 / 744], [train main loss -8.770177], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 629 / 744], [train main loss -8.774737], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 630 / 744], [train main loss -8.768558], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 631 / 744], [train main loss -8.768499], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 632 / 744], [train main loss -8.778620], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 633 / 744], [train main loss -8.782278], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 634 / 744], [train main loss -8.780041], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 635 / 744], [train main loss -8.770804], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 636 / 744], [train main loss -8.769164], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 637 / 744], [train main loss -8.764322], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 638 / 744], [train main loss -8.767543], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 639 / 744], [train main loss -8.761764], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 640 / 744], [train main loss -8.763873], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 641 / 744], [train main loss -8.765306], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 642 / 744], [train main loss -8.776114], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 643 / 744], [train main loss -8.779612], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 644 / 744], [train main loss -8.784005], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 645 / 744], [train main loss -8.782259], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 646 / 744], [train main loss -8.786052], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 647 / 744], [train main loss -8.785002], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 648 / 744], [train main loss -8.780400], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 649 / 744], [train main loss -8.775609], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 650 / 744], [train main loss -8.771544], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 651 / 744], [train main loss -8.775388], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 652 / 744], [train main loss -8.781023], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 653 / 744], [train main loss -8.783868], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 654 / 744], [train main loss -8.774413], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 655 / 744], [train main loss -8.776888], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 656 / 744], [train main loss -8.787242], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 657 / 744], [train main loss -8.795960], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 658 / 744], [train main loss -8.790664], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 659 / 744], [train main loss -8.790804], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 660 / 744], [train main loss -8.789522], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 661 / 744], [train main loss -8.788103], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 662 / 744], [train main loss -8.792417], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 663 / 744], [train main loss -8.797539], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 664 / 744], [train main loss -8.792639], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 665 / 744], [train main loss -8.799675], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 666 / 744], [train main loss -8.800855], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 667 / 744], [train main loss -8.802205], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 668 / 744], [train main loss -8.803261], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 669 / 744], [train main loss -8.801176], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 670 / 744], [train main loss -8.796935], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 671 / 744], [train main loss -8.791546], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 672 / 744], [train main loss -8.789667], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 673 / 744], [train main loss -8.781607], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 674 / 744], [train main loss -8.780032], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 675 / 744], [train main loss -8.783733], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 676 / 744], [train main loss -8.787881], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 677 / 744], [train main loss -8.787590], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 678 / 744], [train main loss -8.791276], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 679 / 744], [train main loss -8.792395], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 680 / 744], [train main loss -8.786035], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 681 / 744], [train main loss -8.790375], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 682 / 744], [train main loss -8.781458], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 683 / 744], [train main loss -8.792597], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 684 / 744], [train main loss -8.792759], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 685 / 744], [train main loss -8.795478], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 686 / 744], [train main loss -8.793974], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 687 / 744], [train main loss -8.791228], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 688 / 744], [train main loss -8.798344], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 689 / 744], [train main loss -8.801242], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 690 / 744], [train main loss -8.806067], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 691 / 744], [train main loss -8.807916], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 692 / 744], [train main loss -8.813595], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 693 / 744], [train main loss -8.816918], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 694 / 744], [train main loss -8.812025], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 695 / 744], [train main loss -8.815376], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 696 / 744], [train main loss -8.814297], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 697 / 744], [train main loss -8.819997], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 698 / 744], [train main loss -8.814797], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 699 / 744], [train main loss -8.814119], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 700 / 744], [train main loss -8.816264], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 701 / 744], [train main loss -8.817713], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 702 / 744], [train main loss -8.808203], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 703 / 744], [train main loss -8.807472], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 704 / 744], [train main loss -8.806537], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 705 / 744], [train main loss -8.816850], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 706 / 744], [train main loss -8.819792], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 707 / 744], [train main loss -8.817747], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 708 / 744], [train main loss -8.822675], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 709 / 744], [train main loss -8.823878], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 710 / 744], [train main loss -8.815309], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 711 / 744], [train main loss -8.814533], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 712 / 744], [train main loss -8.813918], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 713 / 744], [train main loss -8.813138], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 714 / 744], [train main loss -8.807696], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 715 / 744], [train main loss -8.809724], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 716 / 744], [train main loss -8.813954], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 717 / 744], [train main loss -8.811606], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 718 / 744], [train main loss -8.811881], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 719 / 744], [train main loss -8.811799], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 720 / 744], [train main loss -8.809512], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 721 / 744], [train main loss -8.808739], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 722 / 744], [train main loss -8.808792], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 723 / 744], [train main loss -8.800056], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 724 / 744], [train main loss -8.794433], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 725 / 744], [train main loss -8.796441], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 726 / 744], [train main loss -8.794845], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 727 / 744], [train main loss -8.788828], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 728 / 744], [train main loss -8.785017], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 729 / 744], [train main loss -8.778569], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 730 / 744], [train main loss -8.772397], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 731 / 744], [train main loss -8.770064], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 732 / 744], [train main loss -8.765929], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 733 / 744], [train main loss -8.763527], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 734 / 744], [train main loss -8.763089], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 735 / 744], [train main loss -8.764533], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 736 / 744], [train main loss -8.766979], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 737 / 744], [train main loss -8.769614], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 738 / 744], [train main loss -8.770188], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 739 / 744], [train main loss -8.771266], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 740 / 744], [train main loss -8.782236], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 741 / 744], [train main loss -8.782975], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 742 / 744], [train main loss -8.778891], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 743 / 744], [train main loss -8.780619], [lr 0.004391] [batchtime 1.14]
[epoch 11], [iter 744 / 744], [train main loss -8.786868], [lr 0.004391] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
IoU:
  Id  label            iU_1.0     TP    FP    FN    Precision    Recall
----  -------------  --------  -----  ----  ----  -----------  --------
   0  road              96.87  37.30  0.01  0.02         0.99      0.98
   1  sidewalk          75.77   4.43  0.22  0.10         0.82      0.91
   2  building          93.38  21.14  0.04  0.03         0.96      0.97
   3  wall              54.57   0.48  0.52  0.31         0.66      0.76
   4  fence             64.77   0.65  0.26  0.29         0.80      0.78
   5  pole              71.15   1.20  0.23  0.17         0.81      0.85
   6  traffic light     77.53   0.18  0.12  0.17         0.90      0.85
   7  traffic sign      84.35   0.60  0.11  0.08         0.90      0.93
   8  vegetation        92.28  16.63  0.04  0.04         0.96      0.96
   9  terrain           57.67   0.59  0.42  0.31         0.70      0.76
  10  sky               95.20   3.30  0.02  0.03         0.98      0.97
  11  person            79.90   1.23  0.05  0.20         0.95      0.83
  12  rider             68.23   0.17  0.25  0.21         0.80      0.83
  13  car               94.95   6.34  0.03  0.03         0.97      0.97
  14  truck             80.40   0.27  0.13  0.11         0.88      0.90
  15  bus               92.37   0.37  0.05  0.03         0.95      0.97
  16  train             84.32   0.10  0.11  0.07         0.90      0.93
  17  motorcycle        45.61   0.07  0.13  1.06         0.88      0.49
  18  bicycle           77.14   0.65  0.09  0.21         0.92      0.83
Mean: 78.24
-----------------------------------------------------------------------------------------------------------
this : [epoch 11], [val loss 0.18561], [acc 0.95687], [acc_cls 0.88094], [mean_iu 0.78235], [fwavacc 0.92046]
best : [epoch 11], [val loss 0.18561], [acc 0.95687], [acc_cls 0.88094], [mean_iu 0.78235], [fwavacc 0.92046]
-----------------------------------------------------------------------------------------------------------
Class Uniform Percentage: 0.5
Class Uniform items per Epoch: 2975
cls 0 len 5866
cls 1 len 5184
cls 2 len 5678
cls 3 len 1312
cls 4 len 1723
cls 5 len 5656
cls 6 len 2769
cls 7 len 4860
cls 8 len 5388
cls 9 len 2440
cls 10 len 4722
cls 11 len 3719
cls 12 len 1239
cls 13 len 5075
cls 14 len 444
cls 15 len 348
cls 16 len 188
cls 17 len 575
cls 18 len 2238
[epoch 12], [iter 1 / 744], [train main loss -6.297360], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 2 / 744], [train main loss -8.531933], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 3 / 744], [train main loss -7.039656], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 4 / 744], [train main loss -6.812904], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 5 / 744], [train main loss -7.422989], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 6 / 744], [train main loss -8.141969], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 7 / 744], [train main loss -7.802329], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 8 / 744], [train main loss -7.156273], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 9 / 744], [train main loss -6.924173], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 10 / 744], [train main loss -6.887865], [lr 0.004338] [batchtime 0]
[epoch 12], [iter 11 / 744], [train main loss -6.835609], [lr 0.004338] [batchtime 1.13]
[epoch 12], [iter 12 / 744], [train main loss -6.996927], [lr 0.004338] [batchtime 1.13]
[epoch 12], [iter 13 / 744], [train main loss -6.835259], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 14 / 744], [train main loss -7.194437], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 15 / 744], [train main loss -7.807830], [lr 0.004338] [batchtime 1.16]
[epoch 12], [iter 16 / 744], [train main loss -7.970345], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 17 / 744], [train main loss -7.755063], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 18 / 744], [train main loss -7.963943], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 19 / 744], [train main loss -7.736924], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 20 / 744], [train main loss -7.476276], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 21 / 744], [train main loss -7.390274], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 22 / 744], [train main loss -7.951596], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 23 / 744], [train main loss -7.962449], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 24 / 744], [train main loss -8.363288], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 25 / 744], [train main loss -8.167252], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 26 / 744], [train main loss -8.162279], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 27 / 744], [train main loss -8.350459], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 28 / 744], [train main loss -8.566475], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 29 / 744], [train main loss -8.505764], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 30 / 744], [train main loss -8.445052], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 31 / 744], [train main loss -8.682422], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 32 / 744], [train main loss -8.789622], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 33 / 744], [train main loss -8.807547], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 34 / 744], [train main loss -8.812533], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 35 / 744], [train main loss -8.862870], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 36 / 744], [train main loss -8.845636], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 37 / 744], [train main loss -8.868992], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 38 / 744], [train main loss -8.926941], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 39 / 744], [train main loss -8.953002], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 40 / 744], [train main loss -8.955350], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 41 / 744], [train main loss -8.901236], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 42 / 744], [train main loss -8.819970], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 43 / 744], [train main loss -8.759834], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 44 / 744], [train main loss -8.830669], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 45 / 744], [train main loss -8.792956], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 46 / 744], [train main loss -8.773126], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 47 / 744], [train main loss -8.790805], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 48 / 744], [train main loss -8.917131], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 49 / 744], [train main loss -8.972111], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 50 / 744], [train main loss -9.066366], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 51 / 744], [train main loss -9.026366], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 52 / 744], [train main loss -8.994421], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 53 / 744], [train main loss -9.047792], [lr 0.004338] [batchtime 1.15]
[epoch 12], [iter 54 / 744], [train main loss -8.984758], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 55 / 744], [train main loss -9.020435], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 56 / 744], [train main loss -9.033569], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 57 / 744], [train main loss -9.001415], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 58 / 744], [train main loss -8.913875], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 59 / 744], [train main loss -8.924747], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 60 / 744], [train main loss -8.934194], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 61 / 744], [train main loss -8.933201], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 62 / 744], [train main loss -8.861669], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 63 / 744], [train main loss -8.807086], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 64 / 744], [train main loss -8.797416], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 65 / 744], [train main loss -8.790241], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 66 / 744], [train main loss -8.856221], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 67 / 744], [train main loss -8.866095], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 68 / 744], [train main loss -8.908193], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 69 / 744], [train main loss -8.901592], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 70 / 744], [train main loss -8.943766], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 71 / 744], [train main loss -8.958565], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 72 / 744], [train main loss -8.953677], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 73 / 744], [train main loss -9.033533], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 74 / 744], [train main loss -9.093786], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 75 / 744], [train main loss -9.187944], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 76 / 744], [train main loss -9.203762], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 77 / 744], [train main loss -9.200366], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 78 / 744], [train main loss -9.225863], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 79 / 744], [train main loss -9.212386], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 80 / 744], [train main loss -9.239491], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 81 / 744], [train main loss -9.213803], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 82 / 744], [train main loss -9.189507], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 83 / 744], [train main loss -9.179918], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 84 / 744], [train main loss -9.133589], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 85 / 744], [train main loss -9.101535], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 86 / 744], [train main loss -9.082108], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 87 / 744], [train main loss -9.079605], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 88 / 744], [train main loss -9.063045], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 89 / 744], [train main loss -9.069115], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 90 / 744], [train main loss -9.044500], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 91 / 744], [train main loss -9.038928], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 92 / 744], [train main loss -9.067269], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 93 / 744], [train main loss -9.063608], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 94 / 744], [train main loss -9.069653], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 95 / 744], [train main loss -9.123878], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 96 / 744], [train main loss -9.131527], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 97 / 744], [train main loss -9.177228], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 98 / 744], [train main loss -9.160755], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 99 / 744], [train main loss -9.137875], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 100 / 744], [train main loss -9.141039], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 101 / 744], [train main loss -9.101103], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 102 / 744], [train main loss -9.102391], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 103 / 744], [train main loss -9.109856], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 104 / 744], [train main loss -9.066709], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 105 / 744], [train main loss -9.034091], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 106 / 744], [train main loss -9.042717], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 107 / 744], [train main loss -9.024127], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 108 / 744], [train main loss -9.037227], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 109 / 744], [train main loss -9.022938], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 110 / 744], [train main loss -8.960292], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 111 / 744], [train main loss -8.983890], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 112 / 744], [train main loss -9.009123], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 113 / 744], [train main loss -9.078658], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 114 / 744], [train main loss -9.111990], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 115 / 744], [train main loss -9.179476], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 116 / 744], [train main loss -9.168685], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 117 / 744], [train main loss -9.171022], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 118 / 744], [train main loss -9.179139], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 119 / 744], [train main loss -9.177558], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 120 / 744], [train main loss -9.135587], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 121 / 744], [train main loss -9.102140], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 122 / 744], [train main loss -9.127208], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 123 / 744], [train main loss -9.126442], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 124 / 744], [train main loss -9.101392], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 125 / 744], [train main loss -9.071491], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 126 / 744], [train main loss -9.077352], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 127 / 744], [train main loss -9.090039], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 128 / 744], [train main loss -9.072064], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 129 / 744], [train main loss -9.077581], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 130 / 744], [train main loss -9.089242], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 131 / 744], [train main loss -9.089333], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 132 / 744], [train main loss -9.090789], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 133 / 744], [train main loss -9.078758], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 134 / 744], [train main loss -9.100508], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 135 / 744], [train main loss -9.120226], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 136 / 744], [train main loss -9.130777], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 137 / 744], [train main loss -9.122794], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 138 / 744], [train main loss -9.088176], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 139 / 744], [train main loss -9.064737], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 140 / 744], [train main loss -9.102439], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 141 / 744], [train main loss -9.110679], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 142 / 744], [train main loss -9.101438], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 143 / 744], [train main loss -9.136854], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 144 / 744], [train main loss -9.131268], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 145 / 744], [train main loss -9.111268], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 146 / 744], [train main loss -9.088916], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 147 / 744], [train main loss -9.098533], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 148 / 744], [train main loss -9.110496], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 149 / 744], [train main loss -9.126789], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 150 / 744], [train main loss -9.125698], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 151 / 744], [train main loss -9.106551], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 152 / 744], [train main loss -9.073812], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 153 / 744], [train main loss -9.073641], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 154 / 744], [train main loss -9.088978], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 155 / 744], [train main loss -9.086924], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 156 / 744], [train main loss -9.075245], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 157 / 744], [train main loss -9.056946], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 158 / 744], [train main loss -9.035596], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 159 / 744], [train main loss -9.017848], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 160 / 744], [train main loss -8.989757], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 161 / 744], [train main loss -8.982600], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 162 / 744], [train main loss -9.000288], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 163 / 744], [train main loss -8.999917], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 164 / 744], [train main loss -9.005284], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 165 / 744], [train main loss -9.016971], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 166 / 744], [train main loss -9.046143], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 167 / 744], [train main loss -9.024493], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 168 / 744], [train main loss -9.063295], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 169 / 744], [train main loss -9.087749], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 170 / 744], [train main loss -9.066949], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 171 / 744], [train main loss -9.047903], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 172 / 744], [train main loss -9.060451], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 173 / 744], [train main loss -9.010851], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 174 / 744], [train main loss -9.037017], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 175 / 744], [train main loss -9.026405], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 176 / 744], [train main loss -9.032581], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 177 / 744], [train main loss -9.032903], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 178 / 744], [train main loss -9.045790], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 179 / 744], [train main loss -9.046854], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 180 / 744], [train main loss -9.061013], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 181 / 744], [train main loss -9.074024], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 182 / 744], [train main loss -9.077948], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 183 / 744], [train main loss -9.077319], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 184 / 744], [train main loss -9.058736], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 185 / 744], [train main loss -9.022623], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 186 / 744], [train main loss -9.033054], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 187 / 744], [train main loss -9.037102], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 188 / 744], [train main loss -9.024562], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 189 / 744], [train main loss -9.027453], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 190 / 744], [train main loss -9.029127], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 191 / 744], [train main loss -9.012548], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 192 / 744], [train main loss -9.017383], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 193 / 744], [train main loss -9.008225], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 194 / 744], [train main loss -9.006180], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 195 / 744], [train main loss -8.992299], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 196 / 744], [train main loss -9.000106], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 197 / 744], [train main loss -8.961509], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 198 / 744], [train main loss -8.951354], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 199 / 744], [train main loss -8.957835], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 200 / 744], [train main loss -8.935478], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 201 / 744], [train main loss -8.936576], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 202 / 744], [train main loss -8.957343], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 203 / 744], [train main loss -8.958469], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 204 / 744], [train main loss -8.953532], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 205 / 744], [train main loss -8.942678], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 206 / 744], [train main loss -8.921778], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 207 / 744], [train main loss -8.921058], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 208 / 744], [train main loss -8.907827], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 209 / 744], [train main loss -8.884757], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 210 / 744], [train main loss -8.906157], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 211 / 744], [train main loss -8.873794], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 212 / 744], [train main loss -8.877274], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 213 / 744], [train main loss -8.873205], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 214 / 744], [train main loss -8.850276], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 215 / 744], [train main loss -8.861527], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 216 / 744], [train main loss -8.876096], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 217 / 744], [train main loss -8.897458], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 218 / 744], [train main loss -8.896439], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 219 / 744], [train main loss -8.899871], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 220 / 744], [train main loss -8.905876], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 221 / 744], [train main loss -8.897881], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 222 / 744], [train main loss -8.904272], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 223 / 744], [train main loss -8.941053], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 224 / 744], [train main loss -8.973260], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 225 / 744], [train main loss -8.977980], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 226 / 744], [train main loss -8.966255], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 227 / 744], [train main loss -8.959616], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 228 / 744], [train main loss -8.957330], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 229 / 744], [train main loss -8.953322], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 230 / 744], [train main loss -8.950857], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 231 / 744], [train main loss -8.948992], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 232 / 744], [train main loss -8.940915], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 233 / 744], [train main loss -8.949384], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 234 / 744], [train main loss -8.955797], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 235 / 744], [train main loss -8.949985], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 236 / 744], [train main loss -8.958433], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 237 / 744], [train main loss -8.982621], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 238 / 744], [train main loss -8.997184], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 239 / 744], [train main loss -8.989155], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 240 / 744], [train main loss -8.984631], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 241 / 744], [train main loss -8.973634], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 242 / 744], [train main loss -8.950045], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 243 / 744], [train main loss -8.942627], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 244 / 744], [train main loss -8.963899], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 245 / 744], [train main loss -8.951218], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 246 / 744], [train main loss -8.961083], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 247 / 744], [train main loss -8.942257], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 248 / 744], [train main loss -8.939969], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 249 / 744], [train main loss -8.939550], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 250 / 744], [train main loss -8.935505], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 251 / 744], [train main loss -8.927008], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 252 / 744], [train main loss -8.941552], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 253 / 744], [train main loss -8.952087], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 254 / 744], [train main loss -8.951130], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 255 / 744], [train main loss -8.952073], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 256 / 744], [train main loss -8.940414], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 257 / 744], [train main loss -8.936795], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 258 / 744], [train main loss -8.921316], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 259 / 744], [train main loss -8.895512], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 260 / 744], [train main loss -8.888806], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 261 / 744], [train main loss -8.906375], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 262 / 744], [train main loss -8.912163], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 263 / 744], [train main loss -8.908503], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 264 / 744], [train main loss -8.909877], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 265 / 744], [train main loss -8.895855], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 266 / 744], [train main loss -8.868879], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 267 / 744], [train main loss -8.868127], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 268 / 744], [train main loss -8.878631], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 269 / 744], [train main loss -8.873646], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 270 / 744], [train main loss -8.890536], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 271 / 744], [train main loss -8.889175], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 272 / 744], [train main loss -8.901129], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 273 / 744], [train main loss -8.908963], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 274 / 744], [train main loss -8.900402], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 275 / 744], [train main loss -8.902496], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 276 / 744], [train main loss -8.904048], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 277 / 744], [train main loss -8.923360], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 278 / 744], [train main loss -8.917667], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 279 / 744], [train main loss -8.912045], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 280 / 744], [train main loss -8.880467], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 281 / 744], [train main loss -8.894250], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 282 / 744], [train main loss -8.920266], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 283 / 744], [train main loss -8.925671], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 284 / 744], [train main loss -8.910625], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 285 / 744], [train main loss -8.928680], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 286 / 744], [train main loss -8.914358], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 287 / 744], [train main loss -8.901460], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 288 / 744], [train main loss -8.896153], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 289 / 744], [train main loss -8.904137], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 290 / 744], [train main loss -8.914096], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 291 / 744], [train main loss -8.897402], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 292 / 744], [train main loss -8.912445], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 293 / 744], [train main loss -8.904143], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 294 / 744], [train main loss -8.911780], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 295 / 744], [train main loss -8.906902], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 296 / 744], [train main loss -8.919300], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 297 / 744], [train main loss -8.926929], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 298 / 744], [train main loss -8.916401], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 299 / 744], [train main loss -8.906983], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 300 / 744], [train main loss -8.891362], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 301 / 744], [train main loss -8.900478], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 302 / 744], [train main loss -8.897558], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 303 / 744], [train main loss -8.895569], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 304 / 744], [train main loss -8.906190], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 305 / 744], [train main loss -8.908587], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 306 / 744], [train main loss -8.905460], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 307 / 744], [train main loss -8.910218], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 308 / 744], [train main loss -8.898300], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 309 / 744], [train main loss -8.890980], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 310 / 744], [train main loss -8.882482], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 311 / 744], [train main loss -8.883882], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 312 / 744], [train main loss -8.872794], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 313 / 744], [train main loss -8.846412], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 314 / 744], [train main loss -8.861781], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 315 / 744], [train main loss -8.839568], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 316 / 744], [train main loss -8.828017], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 317 / 744], [train main loss -8.825923], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 318 / 744], [train main loss -8.843858], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 319 / 744], [train main loss -8.840177], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 320 / 744], [train main loss -8.856418], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 321 / 744], [train main loss -8.852124], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 322 / 744], [train main loss -8.834786], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 323 / 744], [train main loss -8.837895], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 324 / 744], [train main loss -8.824600], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 325 / 744], [train main loss -8.812341], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 326 / 744], [train main loss -8.812526], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 327 / 744], [train main loss -8.825041], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 328 / 744], [train main loss -8.835193], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 329 / 744], [train main loss -8.837063], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 330 / 744], [train main loss -8.827553], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 331 / 744], [train main loss -8.826925], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 332 / 744], [train main loss -8.819637], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 333 / 744], [train main loss -8.820001], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 334 / 744], [train main loss -8.833842], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 335 / 744], [train main loss -8.844445], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 336 / 744], [train main loss -8.844446], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 337 / 744], [train main loss -8.867136], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 338 / 744], [train main loss -8.846677], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 339 / 744], [train main loss -8.844129], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 340 / 744], [train main loss -8.865058], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 341 / 744], [train main loss -8.876740], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 342 / 744], [train main loss -8.888616], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 343 / 744], [train main loss -8.893347], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 344 / 744], [train main loss -8.881079], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 345 / 744], [train main loss -8.861511], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 346 / 744], [train main loss -8.877583], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 347 / 744], [train main loss -8.905248], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 348 / 744], [train main loss -8.916680], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 349 / 744], [train main loss -8.914941], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 350 / 744], [train main loss -8.909803], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 351 / 744], [train main loss -8.919666], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 352 / 744], [train main loss -8.917599], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 353 / 744], [train main loss -8.921538], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 354 / 744], [train main loss -8.921973], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 355 / 744], [train main loss -8.914167], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 356 / 744], [train main loss -8.920167], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 357 / 744], [train main loss -8.927727], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 358 / 744], [train main loss -8.925312], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 359 / 744], [train main loss -8.921133], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 360 / 744], [train main loss -8.920025], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 361 / 744], [train main loss -8.928938], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 362 / 744], [train main loss -8.933528], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 363 / 744], [train main loss -8.922240], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 364 / 744], [train main loss -8.924097], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 365 / 744], [train main loss -8.937074], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 366 / 744], [train main loss -8.941228], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 367 / 744], [train main loss -8.944538], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 368 / 744], [train main loss -8.950759], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 369 / 744], [train main loss -8.939566], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 370 / 744], [train main loss -8.945708], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 371 / 744], [train main loss -8.950328], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 372 / 744], [train main loss -8.953656], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 373 / 744], [train main loss -8.956304], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 374 / 744], [train main loss -8.945753], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 375 / 744], [train main loss -8.952256], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 376 / 744], [train main loss -8.945078], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 377 / 744], [train main loss -8.946395], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 378 / 744], [train main loss -8.939268], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 379 / 744], [train main loss -8.954670], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 380 / 744], [train main loss -8.962342], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 381 / 744], [train main loss -8.959126], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 382 / 744], [train main loss -8.972732], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 383 / 744], [train main loss -8.972718], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 384 / 744], [train main loss -8.985771], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 385 / 744], [train main loss -8.989046], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 386 / 744], [train main loss -9.003550], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 387 / 744], [train main loss -9.000480], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 388 / 744], [train main loss -9.009756], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 389 / 744], [train main loss -9.005177], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 390 / 744], [train main loss -9.009596], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 391 / 744], [train main loss -9.001541], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 392 / 744], [train main loss -8.988445], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 393 / 744], [train main loss -8.996938], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 394 / 744], [train main loss -8.992384], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 395 / 744], [train main loss -8.985626], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 396 / 744], [train main loss -8.985130], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 397 / 744], [train main loss -9.000414], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 398 / 744], [train main loss -8.985562], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 399 / 744], [train main loss -8.979632], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 400 / 744], [train main loss -8.978503], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 401 / 744], [train main loss -8.985632], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 402 / 744], [train main loss -8.983638], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 403 / 744], [train main loss -8.982786], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 404 / 744], [train main loss -8.978770], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 405 / 744], [train main loss -8.967551], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 406 / 744], [train main loss -8.976640], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 407 / 744], [train main loss -8.973460], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 408 / 744], [train main loss -8.975096], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 409 / 744], [train main loss -8.974018], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 410 / 744], [train main loss -8.975197], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 411 / 744], [train main loss -8.960239], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 412 / 744], [train main loss -8.969393], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 413 / 744], [train main loss -8.964359], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 414 / 744], [train main loss -8.966586], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 415 / 744], [train main loss -8.970470], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 416 / 744], [train main loss -8.959317], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 417 / 744], [train main loss -8.962584], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 418 / 744], [train main loss -8.947651], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 419 / 744], [train main loss -8.948979], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 420 / 744], [train main loss -8.957881], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 421 / 744], [train main loss -8.952972], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 422 / 744], [train main loss -8.951188], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 423 / 744], [train main loss -8.946579], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 424 / 744], [train main loss -8.949891], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 425 / 744], [train main loss -8.959738], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 426 / 744], [train main loss -8.961138], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 427 / 744], [train main loss -8.962310], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 428 / 744], [train main loss -8.958237], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 429 / 744], [train main loss -8.959006], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 430 / 744], [train main loss -8.974662], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 431 / 744], [train main loss -8.950321], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 432 / 744], [train main loss -8.939892], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 433 / 744], [train main loss -8.935856], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 434 / 744], [train main loss -8.937004], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 435 / 744], [train main loss -8.938442], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 436 / 744], [train main loss -8.933512], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 437 / 744], [train main loss -8.935703], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 438 / 744], [train main loss -8.951719], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 439 / 744], [train main loss -8.952000], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 440 / 744], [train main loss -8.942275], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 441 / 744], [train main loss -8.926719], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 442 / 744], [train main loss -8.928306], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 443 / 744], [train main loss -8.925734], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 444 / 744], [train main loss -8.930237], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 445 / 744], [train main loss -8.923841], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 446 / 744], [train main loss -8.928535], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 447 / 744], [train main loss -8.940937], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 448 / 744], [train main loss -8.948233], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 449 / 744], [train main loss -8.940163], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 450 / 744], [train main loss -8.935835], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 451 / 744], [train main loss -8.940768], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 452 / 744], [train main loss -8.938110], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 453 / 744], [train main loss -8.941179], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 454 / 744], [train main loss -8.942238], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 455 / 744], [train main loss -8.940034], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 456 / 744], [train main loss -8.928345], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 457 / 744], [train main loss -8.931426], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 458 / 744], [train main loss -8.916918], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 459 / 744], [train main loss -8.909986], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 460 / 744], [train main loss -8.908867], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 461 / 744], [train main loss -8.901380], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 462 / 744], [train main loss -8.893833], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 463 / 744], [train main loss -8.905581], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 464 / 744], [train main loss -8.895816], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 465 / 744], [train main loss -8.891198], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 466 / 744], [train main loss -8.890191], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 467 / 744], [train main loss -8.896032], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 468 / 744], [train main loss -8.889355], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 469 / 744], [train main loss -8.901052], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 470 / 744], [train main loss -8.898051], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 471 / 744], [train main loss -8.885968], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 472 / 744], [train main loss -8.879362], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 473 / 744], [train main loss -8.890181], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 474 / 744], [train main loss -8.893845], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 475 / 744], [train main loss -8.897216], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 476 / 744], [train main loss -8.892924], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 477 / 744], [train main loss -8.896421], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 478 / 744], [train main loss -8.895230], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 479 / 744], [train main loss -8.893716], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 480 / 744], [train main loss -8.896658], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 481 / 744], [train main loss -8.896152], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 482 / 744], [train main loss -8.884443], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 483 / 744], [train main loss -8.878391], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 484 / 744], [train main loss -8.875738], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 485 / 744], [train main loss -8.889233], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 486 / 744], [train main loss -8.879850], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 487 / 744], [train main loss -8.885066], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 488 / 744], [train main loss -8.883833], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 489 / 744], [train main loss -8.884652], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 490 / 744], [train main loss -8.885735], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 491 / 744], [train main loss -8.901005], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 492 / 744], [train main loss -8.904436], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 493 / 744], [train main loss -8.902501], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 494 / 744], [train main loss -8.895272], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 495 / 744], [train main loss -8.894076], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 496 / 744], [train main loss -8.901487], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 497 / 744], [train main loss -8.895709], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 498 / 744], [train main loss -8.896807], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 499 / 744], [train main loss -8.894519], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 500 / 744], [train main loss -8.888841], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 501 / 744], [train main loss -8.886326], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 502 / 744], [train main loss -8.879851], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 503 / 744], [train main loss -8.888802], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 504 / 744], [train main loss -8.884728], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 505 / 744], [train main loss -8.885681], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 506 / 744], [train main loss -8.891186], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 507 / 744], [train main loss -8.896402], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 508 / 744], [train main loss -8.896739], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 509 / 744], [train main loss -8.897716], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 510 / 744], [train main loss -8.912794], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 511 / 744], [train main loss -8.906977], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 512 / 744], [train main loss -8.909677], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 513 / 744], [train main loss -8.910575], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 514 / 744], [train main loss -8.909609], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 515 / 744], [train main loss -8.915069], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 516 / 744], [train main loss -8.912706], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 517 / 744], [train main loss -8.918686], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 518 / 744], [train main loss -8.914417], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 519 / 744], [train main loss -8.915841], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 520 / 744], [train main loss -8.909952], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 521 / 744], [train main loss -8.909458], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 522 / 744], [train main loss -8.918517], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 523 / 744], [train main loss -8.912418], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 524 / 744], [train main loss -8.904143], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 525 / 744], [train main loss -8.904094], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 526 / 744], [train main loss -8.912572], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 527 / 744], [train main loss -8.914385], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 528 / 744], [train main loss -8.919425], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 529 / 744], [train main loss -8.926325], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 530 / 744], [train main loss -8.934697], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 531 / 744], [train main loss -8.922366], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 532 / 744], [train main loss -8.917453], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 533 / 744], [train main loss -8.916481], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 534 / 744], [train main loss -8.916138], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 535 / 744], [train main loss -8.922115], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 536 / 744], [train main loss -8.912516], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 537 / 744], [train main loss -8.907381], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 538 / 744], [train main loss -8.912271], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 539 / 744], [train main loss -8.911782], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 540 / 744], [train main loss -8.908217], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 541 / 744], [train main loss -8.895693], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 542 / 744], [train main loss -8.895094], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 543 / 744], [train main loss -8.890841], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 544 / 744], [train main loss -8.896812], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 545 / 744], [train main loss -8.898871], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 546 / 744], [train main loss -8.891751], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 547 / 744], [train main loss -8.893482], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 548 / 744], [train main loss -8.886364], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 549 / 744], [train main loss -8.879097], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 550 / 744], [train main loss -8.880743], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 551 / 744], [train main loss -8.875304], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 552 / 744], [train main loss -8.875710], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 553 / 744], [train main loss -8.865649], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 554 / 744], [train main loss -8.855965], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 555 / 744], [train main loss -8.863076], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 556 / 744], [train main loss -8.860297], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 557 / 744], [train main loss -8.854737], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 558 / 744], [train main loss -8.847309], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 559 / 744], [train main loss -8.843234], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 560 / 744], [train main loss -8.841567], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 561 / 744], [train main loss -8.842857], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 562 / 744], [train main loss -8.850280], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 563 / 744], [train main loss -8.854534], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 564 / 744], [train main loss -8.861531], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 565 / 744], [train main loss -8.863251], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 566 / 744], [train main loss -8.863078], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 567 / 744], [train main loss -8.871758], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 568 / 744], [train main loss -8.877845], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 569 / 744], [train main loss -8.878282], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 570 / 744], [train main loss -8.877396], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 571 / 744], [train main loss -8.881281], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 572 / 744], [train main loss -8.881826], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 573 / 744], [train main loss -8.877591], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 574 / 744], [train main loss -8.869302], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 575 / 744], [train main loss -8.861614], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 576 / 744], [train main loss -8.860463], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 577 / 744], [train main loss -8.854556], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 578 / 744], [train main loss -8.852860], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 579 / 744], [train main loss -8.856761], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 580 / 744], [train main loss -8.855416], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 581 / 744], [train main loss -8.858466], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 582 / 744], [train main loss -8.857403], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 583 / 744], [train main loss -8.859777], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 584 / 744], [train main loss -8.856094], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 585 / 744], [train main loss -8.867685], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 586 / 744], [train main loss -8.870304], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 587 / 744], [train main loss -8.865218], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 588 / 744], [train main loss -8.873180], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 589 / 744], [train main loss -8.871687], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 590 / 744], [train main loss -8.864782], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 591 / 744], [train main loss -8.863509], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 592 / 744], [train main loss -8.868005], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 593 / 744], [train main loss -8.866464], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 594 / 744], [train main loss -8.859132], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 595 / 744], [train main loss -8.859476], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 596 / 744], [train main loss -8.864247], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 597 / 744], [train main loss -8.876053], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 598 / 744], [train main loss -8.880231], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 599 / 744], [train main loss -8.878377], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 600 / 744], [train main loss -8.878913], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 601 / 744], [train main loss -8.885638], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 602 / 744], [train main loss -8.876513], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 603 / 744], [train main loss -8.884206], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 604 / 744], [train main loss -8.891867], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 605 / 744], [train main loss -8.879441], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 606 / 744], [train main loss -8.890032], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 607 / 744], [train main loss -8.894641], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 608 / 744], [train main loss -8.892604], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 609 / 744], [train main loss -8.891966], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 610 / 744], [train main loss -8.892797], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 611 / 744], [train main loss -8.901616], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 612 / 744], [train main loss -8.898107], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 613 / 744], [train main loss -8.897304], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 614 / 744], [train main loss -8.893900], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 615 / 744], [train main loss -8.900448], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 616 / 744], [train main loss -8.903224], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 617 / 744], [train main loss -8.905870], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 618 / 744], [train main loss -8.904688], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 619 / 744], [train main loss -8.909892], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 620 / 744], [train main loss -8.914420], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 621 / 744], [train main loss -8.913052], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 622 / 744], [train main loss -8.909620], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 623 / 744], [train main loss -8.914791], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 624 / 744], [train main loss -8.902800], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 625 / 744], [train main loss -8.907860], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 626 / 744], [train main loss -8.905634], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 627 / 744], [train main loss -8.915765], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 628 / 744], [train main loss -8.913783], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 629 / 744], [train main loss -8.917705], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 630 / 744], [train main loss -8.915831], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 631 / 744], [train main loss -8.910242], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 632 / 744], [train main loss -8.909134], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 633 / 744], [train main loss -8.910774], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 634 / 744], [train main loss -8.910983], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 635 / 744], [train main loss -8.908105], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 636 / 744], [train main loss -8.916200], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 637 / 744], [train main loss -8.925817], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 638 / 744], [train main loss -8.927105], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 639 / 744], [train main loss -8.933806], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 640 / 744], [train main loss -8.925457], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 641 / 744], [train main loss -8.921721], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 642 / 744], [train main loss -8.918633], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 643 / 744], [train main loss -8.917083], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 644 / 744], [train main loss -8.918570], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 645 / 744], [train main loss -8.912987], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 646 / 744], [train main loss -8.916552], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 647 / 744], [train main loss -8.917115], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 648 / 744], [train main loss -8.914336], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 649 / 744], [train main loss -8.918934], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 650 / 744], [train main loss -8.916554], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 651 / 744], [train main loss -8.925943], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 652 / 744], [train main loss -8.935075], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 653 / 744], [train main loss -8.935993], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 654 / 744], [train main loss -8.927603], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 655 / 744], [train main loss -8.926399], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 656 / 744], [train main loss -8.928868], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 657 / 744], [train main loss -8.921204], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 658 / 744], [train main loss -8.916942], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 659 / 744], [train main loss -8.910914], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 660 / 744], [train main loss -8.922055], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 661 / 744], [train main loss -8.926886], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 662 / 744], [train main loss -8.913764], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 663 / 744], [train main loss -8.907327], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 664 / 744], [train main loss -8.910764], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 665 / 744], [train main loss -8.912233], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 666 / 744], [train main loss -8.913261], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 667 / 744], [train main loss -8.912719], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 668 / 744], [train main loss -8.912813], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 669 / 744], [train main loss -8.919747], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 670 / 744], [train main loss -8.922260], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 671 / 744], [train main loss -8.913831], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 672 / 744], [train main loss -8.913085], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 673 / 744], [train main loss -8.909089], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 674 / 744], [train main loss -8.909307], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 675 / 744], [train main loss -8.915219], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 676 / 744], [train main loss -8.920471], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 677 / 744], [train main loss -8.926172], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 678 / 744], [train main loss -8.928861], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 679 / 744], [train main loss -8.934906], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 680 / 744], [train main loss -8.934585], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 681 / 744], [train main loss -8.936020], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 682 / 744], [train main loss -8.930573], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 683 / 744], [train main loss -8.930998], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 684 / 744], [train main loss -8.933270], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 685 / 744], [train main loss -8.943995], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 686 / 744], [train main loss -8.940410], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 687 / 744], [train main loss -8.942403], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 688 / 744], [train main loss -8.944922], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 689 / 744], [train main loss -8.941095], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 690 / 744], [train main loss -8.945010], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 691 / 744], [train main loss -8.942116], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 692 / 744], [train main loss -8.939488], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 693 / 744], [train main loss -8.930949], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 694 / 744], [train main loss -8.929525], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 695 / 744], [train main loss -8.942220], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 696 / 744], [train main loss -8.943943], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 697 / 744], [train main loss -8.946477], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 698 / 744], [train main loss -8.945422], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 699 / 744], [train main loss -8.938317], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 700 / 744], [train main loss -8.940966], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 701 / 744], [train main loss -8.949923], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 702 / 744], [train main loss -8.945119], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 703 / 744], [train main loss -8.938714], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 704 / 744], [train main loss -8.935679], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 705 / 744], [train main loss -8.937205], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 706 / 744], [train main loss -8.942215], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 707 / 744], [train main loss -8.945658], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 708 / 744], [train main loss -8.940900], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 709 / 744], [train main loss -8.944191], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 710 / 744], [train main loss -8.936820], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 711 / 744], [train main loss -8.936900], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 712 / 744], [train main loss -8.940189], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 713 / 744], [train main loss -8.939751], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 714 / 744], [train main loss -8.940146], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 715 / 744], [train main loss -8.937007], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 716 / 744], [train main loss -8.942186], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 717 / 744], [train main loss -8.937677], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 718 / 744], [train main loss -8.935207], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 719 / 744], [train main loss -8.940607], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 720 / 744], [train main loss -8.945689], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 721 / 744], [train main loss -8.939220], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 722 / 744], [train main loss -8.945524], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 723 / 744], [train main loss -8.943810], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 724 / 744], [train main loss -8.942233], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 725 / 744], [train main loss -8.942274], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 726 / 744], [train main loss -8.945390], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 727 / 744], [train main loss -8.944455], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 728 / 744], [train main loss -8.938534], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 729 / 744], [train main loss -8.936941], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 730 / 744], [train main loss -8.933110], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 731 / 744], [train main loss -8.934378], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 732 / 744], [train main loss -8.936709], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 733 / 744], [train main loss -8.935616], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 734 / 744], [train main loss -8.934787], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 735 / 744], [train main loss -8.936151], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 736 / 744], [train main loss -8.941330], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 737 / 744], [train main loss -8.935272], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 738 / 744], [train main loss -8.931462], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 739 / 744], [train main loss -8.937129], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 740 / 744], [train main loss -8.934315], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 741 / 744], [train main loss -8.930342], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 742 / 744], [train main loss -8.935042], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 743 / 744], [train main loss -8.935352], [lr 0.004338] [batchtime 1.14]
[epoch 12], [iter 744 / 744], [train main loss -8.938423], [lr 0.004338] [batchtime 1.14]
validating[Iter: 1 / 125]
validating[Iter: 21 / 125]
validating[Iter: 41 / 125]
validating[Iter: 61 / 125]
validating[Iter: 81 / 125]
validating[Iter: 101 / 125]
validating[Iter: 121 / 125]
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())
[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())
[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())
[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())
[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())
[W TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator())
[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())
[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())
/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:114: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Traceback (most recent call last):
  File "train.py", line 601, in <module>
    main()
  File "train.py", line 457, in main
    validate(val_loader, net, criterion_val, optim, epoch)
  File "train.py", line 574, in validate
    args, val_idx)
  File "/home/gandi/Donglusen/workspace/semantic-segmentation/utils/trnval_utils.py", line 141, in eval_minibatch
    output_dict = net(inputs)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/apex/parallel/distributed.py", line 560, in forward
    result = self.module(*inputs, **kwargs)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gandi/Donglusen/workspace/semantic-segmentation/network/ocrnet.py", line 332, in forward
    return self.nscale_forward(inputs, cfg.MODEL.N_SCALES)
  File "/home/gandi/Donglusen/workspace/semantic-segmentation/network/ocrnet.py", line 224, in nscale_forward
    outs = self._fwd(x)
  File "/home/gandi/Donglusen/workspace/semantic-segmentation/network/ocrnet.py", line 174, in _fwd
    cls_out, aux_out, ocr_mid_feats = self.ocr(high_level_features)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gandi/Donglusen/workspace/semantic-segmentation/network/ocrnet.py", line 87, in forward
    aux_out = self.aux_head(high_level_features)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py", line 117, in forward
    input = module(input)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 102, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py", line 1119, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 720.00 MiB (GPU 3; 10.76 GiB total capacity; 4.41 GiB already allocated; 512.94 MiB free; 9.29 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/distributed/launch.py", line 261, in <module>
    main()
  File "/home/gandi/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/distributed/launch.py", line 257, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/home/gandi/miniconda3/envs/pytorch/bin/python', '-u', 'train.py', '--local_rank=3', '--dataset', 'cityscapes', '--cv', '0', '--syncbn', '--apex', '--fp16', '--crop_size', '1024,1024', '--bs_trn', '1', '--poly_exp', '2', '--lr', '5e-3', '--rmi_loss', '--max_epoch', '175', '--n_scales', '0.5,1.0,2.0', '--supervised_mscale_loss_wt', '0.05', '--snapshot', 'ASSETS_PATH/seg_weights/ocrnet.HRNet_industrious-chicken.pth', '--arch', 'ocrnet.HRNet_Mscale', '--result_dir', '/home/gandi/Donglusen/workspace/semantic-segmentation/logs/train_cityscapes/ocrnet.HRNet_Mscale_simple-quetzal_2021.01.04_00.32']' died with <Signals.SIGTERM: 15>.

